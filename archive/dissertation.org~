* post-prospectus
** avenues to pursue
consider joyce98 and pettigrew13: can you show that with Joyce's
assumptions (structure, normality, extensionality, dominance, weak
convexity, and symmetry) or Greaves and Wallace's assumptions
(separable and proper), sharp credences outperform indeterminate
credences? maher02 is an interesting objection to joyce98. Consider
Joyce's idea of supervaluationism joyce98:590. (more on this in
sonk.org)
** committee feedback
The Principle of Maximum Entropy: Virtues and Vices should be 2
chapters, not one.

Make the terminology connect to the concerns of epistemology.
** Carrie's feedback
These are on a marked-up copy of the prospectus as well, see email
2014-04-22.

Just as in deductive logic, we may come to a tentative and voluntary
agreement on a set of rules and presuppositions and then go part of
the way together: Carrie suggests not to get into voluntarism in
deductive logic here.

Figure out the terminology around levels or layers when it comes to
dynamic probabilities. Same for the Romeijn point about evidence
handling (evidential vs. epistemic). 
* collator
** affine constraints
landeswilliamson13:3557 (standard entropy maximizing is not rational because the maximizer is sometimes equivocal, e.g. when the evidence says, P(Tails)>1/2)
debbahmueller05:1673
csiszar67
williams80:137
uffink96:7
paris04:66
howsonfranklin94:456
williamson11:5
penfield13:chapter 9.4 http://www-mtl.mit.edu/Courses/6.050/2013/notes/chapter9.pdf
** AGM belief revision
halpern03:342ff
** Akaike
howsonurbach06:292
forstersober94:2 (Akaike without Tears, criticizing Bayes)
** all propositions under consideration must have subjective probabilities assigned
do you have a name for this principle? hajek03:313 has a list of what these propositions may be
** behaviourism
ramsey
weatherson12:7
** Bertrand's paradox
paris04:71
Gyenis and Redei: Defusing Bertrand's Paradox (article)
** Brandeis dice problem
paris04:72
jaynesbretthorst03:344
** Carnap's continuum
carnap52:7
carnap52:16 (would we be able to fix lambda by ME and weakening the
assumptions so that no individual is fully know?)
carnap52:37ff (lambda=infty)
diasshimony81:188
jaynesbretthorst03:563 (rule of succession see more in their index)
jaynesbretthorst03:574f (specifically on Carnap)
** concentration phenomenon
seidenfeld86:276
** conditionals
campenhoutcover81
douvenromeijn09
** conditionals first
gyenisetalunpub:2 with references
gillies00:30
jaynesbretthorst03:89
** convexity
here is an example where convexity is problematic: imagine you are
given a coin and the information that it is biased to come up heads,
but not how much. you toss it and it comes up tails. what is your
updated probability that the next toss will be heads?
** counterfactuals
halpern03:314ff
howsonurbach06:299fn
chalmers11:3
** Cox's Theorem
jaynes88 (more compelling than representation theorems and DB arguments)
halpern99
cox46
halpern03:65
spohn12:183
paris04:24
howsonurbach06:85
** Dempster-Shafer
paris04:7 
paris04:35
halpern03:32ff
** Donkin's Objectivism
zabell88:23

LJ Savage, Foundations of Statistics: ``The criteria incorporated in
the personalistic view do not guarantee agreement on all questions
among all honest and freely communicating people, even in principle.''
(quoted in huttegger12:1, unpublished,
http://faculty.sites.uci.edu/shuttegg/files/2011/03/MergingProbabilityKinematics.pdf)

huttegger12:26 If uncertain evidence is such that it leaves room for
interpretation, then individually rational people can reach different
conclusions based on the same evidence.
** Dutch-book, diachronic
lewis99
williamson10:5 and williamson10:22
howsonfranklin94:458
armendt80
williamson11:14
** Dutch-book, synchronic
term `arbitrage opportunities' for Dutch books, see Schervish cited in elga10:4

cavesetal02:2

howsonfranklin94:458

skyrms86:234

earman92:38f (with criticism)

halpern03:20 (Ramsey's version)

paris04:21

howsonurbach06:67f
** enthymemes
see literatur/korrespondenz/TO-LeendertHuisman-2014-12-27.txt the idea
here is that evidence sometimes enthymematically carries information
that Adams conditioning should be applied. See douvenromeijn09.
** epistemic entrenchment
agm85
nayaketal96 (nayak has written a lot about entrenchment, see google
scholar (search for "nayak foo") here specifically about the Judy
Benjamin problem) 
douvenromeijn09:14 (Hellinger's Distance)
** evidence -> information -> probability
debbahmueller05:1684
this is what I used for my prospectus defence Donkin Objectivism fails
for evidence -> probability but may succeed for information ->
probability, Ramsey's decisive objection on zabell88:25 against
logical probability may be rebuffed similarly. See enthymemes.
** evidep
see evidep.org

for an example where an evidep confusion leads to a violation of
MAXENT see Leendert Huisman's paper, ``maximizing the relative entropy
won't do''
** excessive apriorism
walley91:334, ``Does this mean, as some Bayesians have suggested, that
Your initial beliefs automatically determine Your beliefs at later
times? Other authors have denied that the updated beliefs are
constrained in any way by initial beliefs. Our conclusions are
intermediate between these extremes.'' Walley does this by posing that
GBR (the generalized bayes rule) is a constraint on updated
probabilities, but an agent can pick out a more precise set of updated
probabilities, as long as they are consistent with GBR. ``Usually,
initial beliefs do not determine updated beliefs, but they do impose
some constraints on updating, through the GBR.'' walley91:340.

teller75:169
teller75:173
joyce05:170f (the baffling position)
williamson11:11
seidenfeld79:414
williamson11:11
gillies00:81
gillies00:84
gillies00:57 (quoting de Finetti)
hempel45:107
earman92:139f
** exchangability
howsonurbach06:87
** formal methods
popper59:410
** frequentism
howsonurbach06:131fff
** full employment
neapolitanchiang14:4012 (referring to a classic statement of FE by Seidenfeld)
according to Chris French, see Carnap 1962/1950 pp192--199 for a discussion, motivated by Alan Turing, of ``the impossibility of an automatic inductive procedure''
grovehalpern97:3 and 6
jaynesbretthorst03:492
halpern03:423
halpern03:54f (eclecticism)
douvenromeijn09:16 (Bradley)
fraassen93:306
** independence
debbahmueller05:1670
debbahmueller05:1672
debbahmueller05:1674
Allais problem maher93:63
walley91:443ff
** inductive logic
hempel45:98
jaynesbretthorst03:279 (Jaynes' assessment of Carnap)
jaynesbretthorst03:326
** information, philosophy of
interesting story: The Library of Babel by Jorge Luis Borges
** information versus probability
kampe67
kampe63
guiasu77:29
kolmogorov68a:158
ingardenurbanik62:136 (see also guiasu77:87)
guiasu77:36f
kolmogorov68:663f
guiasu77:337f
** introductory remarks
The thesis of this dissertation is simple. If you are a Bayesian, you
ought to use sharp credences and update on the basis of information
entropy. This view was wide-spread 50 years ago, when it was more or
less taken for granted. E.T. Jaynes did much to formalize it and give
it a justification specifically aimed at scientists. From today's
perspective, however, holding Jaynes' views would be naive. My project
is not dissimilar, by analogy, to Jesse Prinz's project of defending
empiricism in a climate where old-style empiricism is considered
naive. The challenge is to give the critics a careful reading, adjust
the places where earlier views reveal vulnerabilities, and show that
the project does not collapse but on the contrary becomes more
intimately detailed and therefore stable. Whenever Prinz addresses an
issue, one can hear the voice of the fidei defensor (fides being
empiricism in this case) in the background. This dissertation has a
similar ring to it. 

Whatever the issue is, in the background a defence of Jaynesian
Bayesianism is operative. The defence, however, does not shy away from
modifying the naive account, as Prinz never shies away from modifying
naive Humean empiricism. Nevertheless, Prinz's claim is provocative
and difficult to reconcile with current philosophical trends: all
cognition is based on perception. I experience the world before I come
to know it. Analogously, my claim is difficult to reconcile with
current epistemological trends. They are characterized by what I will
call the full employment theorem, an attitude towards epistemology
which puts emphasis on the epistemologist and her ingenuity. By
contrast, I defend an austere view of Bayesian objectivism (not to be
confused with an objective interpretation of probabilities, which all
Bayesians reject). Behind the austerity, there is a deeper
philosophical point, comparable to Prinz's emphasis on experience over
thought. I am not much of a metaphysician, but vaguely sympathetic to
Carnapian doubts that there is much to be gained from metaphysical
inquiry. Operative behind the austerity of my (Bayesian) objectivism
is the view that in this century we should arrive at an
epistemological pessimism as deep as Carnap's metaphysical pessimism. 

Pessimism, as opposed to skepticism, rejects second-order knowledge.
While skepticism claims that the skeptic knows what she doesn't know,
the pessimist may be a (cautious) optimist that she knows something
rather than nothing. But she has no idea what she knows, and never
will. I presume Carnap did not reject metaphysics as such. There are
things and relations between those things. We have no idea what they
are, and never will. The full employment theorem is false:
epistemology is not complicated, but simple---almost as simple as
Jaynes thought it was; and we cannot do it. Computers could, if we
could only figure out what to tell them to do. Rank and file
scientists are as good at it as sophisticated epistemologists employed
in philsophy departments, as long as the former do not take too
seriously the theories of the latter. The objective of this
dissertation is so show how the full employment criticism of the naive
view always fails to torpedo the simple idea of the naive view, while
sometimes succeeding in making the naive view even simpler by
jettisoning some historical baggage (e.g. objectivism about prior
probabilities).
** invariance
Howson's description-relativity worry (see gyenisetalunpub:15)
landeswilliamson13:3560 (``standard entropy maximization is language invariant,'' see paris04:76, all other g-entropy maximizers are not, landeswilliamson13:3564)
uffink95:25
jaynesbretthorst03:378ff
jaynes73
paris04:76 (of ME)
howsonurbach06:273f
** Jaynes' Well-Posed Problem
howsonurbach06:284f (criticism)
** JC justified/introduced/criticized
investigate Richard Pettigrew and Hans Leitgeb's criticism of JC based on rigidity, see ReadingGroup-FormalEpistemology
there is more on this now in jeco.org, the literature should be reviewed there as well
diaconiszabell82:824
halpern03:105
fraassen93:297ff (JC is better than ME)
levi67
** JC solves affine constraints
douvenromeijn09:1
** JC dynamic coherence (Dutch-book)
Skyrms has a Dutch-book argument for JC, but I don't know where (what
about David Lewis's Why Conditionalize?)

huttegger12:23 The dynamic coherence arguments used by Goldstein, van
Fraassen and Skyrms have been met with a lot of critical resistance in
the literature (see e.g. Levi, 1987; Christensen, 1991; Talbott, 1991;
Maher, 1992; Howson and Urbach, 1993). (huttegger12:1, unpublished,
http://faculty.sites.uci.edu/shuttegg/files/2011/03/MergingProbabilityKinematics.pdf)
** knowledge -> model -> reality
debbahmueller05:1685
** Kullback-Leibler measures information
kullbackleibler51
seidenfeld86:262ff
guiasu77:28
guiasu77:308ff
kullback59:chapter 1 (in paper collection)
** Lagrange Multipliers
palmiericiuonzo13:2 call the function resulting from the Lagrange
Multiplier method the Boltzmann distribution

proof that the LM function maximizes entropy: penfield13:chapter 9.6.3
(similar to the proof I once did on my own);coverthomas06:409ff

jaynesbretthorst03:354ff
jaynesbretthorst03:285ff, 290ff
jaynes78:244
jaynes57:623
shorejohnson81:480
guiasu77:69f
guiasu77:296
guiasu77:327ff
guiasu77:333
according to penfield13 LMs are too complicated and not needed, see
quotes
zubarevetal74:54ff (not really useful)
seidenfeld86:281
uffink95:5
uffink96:6
** logarithmic loss functions
landeswilliamson13:3530f
** ME axiomatic approach
guiasu77:9 (axiomatic justification for entropy, distinguish between
discrete and continuous, see guiasu77:16ff, shorejohnson80:26,
reza94:269ff and zubarevetal74:55)
jaynes57:appendix A (axiomatic justification for entropy, Shannon)
uffink96:8 (axiomatic justification for entropy, Shannon)
jaynesbretthorst03:346 (axiomatic justification for entropy, Shannon)
fraassenetal86
shorejohnson80 (criticized in uffink96:14ff)
tikochinskyetal84
skilling88
** ME conclusive remarks
walley91:271
moss13:7
mackay02:308
williams80:140f
gruenwaldhalpern03:243, 245
wagner92:255
skyrms86:241
halpern03:110
diaconiszabell82:829
howsonfranklin94:465
howsonurbach06:287
skyrms87:237 
douvenromeijn09:16 (Bradley)
** ME the simple intuition
debbahmueller05:1685f

The \textsc{pme} operates on the basis of an astonishingly simple
principle: when updating your probabilities, waste no useful
information and do not gain information unless the evidence compels
you to gain it (see \scite{8}{jaynes88}{280},
\scite{8}{fraassenetal86}{376}, and \scite{8}{zellner88}{278}). The
astonishingly simple principle comes with its own formal apparatus
(not unlike probability theory itself): Shannon's information entropy,
the Kullback-Leibler divergence, the use of Lagrange multipliers, and
the sometimes intricate, sometimes straightforward relationship
between information and probability.
** ME for type I prior probabilities
the nonsense of noninformative priors walley91:234
alternatives to uniform priors see Kass and Wasserman: The Selection of Prior Distributions by Formal Rules
see my Bartha paper
** ME versus infomin
see order dependence
** ME applications
debbahmueller05:1668
karmeshu03
buck91
shorejohnson80:26
** ME contradicts standard conditioning/Bayes
neapolitanchiang14:4012
uffink95:14
howsonurbach06:278
shimony85
seidenfeld79:432f
fraassen93:288ff (SC is better than ME)
** ME is SC/JC extension
grovehalpern97:1
williamson11:8
gruenwaldhalpern03:262
catichagiffin06:11
paris04:119f
skyrms86:234
** ME justified/introduced/criticized
landeswilliamson13:3530 (unified justification for three norms at once: probability norm, calibration norm, and equivocation norm)
debbahmueller05:1668
walley91:266f for criticism (list of objections walley91:270ff)
guiasu77:293fff
halpern03:107f
halpern03:418 (and criticism of ME halpern03:420, more literature for
random worlds see halpern03:429f)
giffin08
** ME produces unwarranted information
howsonurbach06:286 (williamson04)
** ME throws away information
howsonurbach06:297
** ME versus PI
jaynes57:623
** non-unary case
halpern03 claims that ME fails for the non-unary case,
penfield13:chapter 9.6.4 has a more differentiated picture
** objectivity
see prospectus

walley91:111 for a nice summary of issues
** Old Evidence
howsonurbach06:297
** optimal information processing
zellner88:278
there is a Jaynes quote somewhere -- have fun finding it -- got it jaynes88:280
fraassenetal86:376
** order dependence
other terms:
asymmetry
commutativity

see BJPS review of my Wagner paper
walley91:270
wagner02:266
wagner02:274
field78

huttegger12:17 Soft Jeffrey shifts play an important role for studying
the problem of non- commutativity in probability kinematics (Diaconis
and Zabell, 1982; Wagner, 2002). Commutativity means that an agent
ends up with the same posterior probability regardless of the order of
successive updates. Bayesian conditioning is commutative, but
probability kinematics may not be. This has caused some concerns as to
whether probability kinematics is a rational way to update beliefs
(D{\"o}ring, 1999; Lange, 2000; Kelly, 2008). I agree with Wagner
(2002) and Joyce (2010) that these concerns are misguided. As Joyce
(2010) points out, probability kinematics is non-commutative exactly
when it should be; namely, when belief revision destroys information
obtained in previous updates. (huttegger12:1, unpublished,
http://faculty.sites.uci.edu/shuttegg/files/2011/03/MergingProbabilityKinematics.pdf)
*** ME versus Infomin
This corresponds to the intuition that we ought not to gain
information where the additional information is not warranted by the
evidence. Some want to drive a wedge between the synchronic rule to
keep the entropy maximal (\textsc{maxent}) and the diachronic rule to
keep the cross-entropy minimal (\emph{Infomin}) (for this objection
see \scite{8}{walley91}{270f}).

Here is a brief excursion to dispel this worry. Consider a bag with
blue, red, and green tokens. You know that ($C'$) at least 50\% of the
tokens are blue. Then you learn that ($C''$) at most 20\% of the tokens
are red. The synchronic norm \textsc{maxent}, on the one hand, ignores
the diachronic dimension and prescribes the probability distribution
which has the maximum entropy and obeys both ($C'$) and ($C''$). The
three-dimensional vector containing the probabilities for blue, red,
and green is $(\frac{1}{2},\frac{1}{5},\frac{3}{10})$. \emph{Infomin},
on the other hand, processes ($C'$) and ($C''$) sequentially, taking in its
second step $(\frac{1}{2},\frac{1}{4},\frac{1}{4})$ as its prior
probability distribution and then diachronically updating to
$(\frac{8}{15},\frac{1}{5},\frac{4}{15})$.

The information provided in a problem calling for \textsc{maxent} and
the information provided in a problem calling for \emph{Infomin} is
different, as temporal relations and their implications for dependence
between variables clearly matter. In the above case, we might have
relevantly received information ($C''$) before ($C'$) (\qnull{before} may
be understood logically rather than temporally) so that \emph{Infomin}
updates in its last step $(\frac{2}{5},\frac{1}{5},\frac{2}{5})$ to
$(\frac{1}{2},\frac{1}{6},\frac{1}{3})$. Even if ($C'$) and ($C''$) are
received in a definite order, the problem may be phrased in a way that
indicates independence between the two constraints. In this case,
\textsc{maxent} is the appropriate norm to use. \emph{Infomin} does
not assume such independence and therefore processes the two pieces of
information separately. Disagreement arises when observations are
interpreted differently, not because \textsc{maxent} and
\emph{Infomin} are inconsistent with each other. In the following I
will assume that \textsc{maxent} and \emph{Infomin} are compatible and
part of the toolkit at the disposal of (M), the principle of maximum
entropy.
** Paris' renaming principle
howsonurbach06:286 (criticism)
paris04:95
** principal principle
lewis80
howsonurbach06:76
earman92:51f
** principle of indifference
white10:161
uffink96:3
jaynes73
earman92:14f
halpern03:17f
howsonurbach06:266f
** propositions and sentences
williamson00
moss13:5
** ranking functions
halpern03:43ff
halpern03:97 (conditioning)
** raven's paradox
howsonurbach06:99
clarke10
** reconciliation full belief partial belief
weatherson12:19
Spohn, 2012; and Moss, 2013
** regularity
also called inclusivity in landeswilliamson13:3556

also called strict coherence, see hajek03:281, who also lists
supporters and deniers

I suspect that strict conditionalization should be regarded as an
oversimplicfication that can't ever really arise (field78:365)
** Renyi entropy
huisman14, defending imprecise probabilities for Judy Benjamin based
on Renyi entropy et al
uffink96
catichagiffin06:8f
guiasu77:75f
** representation theorems
J. Joyce apparently argues that probabilism is independent of
representation theorems (Schmierbuch p. 888)
jeffrey70:159
howsonurbach06:57
kaplan96:ix
** retrospective conditioning
grovehalpern97
diaconiszabell82:822
** rule of succession
howsonurbach06:269
** SC justified/introduced/criticized
plain vanilla Bayesian conditioning (huttegger12:1, unpublished, http://faculty.sites.uci.edu/shuttegg/files/2011/03/MergingProbabilityKinematics.pdf)
there is a whole paragraph on the justification of SC in the literature in leitgebpettigrew10ii:244
lewis99
moss13:7 for a howler
howson14: Colin Howson: Finite Additivity, Another Lottery Paradox and Conditionalization
SC is the problem, not ME williamson11:1 -- interesting paper; read!
teller75 (Shimony justifies SC on very weak assumptions)
howsonurbach06:81 (SC is inconsistent)
zellner88:279
earman92:44
earman92:46
see also Dutchbook, synchronic
earman92:9
halpern03:77ff
earman92:chapter9 (formal learning -> Bayes neither descriptive nor
normative earman92:225)
** SC solves affine constraints
Campenhout and Cover (1981) see MAXENT as a special case of Bayes' Theorem
skyrms86:237
skyrms85 (according to van Fraassen, ``the most sensitive treatment
so far'', fraassen93:313)
skyrms86:237
grovehalpern97
howsonfranklin94:461
** SC solves ME problems as an ME special case
my claim about Monty Hall in gruenwaldhalpern03, but this strategy
also works against skyrms87:236f (see printed version)

walley91:279 thinks that in the three prisoners' problem, the
probabilities should dilate
** second tier
domotor80
skyrms86:238 (``higher order probabilities'')
earman92:52
skyrms85:64
gillies00:21
paris04:38 (for DS belief functions)
earman92:52
hempel45:114
haack: not 0.5 but I don't know
** Seidenfeld
seidenfeld86
seidenfeld79:434 (nuisance)
gruenwaldhalpern03:246, 263
** semantic information
carnapbarhillel53
burgin09:316ff
** Shimony's Lagrange Multiplier
cyranski79
diasshimony81
friedmanshimony71
gagehestenes73
hobson72
jaynes85
jaynes78
shimony85
skyrms87:236
tribusmotroni72
uffink95:16
** Solomonoff
wallacedowe99:271f
solomonov64:7 (very similar approach in jeffreys57:37)
kolmogorov68:662
howsonurbach06:296
kaplan96:27
** stopping rule
howsonurbach06:250
** strictly prior probabilities
jaynesbretthorst03:chapter 12 (372ff)
jaynesbretthorst03:178
earman92:57f
earman92:139 (the tabula rasa argument)
** supposing
skyrms87
** thought experiments
*** Bertrand's paradox
jaynesbretthorst03:386ff
*** Brandeis Dice
the original in Jaynes, E. T. (1963), Information theory and
statistical mechanics. In 1962 Brandeis Summer Institute in
Theoretical Physics, ed. K. Ford. New York: Benjamin. Reprinted in
Jaynes (1983).

jaynes78:243 
uffink95:26
williams80:132
*** Courtney's bottle factory
to illustrate overdetermined problems see paris04:128f
*** Jaynes' monkeys
jaynesbretthorst03:160
*** Jeffrey's Horse Race
jaynesbretthorst03:140
*** Kate and Henry
douvenromeijn09:12 -- there may be a better example in Leendert's
article
/media/stefan/SONY_32X1/articles-2014/various/2015__Leendert_Huisman__Learning_Simple_Indicative_Conditionals.pdf
on page 37
*** Sleeping Beauty
bovens10
*** sundowners at the Westcliff
douvenromeijn09:7
*** there is a list in halpern03:1ff
*** von Mises: water and wine
jaynes73:10 (overdetermined, not underdetermined, see also jaynesbretthorst03:392)
mikkelson04
gillies00:43
** two epistemological dimensions
lots about this in maher93, moss13, jeffrey70, and spohn12

joyce98:576 traditional epistemology considers full belief to tbe
fundamental doxastic attitude and partial beliefs subsidiary -- part
of the problem is that formal epistemologists justify partial beliefs
pragmatically and not epistemically
** type I vs. type II priors
"forever anterior, never original" (Roland Barthes, The Death of the
Author, p. 4)
** Uffink
uffink95
uffink96
** unconditional probs based on conditional probs
hajek03:273 (``Conditional probability should be taken as the primitive notion, and unconditional probability should be analyzed in terms of it.'')
keynes09:ch1 (see prospectus)
hajek03:315 (``given an unconditional probability, there is always a corresponding conditional probability lurking in the background.'')
hajek03:315 (``Unconditional probabilities are special cases of conditional probabilities'')
hajek03:315 (``regard conditional probability to be the primitive notion, and unconditional probability as the derivative notion'', with a list of supporters)
and a list of ``axiomatization[s] of conditional probability'' in hajek03:316
** Watts assumption
paris04:67
** Wolfman versus Dracula (acceptance versus partial belief, two epistemological dimensions)
earman92:33
kyburg95:343
spohn12:201
spohn12:46
jeffrey70:183
jeffrey70:171f
morton99:507
* quotes
** neapolitanchiang14: Neapolitan and Jiang: A Note of Caution on Maximizing Entropy
**** Zabell (ref) shows that if we make certain reasonable
assumptions about an individual's beliefs concerning the probabilities
of the outcomes of an experiment, then that individual's beliefs about
those probabilities must be represented by a Dirichlet distribution of
the probability values. (Neapolitan and Jiang: A Note of Caution on
Maximizing Entropy, 4010)
**** the maximum entropy solution does not agree 
with the Bayesian solution if we consider all outcomes satisfying the
mean value constraint equally probable (Neapolitan and Jiang: A Note
of Caution on Maximizing Entropy, 4012)
**** In general, there is no answer to the question 
just posed. Rather a way out of this conundrum is to carefully analyze
each situation and adopt the strategy that seems most applicable, as
suggested by Seidenfield (ref, quoted directly) (Neapolitan and Jiang:
A Note of Caution on Maximizing Entropy, 4012)
** weatherson12: Weatherson, Brian: Knowledge, Bets and Interests
**** The working assumption of my project on interest-relativity
has been that talking about beliefs and talking about credences are
simply two ways of modelling the very same things, namely minds. If
the agent both has a credence 0.99 in p, and believes that p, these
are not two different states. Rather, there is one state of the agent,
and two different ways of modelling it. So it is implausible, if not
incoherent, to apply different valuations to the state depending on
which modelling tools we choose to use. That is, it's implausible to
say that while we're modelling the agent with credences, the state is
rational, but when we change tools, and start using beliefs, the state
is irrational. (Weatherson, Brian: Knowledge, Bets and Interests, 19)
** levinstein12: Levinstein, Benjamin: Leitgeb and Pettigrew on Accuracy and Updating
**** We take the average square of the Euclidean distance 
instead of just the Euclidean distance to guarantee that all
probability functions assign themselves lowest expected inaccuracy. I
thank a referee for catching earlier sloppiness about this point.
(Levinstein, Benjamin: Leitgeb and Pettigrew on Accuracy and
Updating, 414)
** kaplan10 Kaplan, Mark: In Defense of Modest Probabilism
**** Orthodox Probabilists hold that an inquirer 
ought to harbor a precise degree of confidence in each hypothesis
about which she is concerned. Modest Probabilism is one of a family
[of] doctrines inspired by the thought that Orthodox Probabilists are
thereby demanding that an inquirer effect a precision that is often
unwarranted by her evidence. (Kaplan, Mark: In Defense of Modest
Probabilism, 41)
**** Orthodox Bayesian Probabilism 
It is a condition on your holding a cogent state of opinion that (i)
you harbor a precise degree of confidence in the truth of each
proposition, and (ii) if you harbor a precise degree of confidence
assignment to a set of propositions then that assignment satisfies the
axioms of the probability calculus. (Kaplan, Mark: In Defense of
Modest Probabilism, 43)
**** I do not mean, in saying it is a consistency 
constraint, that the violation of this constraint somehow commits the
violator to a set of claims that cannot all be true. Rather, I mean
that the constraint is formal in the same way logical consistency is.
Take a set of sentences in a formal language where the set is closed
under truth-functional operations. Just as the consistency of any
subset of that set can be determined without regard to the actual
truth-values of the non-logical components of the sentences, so it can
be determined whether a degree of confidence assignment to any subset
of the set satisfies the probability calculus without regard to the
actual truth-values of the non-logical components of the sentences.
(Kaplan, Mark: In Defense of Modest Probabilism, 43, fn 5)
**** Consider the two cases we considered earlier, and how the 
difference between them bears on the question as to how confident you
should be that (B) the ball drawn will be black. In the first case, it
is clear why you should have a degree of confidence equal to 0.5 that
ball drawn from the urn will be black. Your evidence tells you that
there is an objective probability of 0.5 that the ball will be black:
it rules every other assignment out either as too low or as too high.
In the second case, however, you do not know the objective probability
that the ball will be black, because you don't know exactly how many
of the balls in the urn are black. Your evidence thus much inferior in
quality to the evidence you have in the first case ---doesn't rule out
all the assignments your evidence in the first case does. It rules
out, as less warrante d than the rest, every assignment that gives B a
value <0.3, and every assignment that gives B a value >0.65. But none
of the remaining assignments can reasonably thought to be any more
warranted, or less warranted, by your evidence than any other. But
then it would seem, at least at first blush, an exercise in
unwarranted precision to accede to the requirement, issued by Orthodox
Bayesian Probabilism, that you choose one of those assignments to be
your own. (Kaplan, Mark: In Defense of Modest Probabilism, 43f)
[villainy]
** landeswilliamson13 Landes, J{\"u}rgen and Williamson, Jon: Objective Bayesianism and the Maximum Entropy Principle
**** we seek a single justification of the three norms
of objective Bayesian epistemology [unified justification for three
norms at once: probability norm, calibration norm, and equivocation
norm] (Landes, J{\"u}rgen and Williamson, Jon: Objective Bayesianism
and the Maximum Entropy Principle, 3530)
**** only a logarithmic loss function satisfies certain 
desiderata that ... any default loss function should satisfy (Landes,
J{\"u}rgen and Williamson, Jon: Objective Bayesianism and the Maximum
Entropy Principle, 3530f)
**** g-entropy is a natural generalization of standard
entropy from probability functions to belief functions ... g-entropy
corresponds to minimizing worst-case expected loss ... Shannon's
argument can be adapted to give a justification of our generalized
entropy measure (Landes, J{\"u}rgen and Williamson, Jon: Objective
Bayesianism and the Maximum Entropy Principle, 3535)
** palmiericiuonzo13 Palmieri and Ciuonzo: Objective Priors from Maximum Entropy in Data Classification
**** We question whether remaining in the realm 
of classical probability and information theory (Cover and Thomas) we
can resolve some of the apparent difficulties in dealing with model
uncertainties. We find that in most cases if we fill our lack of
knowledge following the maximum entropy (ME) principle, all the
contradictions seem resolved indicating that the problems that may
have arisen are just the consequences of arbitrary implicit
assumptions. (Palmieri and Ciuonzo: Objective Priors from Maximum
Entropy in Data Classification, 1)
**** These experiences motivated our investigations 
on the method because the maximum entropy priors showed striking
results in providing good common sense answers where Bayes' rule with
uniform priors was claimed to be inadequate. (Palmieri and Ciuonzo:
Objective Priors from Maximum Entropy in Data Classification, 2)
** debbahmueller05 Debbah and Mueller: MIMO Channel Modeling and the Principle of Maximum Entropy
**** This problem can be answered in light of 
Bayesian probability theory. Bayesian probability theory has led to a
profound theoretical understanding of various scientific areas
[citations] and has shown the potential of entropy as a measure of our
degree of knowledge when encountering a new problem. The principle of
maximum entropy provides a theoretical justification in conducting
scientific inference: we do not need a model, entropy maximization
creates a model for us out of the information available [citations].
Choosing the distribution with greatest entropy avoids the arbitrary
introduction or assumption of information that is not available.
(Debbah and Mueller: MIMO Channel Modeling and the Principle of
Maximum Entropy, 1668)
**** this assumption implies independent entries since the 
joint probability distribution P(H) simplifies into products of
P(h_ij). Therefore, based on the previous state of knowledge, the only
maximizer of the entropy is the i.i.d. one. This does not mean that we
have supposed independence in the model. (Debbah and Mueller: MIMO
Channel Modeling and the Principle of Maximum Entropy, 1670)
**** Although correlation might exist between the 
scatterers, the modeler is not aware of that fact. Based on this state
of knowledge, the modeler wants to derive a model which takes into
account all the previous constraints while leaving as many degrees of
freedom as possible to the other parameters to avoid the introduction
of unjustified information. (Debbah and Mueller: MIMO Channel Modeling
and the Principle of Maximum Entropy, 1672)
**** incorporating information in the entropy criteria 
which is not given in terms of expected values is not an easy task
(Debbah and Mueller: MIMO Channel Modeling and the Principle of
Maximum Entropy, 1673)
**** One interesting point of the maximum-entropy approach 
is that while we have not assumed uncorrelated scattering, the above
methodology will automatically assign a model with uncorrelated
scatterers in order to have as many degrees of freedom as possible.
But this does not mean that correlation is not taken into account. The
model in fact leaves free degrees for correlation to exist or not.
(Debbah and Mueller: MIMO Channel Modeling and the Principle of
Maximum Entropy, 1674)
**** One of the great features of the maximum entropy approach 
is the simplicity of translating any additional physical information
into probability assignment in the model. A one-to-one mapping between
information and model representation is possible. (Debbah and Mueller:
MIMO Channel Modeling and the Principle of Maximum Entropy, 1684)
**** Transition 1: the modeler creates a model 
maximizing entropy. Transition 2: the modeler mis-estimates the real
achievable rate because even though the created model is the best
possible, based on the state of knowledge, it derives the mutual
information of the channel based on the assumption that the model is
reality. Transition 3: a new measure of the information rate should be
derived based only on our state of knowledge, taking into account the
fact that the model does not represent reality, but only our knowledge
(which is scarce) of reality. [this may map onto the mistake that
Booleans are making] (Debbah and Mueller: MIMO Channel Modeling and
the Principle of Maximum Entropy, 1685)
**** With the maximum entropy approach, we derive 
a channel model having as much degrees of freedom as possible (but
still with the constraints of our state of knowledge) in order to cope
with all the cases when they happen. We do this because we need a
unique model consistent with our state of knowledge. Any other
approach will add unjustified constraints. (Debbah and Mueller: MIMO
Channel Modeling and the Principle of Maximum Entropy, 1685f)
** walley91 Peter Walley: Statistical Reasoning with Imprecise Probabilities
**** None of the arguments for the PME, when regarded 
as a general method for generating precise probabilities, is at all
compelling. We accept that the PME can be a useful method of
generating aleatory hypotheses. (Peter Walley: Statistical Reasoning
with Imprecise Probabilities, 271)
** white10 Roger White: Evidential Symmetry and Mushy Credence
**** principle of indifference
[in my words] (i) match confidence to symmetry (ii) even distribution
[I find (i) more defensible than (ii), especially if viewed in terms
of information; in the continuous case, for example, assigning higher
probabilities to some intervals may not be even-handed, but optimal in
terms of information] (Roger White: Evidential Symmetry and Mushy
Credence, 161)
** moss13 Sarah Moss: Epistemology Formalized
**** the semantic value of a sentence is a set of 
probability measures, and an assertion expresses the advice that your
credence distribution be among the members of that set. [with
examples] (Sarah Moss: Epistemology Formalized, 4)
**** It is notoriously difficult to defend general procedures for directly
updating credences on constraints. [footnote: For further
discussion, see Diaconis and Zabell 1982 , Jaynes 1978 , Skyrms 1987 ,
Joyce 1999 , and Grünwald and Halpern 2003 .] (Sarah Moss:
Epistemology Formalized, 7)
** levi81 Isaac Levi: Direct Inference and Confirmational Conditionalization
**** The early Carap and other strict Bayesians think that credal states
for ideally rational agents ought to be representable by single
conditional probability measures relative to the appropriate corpora
of knowledge. (Isaac Levi: Direct Inference and Confirmational
Conditionalization, 533)
**** My view of confirmational commitments deviates from the 
Jeffrey-Carnap approach in still one other respect. Like Keynes,
Koopman, Ky- burg, Good and Smith, I avoid assuming that a credal
state B is repre- sentable by a unique probability function.
Probability judgment may go indeterminate. Indeed, it may go so
indeterminate as to preclude a weak ordering of propositions with
respect to probability (Isaac Levi: Direct Inference and
Confirmational Conditionalization, 533)
**** direct inference derives credal probability from knowledge of the
chances of possible outcomes occurring on trials of a certain kind on
a given chance set-up together with information about the trial
occurring on a specific occasion. (Isaac Levi: Direct Inference and
Confirmational Conditionalization, 540)
** levi85 Isaac Levi: Imprecision and Indeterminacy in Probability Judgment
**** Some who deny that states of probability 
judgment ("credal states" as I shall call them) are numerically
definite have sought to represent them in terms of a relation of
comparative probability. Others use functions assigning upper and
lower probabilities (or, alternatively, interval-valued probabilities)
to hypotheses. Still others represent credal states by means of sets
of probability functions defined for the relevant algebras of
propositions or events. (Isaac Levi: Imprecision and Indeterminacy in
Probability Judgment, 390)
**** The set of distributions represents a set of 
rival hy- potheses about the unknown contents of the black box. (Isaac
Levi: Imprecision and Indeterminacy in Probability Judgment, 391)
**** rational agents often do not and should not regard exactly one
real-valued probability function to be permissible for use in
assessing expected utilities. The credal state should be repre- sented
by a set of permissible probability functions. (Isaac Levi:
Imprecision and Indeterminacy in Probability Judgment, 392)
**** a set of probability functions can be used to characterize the credal
state as a set of permissible probability distributions and not as a
set of possibly true hypotheses concerning the unknown uniquely
permissible distribution. (Isaac Levi: Imprecision and Indeterminacy
in Probability Judgment, 392)
**** distinction between black box construals of sets of distributions and
permissibility construals (Isaac Levi: Imprecision and Indeterminacy
in Probability Judgment, 392)
**** the ample bosom of Mother Bayes
(Isaac Levi: Imprecision and Indeterminacy in Probability
Judgment, 392)
**** Here I am supposing, as all these authors have, that refusal 
to make a deter- minate probability judgment does not derive from a
lack of clarity about one's credal state. To the contrary, it may
derive from a very clear and cool judgment that on the basis of the
available evidence, making a nu- merically determinate judgment would
be unwarranted and arbitrary. (Isaac Levi: Imprecision and
Indeterminacy in Probability Judgment, 396)
**** Both strict Bayesians and their critics can agree 
about this. Even if magnitudes have precise values, measurement aimed
at determining these values is always liable to imprecisions of var-
ious sorts. [but probs do NOT measure a magnitude, they represent
uncertainty] (Isaac Levi: Imprecision and Indeterminacy in Probability
Judgment, 407)
** williamson10 Jon Williamson: An Objective Bayesian Account of Confirmation
**** an objective Bayesian conﬁrmation theory that can capture both partial
entailment and learning from experience (Jon Williamson: An Objective
Bayesian Account of Confirmation, 2)
**** For Carnap, as for Keynes (1921) before him, this notion of
probability is fundamentally a logical relation between a body of
evidence and a proposition. It is clear that Carnap viewed this
relation as objective, not as an expression of subjective degree of
belief. (Jon Williamson: An Objective Bayesian Account of
Confirmation, 2)
**** The characterization of logic in terms of correct or rational or
justiﬁed belief is just as right but not more enlightening than to say
that mineralogy tells us how to think correctly about minerals. (Jon
Williamson: An Objective Bayesian Account of Confirmation, 2)
**** we are left with the equivocator as the only viable
candidate {\ldots} the equivocator [$c_\infty}$ in Carnap's notation]
is the only function able to capture partial entailment (Jon
Williamson: An Objective Bayesian Account of Confirmation, 11)
**** on the one hand, the equivocator seems to preclude learning by
experience, and so fails to capture the concept of inductive
plausibility, while on the other, the equivocator seems to be required
to capture the concept of partial entailment (Jon Williamson: An
Objective Bayesian Account of Confirmation, 12)
**** objective Bayesian epistemology. The reader is referred 
to Williamson (2010b) for the details of this particular version of
Bayesian epistemology. (Jon Williamson: An Objective Bayesian Account
of Confirmation, 14)
**** [for Williamson's solution and the use of statistical 
theory, see also my handwritten notes] (Jon Williamson: An Objective
Bayesian Account of Confirmation, 18ff)
** rott01 Hans Rott: Change, Choice and Inference
**** William James holds that ``Truth lives, in fact, for the most 
part on a credit system. Our thoughts and beliefs `pass,' so long as
nothing challenges them, just as bank notes pass so long as nobody
refuses them.'' [compare also Thomas Reid on the preceding page] (Hans
Rott: Change, Choice and Inference, 27)
**** [G"ardenfors's] criterion of Informational Economy: ``The key 
idea is that, when we change our beliefs, we want to retain as much as
possible of our old beliefs---information is in general not
gratuitous, and unnecessary losses of information are therefore to be
avoided.'' [G"ardenfors] (Hans Rott: Change, Choice and Inference, 73)
** kaplan96 Mark Kaplan: Decision Theory as Philosophy
**** What sets the Bayesian approach to epistemology 
apart from the rest is that its proponents look in a different place.
They look for rules for the direction of the mind in the theory of
rational preference -- in decision theory. (Mark Kaplan: Decision
Theory as Philosophy, ix)
** floridi11 Luciano Floridi: The Philosophy of Information
**** [list of what information could mean: (1) Shannon/Weaver; (2) Kolmogorov
complexity; (3) probabilistic approach to semantic information a la
Carnap/Bar Hillel; (4) modal approach; (5) systemic approach by
Barwise/Perry; (6) inferential approach; (7) semantic approach by
Floridi (Luciano Floridi: The Philosophy of Information, 31)
** schlesinger91 G.N. Schlesinger: The Sweep of Probability
**** celebrated debates in the history of the American
Philosophical Association took place in 1952 between ... C.I. Lewis
and Hans Reichenbach ... Lewis argued that if a statement can be
established only as probable then it must have a ground [which itself
cannot be only probable] ``nothing is probable unless something is
certain '' [Lewis] (G.N. Schlesinger: The Sweep of Probability, 39)
**** [three prisoners] c = C has been pardoned, g = the guard 
says B has not been pardoned. (G.N. Schlesinger: The Sweep of
Probability, 9)
** wagner02 Carl Wagner: Probability Kinematics and Commutativity
**** [for literature on non-commutativity see
wagner02:266 and leitgebpettigrew10ii:258 and 259]
**** sequential probability kinematics: all is cool
(wagner02 Carl Wagner: Probability Kinematics and Commutativity, 274)
** zabell88 Sandy L. Zabell: Symmetry and Its Discontents
**** [Donkin] absolute in the sense of not being relative 
to any individual mind; since, the same information being presupposed,
all minds ought to distribute their belief in the same way. (zabell88
Sandy L. Zabell: Symmetry and Its Discontents, 23)
**** such theories [logical probability] have never really answered Ramsey's
simple criticism: ``It is true that about some particular cases there
is agreement, but these somehow paradoxically are always immensely
complicated; we all agree that the probability of a coin coming down
heads is 1/2 , but we can none of us say exactly what is the evidence
which forms the other term for the probability relation about which we
are then judging. If, on the other hand, we take the simplest possible
pairs of propositions such as 'This is red' and 'That is blue' or
'This is red' and 'That is red', whose logical relations should surely
be easiest to see, no one, I think, pretends to be sure what is the
probability relation [between them, Zabell's quote] [which connects
them, actual quote?]. (zabell88 Sandy L. Zabell: Symmetry and Its
Discontents, 25)
** teller75 Teller, Paul: Shimony's A Prior Arguments for Tempered Personalism
**** If it would be possible to find justifiable constraints 
on a prior probability function sufficient to define it completely,
all changes in rational belief could henceforth be described by
conditionalization on new observations, In other words, the initial
constraints would once and for all determine confirmation relations
between any possible hypothesis and any possible observations. Many
personalists differ from Carnap in this respect also. They recommend
their doctrine only for use in restricted, relatively well-defined
situations in which an agent is confronted with a practical
decision-making problem in face of uncertainty (cf. Savage, 1954, pp.
16, 82—91; 1967a, pp. 306—7). (Teller, Paul: Shimony's A Prior
Arguments for Tempered Personalism, 169)
**** it is surely overoptimistic to suppose that men 
could, following Carnap's prescription, once and for all settle on a
perfectly general prior probability function which henceforth need
only change by conditionalization. (Footnote: In fact Putnam has
proved that there cannot be such a function. See Putnam (1963).)
(Teller, Paul: Shimony's A Prior Arguments for Tempered
Personalism, 173)
**** Shimony holds that ``the axioms of probability are
necessary conditions for orderly thinking about propositions with
unknown truth values'' (1970, p. 158). He supports this claim with an
ingenious combination of the Cox-Cood argument and the Dutch book
argument which avoids many of the shortcomings of each and makes it
possible to derive the probability axioms from exceedingly weak
assumptions (1970, pp. 104-9). (Teller, Paul: Shimony's A Prior
Arguments for Tempered Personalism, 186f)
**** 
** zellner88 Zellner, Arnold: Optimal Information Processing and Bayes's Theorem
*** Bayes' theorem has been widely used as an inductive learning model
to transform prior and sample information into posteriro
information. (nice wording, zellner88:278)
*** Information Conservation Principle
[the ``simple'' idea] see full formulation zellner88:278
*** No information is lost and no extraneous information is
introduced by use of the Bayesian IPR (zellner88:279)
** jaynes88 Jaynes, E.T.: Optimal Information Processing and Bayes's Theorem: Comment
*** An acceptable inference procedure should have the property
that it neither ignores any of the input information nor injects
any false information. (jaynes88:280)
*** Cox's desiderata appeared to be more 
elementary---therefore, more compelling logically--- than the
weill-known arguments of de Finetti, Jeffreys, and L.J. Savage.
(jaynes88:280)
** Stephens Epistemology
*** 1684__Gottfried_Wilhelm_Leibniz__Meditations_on_Knowledge_Truth_and_Ideas
******* Another kind of example: I have dim notions when I think about some 
term for which there is no settled definition---such as Aristotle's
entelechy, or his notion of cause when offered as something that is
common to material, formal, efficient, and final causes.
*** 1945__Hempel_Oppenheim__A_Definition_of_Degree_of_Confirmation
******* The preceding remarks, however, are meant only 
as accounts of methodological tendencies and are not intended to imply
the existence of clear-cut criteria ·by means of which the scientist
can decide whether---or, in quantitative terms, to what degree---a
given hypothesis is confirmed by certain data. For indeed, no general
and objective criteria of this kind are at present available; in other
words, no general definition of the concept of confirmation has been
developed so far. This is a remarkable fact in view of the importance
of the concept concerned, and the question naturally suggests itself
whether it is at all possible to set up adequate general criteria of
confirmation, or whether it may not rather be necessary to leave the
decision in matters of confirnlation to the intuitive appraisal of the
scientist. {\parag} This latter alternative would be highly
unsatisfactory; for firstly, it would clearly jeopardize the
objectivity-in the sense of intersubjectivity-of scientific procedure.
Secondly, it would run counter to a view of confirmation which is now
widely accepted; according to this view, statements about confirmation
assert nothing regarding an observer's subjective appraisal of the
soundness of a hypothesis; rather, they concern a certain objective
relation between a hypothesis and the empirical evidence with which it
is confronted; this relation depends exclusively on the content of the
hypothesis and of the evidence, and it is of a purely logical
character in the sense that once a hypothesis and a description of
certain observational findings are given, no further empirical
investigation is needed to determine whether, or to what degree, the
evidence confirms the hypothesis; the decision is a matter exclusively
of certain logical criteria vvhich form the subject matter of a formal
discipline which might be called inductive logic.
((1945__Hempel_Oppenheim__A_Definition_of_Degree_of_Confirmation, 98)
******* An alternative to this approach would be to 
determine, by means of Bayes' theorem, that distribution upon which E
confers the greatest probability (in contradistinction to our question
for that distribution which confers upon E the maximum probability);
but this approach presupposes-to state it first by reference to the
urn analogue-an infinity of urns, each with a different frequency
distribution; and to each urn U, there would have to be assigned a
definite a priori probability for the sample to be taken from U.
Applied to our problem, this method would involve reference to an
infinity of possible states of the world, to each of which there would
have to be attached a certain a priori probability of being realized;
and for such a "lottery of states of the world,'~ as it were, it seems
very difficult to find an empiricist interpretation.
(1945__Hempel_Oppenheim__A_Definition_of_Degree_of_Confirmation, 107)
******* In view of the fact that dc as defined above does not satisfy 
all of the postulates of probabilitytheory, we prefer not to call dc
a probability.
(1945__Hempel_Oppenheim__A_Definition_of_Degree_of_Confirmation, 112)
******* The theory obtained by our procedure provides criteria 
which establish, so to speak, a fair rate of betting on a specified
hypothesis on the basis of given data. (In many cases, as we saw, dc
will be single-valued and the betting rate will therefore be uniquely
determined; in other cases, where the evidence is insufficient in a
certain sense, dc will have several values, and then, the smallest of
these might be used to establish a betting rate.) The decisions,
however, which a gambler has to make concern not only the betting rate
but also the amount he is going to risk; and while the rate is
determined, generally speaking, by the relative frequency in the past
of the event on which he wishes to bet, the gambler's stake will be
determined by different factors, such as, e.g., the size of the sample
which represents the evidence. Analogously, the concept of degree of
confirmation as it has been defined in the present article, refers
only to one among several factors which enter into an objective
appraisal of the soundness or reliability of an empirical hypothesis.
The remaining factors include, among others, the number of tested
instances which are mentioned in E, and the variety of those
instances.
(1945__Hempel_Oppenheim__A_Definition_of_Degree_of_Confirmation, 114)
*** 1959__Karl_Popper__The_Logic_of_Scientific_Discovery
**** Chapter 1
******* [Reichenbach] science decides upon truth. To be more exact, we should say 
that it serves to decide upon probability {\ldots} but scientific
statements can only attain continuous degrees of probability whose
unattainable upper and lower limits are truth and falsity
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 6)
******* The theory to be developed in the following pages 
stands directly opposed to all attempts to operate with the ideas of
inductive logic. It might be described as the theory of the deductive
method of testing, or as the view that a hypothesis can only be
empirically tested---and only after it has been advanced.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 6) [see
Derrida's indeterminacy in Plato's Pharmacy]
******* I never assume that by force of
verified conclusions, theories can be established as true, or even as
merely probable.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 10)
******* it may be said, I deprive empirical science of
what appears to be its most important characteristic; and this means
that I remove the barriers which separate science from metaphysical
speculation. My reply to this objection is that my main reason for
rejecting inductive logic is precisely that it does not provide a
suitable distinguishing mark of the empirical, non-metaphysical,
character of a theoretical system; or in other words, that it does
not provide a suitable criterion of demarcation.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 11)
******* Positivists usually interpret the problem of demarcation 
in a naturalistic way; they interpret it as if it were a problem of
natural science. Instead of taking it as their task to propose a
suitable convention, they believe they have to discover a difference,
existing in the nature of things, as it were, between empirical
science on the one hand and metaphysics on the other. They are
constantly trying to prove that metaphysics by its very nature is
nothing but nonsensical twaddle---`sophistry and illusion,' as Hume
says, which we should `commit to the flames.' {\ldots} My criterion of
demarcation will accordingly have to be regarded as a proposal for an
agreement or convention.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 12, after ldots
15)
******* in arriving at my proposals I have been guided, in the 
last analysis, by value judgments and predilections. But I hope that
my proposals may be acceptable to those who value not only logical
rigour but also freedom from dogmatism; who seek practical
applicability, but are even more attracted by the adventure of
science, and by discoveries which again and again confront us with new
and unexpected questions, challenging us to try out new and hitherto
undreamed-of answers. [contra Bayes] [``every discovery contains `an
irrational element,' or `a creative intuition', in Bergson's sense''
(8)] (1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 15) [see
also ``unfortunately there seems to be no such thing as `the language
of science.' It therefore becomes necessary for them to construct one.
However, the construction of a full-scale working model of a language
of science---one in which we could operate a real science such as
physics---turns out a little difficult in practice; and for this
reason we find them engaged in the construction of intricate working
models in miniature---of vast systems of minute gadgets. In my
opinion, this group of philosophers gets the worst of both worlds. By
their method of constructing miniature model languages they miss the
most exciting problems of the theory of knowledge---those connected
with its advancement. For the intricacy of the outfit bears no
relation to its effectiveness, and practically no scientific theory of
any interest can be expressed in these vast systems of minutiae. These
model languages have no bearing on either science or common sense.''
(Karl Popper, The Logic of Scientific Discovery, xxiv)]
******* scientific discovery is impossible without faith in ideas 
which are of a purely speculative kind, and sometimes even quite hazy;
a faith which is completely unwarranted from the point of view of
science, and which, to that extent, is `metaphysical.' [see Einstein,
Die Religiosit"at der Forschung, and Nietzsche] [see also (278) ``We do
not know: we can only guess. And our guesses are guided by the
unscientific, the metaphysical (though biologically explicable) faith
in laws, in regularities which we can uncover---discover. Like Bacon, we
might describe our own contemporary science---‘the method of reasoning
which men now ordinarily apply to nature'---as consisting of
`anticipations, rash and premature' and of `prejudices'.]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 16)
******* not the verifiability but the falsifiability of a system 
is to be taken as a criterion of demarcation. [against Waismann, for
whom ``the meaning of a statement is the method of its verification''
(17)] [This may be a problem for Maher: that his criterion of
demarcation is quantifiability. Here is what scientific confirmation
must fulfill. C fulfills it. Therefore, quantifiability is a criterion
of demarcation. But: what if C' fulfills it as well? (Hempel, Carnap.)
What if an additional requirement for scientific confirmation is that
it gets demarcation right?]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 18)
******* argue from the truth of singular statements to the falsity of
universal statements. Such an argument to the falsity of universal
statements is the only strictly deductive kind of inference that
proceeds, as it were, in the `inductive direction'; that is, from
singular to universal statements. [Falsifiers and falsifiees. Theories
and basic statements. Is Evolution a falsifiee or a falsifier? Of
what? Is the distinction sustainable? See my comment on (3) and
Popper's rain example on (19)]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 19)
******* A third objection may seem more serious. It might be said 
that even if the asymmetry is admitted, it is still impossible, for
various reasons, that any theoretical system should ever be
conclusively falsified. For it is always possible to find some way of
evading falsification, for example by introducing ad hoc an auxiliary
hypothesis, or by changing ad hoc a definition. It is even possible
without logical inconsistency to adopt the position of simply refusing
to acknowledge any falsifying experience whatsoever. Admittedly,
scientists do not usually proceed in this way, but logically such
procedure is possible; and this fact, it might be claimed, makes the
logical value of my proposed criterion of demarcation dubious, to say
the least. {\parag} I must admit the justice of this criticism; but I
need not therefore withdraw my proposal to adopt falsifiability as a
criterion of demarcation. For I am going to propose (in sections 20
f.) that the empirical method shall be characterized as a method that
excludes precisely those ways of evading falsification which, as my
imaginary critic rightly insists, are logically possible. According to
my proposal, what characterizes the empirical method is its manner
of exposing to falsification, in every conceivable way, the system to
be tested. Its aim is not to save the lives of untenable systems but,
on the contrary, to select the one which is by comparison the fittest,
by exposing them all to the fiercest struggle for survival.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 20)
******* any controversy over the question whether events 
which are in principle unrepeatable and unique ever do occur cannot be
decided by science: it would be a metaphysical controversy.
[Evolution, Big Bang, history; it seems, on the other hand, that
posing the existence of the devil and of guardian angels is
scientific, as those are inter-subjectively testable, see (22)]
[confirmed here: ``I do not believe in hampering scientific language
by preventing the scientist from using freely, whenever it is conveni-
ent, new ideas, predicates, `occult' concepts, or anything else.''
(392)] (1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 24)
**** Chapter 10
******* in my view, the whole problem of the probability 
of hypotheses is misconceived. Instead of discussing the `probability'
of a hypothesis we should try to assess what tests, what trials, it
has withstood; that is, we should try to assess how far it has been
able to prove its fitness to survive by standing up to tests. [Bayes
does this, except in quantitative terms, attending precisely to the
three factors that we need: deductive association of E and H,
corroboration so far (P(H)), and the rigour of the test (P(E))]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 248)
******* One attempt to replace metaphysical statements of this kind 
by principles of method leads to the `principle of induction',
supposed to govern the method of induction, and hence that of the
verification of theories. But this attempt fails, for the principle of
induction is itself metaphysical in character.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 251)
******* if we try to turn our metaphysical faith in the uniformity 
of nature and in the verifiability of theories into a theory of
knowledge based on inductive logic, we are left only with the choice
between an infinite regress and apriorism.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 252)
******* if one says of a hypothesis that it is not true but 
`probable', then this statement can under no circumstances be
translated into a statement about the probability of events. For if
one attempts to reduce the idea of a probability of hypotheses to that
of a truth-frequency which uses the concept of a sequence of
statements, then one is at once confronted with the question: with
reference to what sequence of statements can a probability value be
assigned to a hypothesis? [Popper here (55) assumes that, based on
Reichenbach, the assignment of a probability must be based on
knowledge (of test outcomes). Bayesians originally base their
probabilities on ignorance, entropy. People (Haack, Seidenfeld) make
the mistake to think that P(X)=.5 contains a lot of information.]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 254f)
******* we have to regard the attempt to identify the probability 
of a hypothesis with the probability of events as a complete failure.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 258f)
******* The probability of hypotheses cannot be reduced to 
the probability of events. This is the conclusion which emerges from
the examination carried out in the previous section. But might not a
different approach lead to a satisfactory definition of the idea of a
probability of hypotheses? [subjectivists]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 261)
******* An appraisal must, of course, be a synthetic 
statement---an assertion about `reality'---in the same way as would be
the statement `Schrödinger's theory is true' or `Schrödinger's theory
is false'. All such statements obviously say something about the
adequacy of the theory, and are thus certainly not tautological. They
say that a theory is adequate or inadequate, or that it is adequate in
some degree. Further, an appraisal of Schrödinger's theory must be a
non-verifiable synthetic statement, just like the theory itself. For
the `probability' of a theory---that is, the probability that the theory
will remain acceptable---cannot, it appears, be deduced from basic
statements with finality. Therefore we are forced to ask: How can the
appraisal be justified? How can it be tested? (Thus the problem of
induction arises again) [contra subjectivists, appraisal of the
appraisal -> infinite regress (263)]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 262)
******* nothing is gained by replacing the
word `true' by the word `probable', and the word `false' by the word
`improbable'. Only if the asymmetry between verification and
falsification is taken into account---that asymmetry which results
from the logical relation between theories and basic statements---is
it possible to avoid the pitfalls of the problem of induction
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 263)
******* This shows that it is not so much the number 
of corroborating instances which determines the degree of
corroboration as the severity of the various tests to which the
hypothesis in question can be, and has been, subjected.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 266)
******* The degree of corroboration of two statements may not be 
comparable in all cases [see Salmon], any more than the degree of
falsifiability: we cannot define a numerically calculable degree of
corroboration, but can speak only roughly in terms of positive degree
of corroboration, negative degrees of corroboration, and so forth.
[Popper remarked on this later: As far as practical application to
existing theories goes, this seems to me still correct; but I think
now that it is possible to define `degree of corroboration' in such a
way that we can compare degrees of corroboration (for example, those
of Newton's and of Einstein's theory of gravity). Moreover, this
definition makes it even possible to attribute numerical degrees of
corroboration to statistical hypotheses, and perhaps even to other
statements provided we can attribute degrees of (absolute and
relative) logical probability to them and to the evidence statements.
Footnote 266f.]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 266)
******* [Logical probability: degree to which a theory is synthetic 
ie. a theory about the eigenheit of the world as opposed to other
logically possible worlds]
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 268)
******* Science is not a system of certain, or 
well-established, statements; nor is it a system which steadily
advances towards a state of finality. Our science is not knowledge
(episteme): it can never claim to have attained truth, or even a
substitute for it, such as probability.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 278) [see also
(280) ``The old scientific ideal of episteme---of absolutely certain,
demonstrable knowledge---has proved to be an idol.'']
******* myth of a scientific method that starts from observation 
and experiment and then proceeds to theories.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 279)
******* Bold ideas, unjustified anticipations, and speculative 
thought, are our only means for interpreting nature: our only
organon, our only instrument, for grasping her. And we must hazard
them to win our prize. Those among us who are unwilling to expose
their ideas to the hazard of refutation do not take part in the
scientific game.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 280)
******* And it is further asserted that degree of corroboration 
cannot be a probability, because it cannot satisfy the laws of the
probability calculus. For the laws of the probability calculus demand
that, of two hypotheses, the one that is logically stronger, or more
informative, or better testable, and thus the one which can be better
corroborated, is always less probable---on any given evidence---than the
other. (See especially sections 82 and 83.) {\parag} Thus a higher
degree of corroboration will, in general, be combined with a lower
degree of probability; which shows not only that we must distinguish
sharply between probability (in the sense of the probability calculus)
and degree of corroboration or confirmation, but also that the
probabilistic theory of induction, or the idea of an inductive
probability, is untenable.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 374)
******* Nothing depends here on `infinity', for any sufficiently 
large universe will yield, with any desired degree of approximation,
the same result; and we know that our universe is extremely large,
compared with the amount of evidence available to us.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 376)
******* Empirical knowledge in some sense of the word 
`knowledge', exists. But in other senses---for example in the sense of
certain knowledge, or of demonstrable knowledge---it does not. And we
must not assume, uncritically, that we have `probable' knowledge–
knowledge that is probable in the sense of the calculus of
probability. It is indeed my contention that we do not have probable
knowledge in this sense. For I believe that what we may call
`empirical knowledge', including `scientific knowledge', consists of
guesses, and that many of these guesses are not probable (or have a
probability zero) even though they may be very well corroborated.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 381)
******* A solution of this last problem was needed because I soon 
found that, in order to define C(x,y)---the degree of corroboration of
the theory x by the evidence y---I had to operate with some converse
p(y,x), called by Fisher the `likelihood of x' (in the light of the
evidence y, or given y; note that both, my `corroboration' and
Fisher's likelihood, are intended to measure the acceptability of the
hypothesis x; it is thus x which is important, while y represents
merely the changing empirical evidence or, as I prefer to say, the
reports of the results of tests). Now I was convinced that, if x is a
theory, p(x)=0. I saw therefore that I had to construct a new
probability calculus in which the likelihood, p(y,x), could be a
definite number, other than 0/0, even if x was a universal theory with
p(x)=0. (1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 403)
******* In this postrationalist age of ours, more and more books 
are written in symbolic languages, and it becomes more and more
difficult to see why: what it is all about, and why it should be
necessary, or advantageous, to allow oneself to be bored by volumes of
symbolic trivialities. It almost seems as if the symbolism were
becoming a value in itself, to be revered for its sublime `exactness':
a new expression of the old quest for certainty, a new symbolic
ritual, a new substitute for religion.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 410)
******* I regard the doctrine that degree of corroboration 
or acceptability cannot be a probability as one of the more
interesting findings of the philosophy of knowledge. It can be put
very simply like this. A report of the result of testing a theory can
be summed up by an appraisal. This can take the form of assigning some
degree of corroboration to the theory. But it can never take the form
of assigning to it a degree of probability; for the probability of a
statement (given some test statements) simply does not express an
appraisal of the severity of the tests a theory has passed, or of the
manner in which it has passed these tests. The main reason for this is
that the content of a theory---which is the same as its
improbability---determines its testability and its corroborability.
(1959__Karl_Popper__The_Logic_of_Scientific_Discovery, 411)
**** Appendix
what we may call `empirical knowledge,' including `scientific
knowledge,' consists of guesses, and that many of these guesses are
not probable (or have a probability zero) even though they may be very
well corroborated (381)
*** 1992__John_Earman__Bayes_or_Bust
******* On Tuesdays, Thursdays, and Saturdays, however, I have my
doubts, not only about the imperialistic ambitions of Bayesianism, but
also about its viability as a basis for analyzing scientific
inference. (1992__John_Earman__Bayes_or_Bust, 2)
******* Bayesianism is the only view presently in the offing
that holds out the hope for a comprehensive and unified treatment of
inductive reasoning. (1992__John_Earman__Bayes_or_Bust, 2)
******* Whatever once ultimate decision about Bayesian confirmation 
theory, it possesses the one unmistakable characteristic of a worthy
philosophical doctrine: the harder it is pressed, the more interesting
results it yields. (1992__John_Earman__Bayes_or_Bust, 2) [see also 117]
******* Thus, for example, Fisher (1922) complained that instead of 
/p we might use another parameter, /q, where sin/q=2/p-1 and reason
that since we antecedently know nothing about /q, equal interval of /q
ought to be initially regarded as equally probable.
(1992__John_Earman__Bayes_or_Bust, 15)
******* Bayesians of all stripes are united in the convictions that 
qualitative approaches to confirmation, such as hypotheticodeductivism
and Hempel's instance confirmation (see chapter 3), are hopeless and
that an adequate accounting of the way evidence bears on hypotheses
and theories must be quantitative.
(1992__John_Earman__Bayes_or_Bust, 33)
******* In chapter 1, we saw that Bayes's essay contained a tension between 
personalism (probability as personal degree of belief) and objectivism
(probability as uniquely determined rational degree of belief). The
tension survives in modern Bayesianism. The pure personalists, as
represented by de Finetti and his followers, recognize the axioms of
probability as the only synchronic constraints of degrees of belief.
Some personalists have also refused to recognize any diachronic
constraints, but it turns out that the Dutch-book arguments used to
justify the probability axioms can also be used to justify rules of
conditionalization (see, however, section 6 below). Tempered
personalists would add further constraints, such as Lewis's principal
principle to be discussed below in section 7, or Shimony's (1970)
injunction on the members of a scientific community to assign a
nonzero prior to any hypothesis seriously proposed by a fellow member
of the community. Objectivists, such as Harold Jeffreys, carry the
tempering of priors to the extreme by proposing principles to uniquely
fix these numbers. Thomas Bayes himself seems to have fallen into this
camp, at least with respect to the problem treated in his founding
essay. (1992__John_Earman__Bayes_or_Bust, 35)
******* a knowledge of the tendencies of opponents may make it 
advisable to post odds that differ from one's true probabilities
(1992__John_Earman__Bayes_or_Bust, 43)
******* The worry is that two numbers are needed to characterize 
my belief state, one describing my degree of belief, the other
describing the weight of the evidence.
(1992__John_Earman__Bayes_or_Bust, 52)
******* The probability calculus requires that the degrees of 
belief assigned to Einstein's general theory of relativity (GTR) and
its negation sum to one {\ldots} assessments of \urcorner GTR are
ill-informed {\ldots} no practical guidelines
(1992__John_Earman__Bayes_or_Bust, 57)
******* [Hempel's conditions for confirmation]
consequence condition, consistency condition, special consequence
condition, converse consequence condition
(1992__John_Earman__Bayes_or_Bust, 65f)
******* Bayesianism pays a backhanded compliment to Popper's methodology 
{\ldots} the virtues of sincere attempts to falsify can be recognized
(1992__John_Earman__Bayes_or_Bust, 72)
******* For Hempel, whether or not /E confirms /H depends only on the 
syntax of /E and /H. But from Goodman we know this to be wrong
{\ldots} for Hempel, confirmation is a two-place relation. But from
the ravens paradox and other examples we know that background
information /K must be brought into the analysis to get and
illuminating treatment. (1992__John_Earman__Bayes_or_Bust, 74)
******* applying the Bayesian apparatus to topics like the paradox 
of the ravens, the variety of evidence, the role of theories in
scientific inference, and the problem of Quine and Duhem leads to
fruitful avenues of investigation.
(1992__John_Earman__Bayes_or_Bust, 86)
******* Carnap's principle of tolerance 
{\ldots} the implication is that evidential support has a pragmatic
dimension. Pure personalists will hardly be shocked by this
consequence, but those who want confirmation theory to deliver
rational and objective degrees of belief may not be so shock-proof.
(1992__John_Earman__Bayes_or_Bust, 82)
******* A Carnapian confirmation function /c(H,E) for a language is a 
conditional probability function defined on pairs of sentences /H, /E
of the language, where /E is noncontradictory.
(1992__John_Earman__Bayes_or_Bust, 87)
******* the use of the probability calculus [the quantitative approach] 
{\ldots} leads to a significant clarification of the problem of
projectability (1992__John_Earman__Bayes_or_Bust, 111)
******* humanized Bayesianism: namely, a realistic theory of 
confirmation must take into account nonempirical learning.
(1992__John_Earman__Bayes_or_Bust, 132)
******* [distinguish observational and theoretical 
hypotheses and Bayesianism's varying success]
(1992__John_Earman__Bayes_or_Bust, 138)
******* Recall that Bayes assumed a condition of complete 
ignorance regarding the unknown event. If we ignore the potential
ambiguities in this notion, the point is that such a condition will be
realized only in never-never-land Bayesianism, where an agent begins
as a tabula rasa, chooses her priors, and forever after changes her
probabilities only by conditionalization. A more realistic Bayesianism
would recognize the local and episodic character of problem solving.
In Bayesian terms, we use different probability functions for
different problem-solving contexts, and within a context we may change
probabilities not by conditionalization but by some more radical
means. Thus, far from being a tabula rasa, the typical scientist comes
burdened with a wealth of information in trying to make what the
Bayesian would describe as decisions about prior probabilities. E.T.
Jaynes's modern version of the principle of indifference tries to take
into account some of this information, since it enjoins us to maximize
a quantity he calls ``entropy'' subject to known constraints that can
be expressed in terms of moments of the probability distribution. But
only a small part of information can be expressed in these terms.
(1992__John_Earman__Bayes_or_Bust, 139f)
******* there aren't any extant non-Bayesian accounts of scientific 
inference that have proved to be viable across the broad range of
cases. As one example of dashed hopes, I would cite Hempel's account
of qualitative confirmation and Glymour's attempt to extend Hempel's
ideas to the confirmation of theoretical hypotheses by  means of
bootstrapping relations. One might have hoped that Hempel's
confirmation relations and Glymour's bootstrapping relations, which
are purely logicostructural relations, could provide at least part of
the basis for objectivity. Alas, as we saw in chapter 3, the Bayesian
apparatus is needed before any conclusions can be drawn about the
bearing of these relations on the credibility of  hypotheses. Other
examples of dashed hopes could be cited, but enough tears have already
been shed. (1992__John_Earman__Bayes_or_Bust, 158)
******* Putnam's indictment {\ldots} an approach based on 
c functions {\ldots} cannot capture the judgments of a ``good'' or
``ideal'' judge {\ldots} once a scientist announces that she is using
a particular minimally recursive Pr function, we can diagonalize to
produce an effective hypothesis {\ldots} and if its predictions are
borne out without exception, then eventually the ideal judge will base
her predictions on the hypothesis and will continue to do so unless
the hypothesis fails. (1992__John_Earman__Bayes_or_Bust, 220)
******* This is a move recommended by Wesley Salmon. It works 
if what we are trying to do is to choose among the explicitly
formulated hypotheses. But this move seems most un-Bayesian, since
Bayesian epistemologists don't want to choose hypotheses, in the sense
of accepting or rejecting them, but rather aim to probabilify them.
(1992__John_Earman__Bayes_or_Bust, 229)
*** 1994__Howson_Franklin__Bayesian_Conditionalization
*** 2000__Eells_Fitelson__Measuring_Confirmation_and_Evidence
*** 2000__James_Pryor__The_Skeptic_and_the_Dogmatist
******* He allows that you may have some justification for 
believing p that does rest on your introspective aware- ness of your
experiences, and on background beliefs. He only claims that there is a
kind of justification you have which does not rest on these things.
(2000__James_Pryor__The_Skeptic_and_the_Dogmatist, 519)
*** 2004__Kelly_Glymour__Why_Probability_does_not_Capture_the_Logic_of_Scientific_Justification
******* scientific justification should reflect how intrinsically difficult 
it is to find the truth and how efficient one's methods are at finding
it. Difficulty and efficiency can be understood in terms of such
cognitive costs as errors or retractions of earlier conclusions
prior to convergence to the truth.
(2004__Kelly_Glymour__Why_Probability_does_not_Capture_the_Logic_of_Scientific_Justification, 96)
******* But high degrees of belief are not permanent at all: arbitrarily
high confirmation can evaporate in a heartbeat and can fluctuate
between extremes repeatedly, never providing a hint about how many
bumps might be encountered in the future or about whether some other
method could guarantee fewer. Hence, Bayesian confirmation, or any
other notion of confirmation that can be arbitrarily high irrespective
of considerations of truth-finding efficacy, cannot explicate
scientific justification. [the problem here is that Bayes' formula
doesn't give us two numbers, one for the posterior probability and
another one for what the posterior probability is worth---but, I
object, doesn't entropy do just that? Again, a 50% chance just means
that we DON'T know (not that we do know and have already done a lot of
testing to that effect)]
(2004__Kelly_Glymour__Why_Probability_does_not_Capture_the_Logic_of_Scientific_Justification, 97)
******* viewing the minimization of retractions as a natural aim that might
provide alternative explanations of features of scientific practice
routinely explained along confirmation-theoretic lines.
(2004__Kelly_Glymour__Why_Probability_does_not_Capture_the_Logic_of_Scientific_Justification, 100)
******* The same efficiency could be had by attaching the numbers in other
ways or by dispensing with the numbers and producing theories
outright, as scientists have always done until fairly recently. There
is no special aptness about softening one's views in the face of
uncertainty
(2004__Kelly_Glymour__Why_Probability_does_not_Capture_the_Logic_of_Scientific_Justification, 112)
*** 2004__Patrick_Maher__Probability_Captures_the_Logic_of_Scientific_Confirmation
*** 2006__Joseph_Halpern__Reasoning_about_Uncertainty
*** 2010__Roger_Clarke__The_Ravens_Paradox_Is_a_Misnomer
******* As an exemplar of type (b), we have Maher's 
(2004, pp. 77–78) numerical example. Maher takes a Carnapian approach
to confirmation, giving a series of axioms a satisfactory probability
function must obey, going beyond the axioms of probability calculus.
[This is a departure from the subjective Bayesian approach, which
holds that the only rational constraints on a subjective probability
function are the probability calculus and the rule of updating by
conditionalization. Most of Maher's extra axioms are to be found
elsewhere, in his (2000).] There is also the further, rather vague,
injunction that determining the prior probability that a is a raven,
for example, ``would require careful consideration of what exactly is
meant by `raven' and what the alternatives are'' (2004, p. 75). Thus,
despite Maher's desire to get his probabilistic results from a system
of inductive logic, the determination of prior probabilities---which
will be important in his supposed counterexample to Nicod's
Condition---seems to require some empirical knowledge about the
properties concerned.
(2010__Roger_Clarke__The_Ravens_Paradox_Is_a_Misnomer , 438)
******* there is no single correct formal representation of 
a given hypothesis that will be appropriate in all contexts. The wrong
representation can lead to paradoxes like that of the ravens
(2010__Roger_Clarke__The_Ravens_Paradox_Is_a_Misnomer , 439)
******* It bears emphasizing that I do not have anything 
to say about the logical structure of hypotheses like ``All ravens are
black.'' I am especially not defending any sort of contextualist
semantics. Although I have been arguing that when we use the sentence
``All ravens are black'' in different contexts of inquiry, we may need
different formal representations of that sentence to best bring out
the relations of confirmation in each context, it is important that
the hypothesis sentence mean the same thing across contexts.
(2010__Roger_Clarke__The_Ravens_Paradox_Is_a_Misnomer , 439)
** maher93 Maher, Patrick: Betting on Theories
If a, b, and c are three quantities, it is possible that P(a<b),
P(b<c), and P(c<a) are all greater than 1/2. Bar-Hillel and
Margalit (1988) refer to this phenomenon as probabilistic
prevalence. X., Y., and Z. [see maher93:48] have all claimed that
the phenomenon leads to intransitive preferences. (maher93:48)

The Allais problems. Maurice Allais was one of the earliest
critics of independence, and backed up his position by formulating
decision problems in which many people have preferences that
appear to violate independence. I will present these problems in
the way Savage formulated them, since this brings out the conflict
with independence most clearly. (These are the problems I posed to
Clayton and Reid in Augusta 2014, maher93:63)

Wesley Salmon objects that on this view: ``You cannot be convicted
of irrationality as long as you are willing to make the
appropriate adjustments elsewhere in your system of beliefs. You
can believe to degree 0.99 that the sun will not rise tomorrow.
You can believe with equal conviction that hens will lay billiard
balls. You can maintain with virtual certainty that a coin that
has consistently come up heads three quarters of the time in 100
million trials is heavily biased for tails! There is no end to the
plain absurdities that qualify as rational. It is not that the
theory demands the acceptance of such foolishness, but it does
tolerate it.'' (maher93:91f)

Apart from the semantic issue of what counts as a Dutch book
argument, I think Skyrms and I are in complete agreement. He seems
to allow that it cannot cogently be argued that violation of the
probability calculus makes you susceptible to a Dutch book. And he
maintains, as I do, that the cogent way to argue that rational
scientists have subjective probabilities, satisfying the axioms of
probability, is to use a representation theorem. (maher93:104) 

Henry Kyburg writes: "But the really serious problem is that there
is nothing in the theory that says that a person should change his
beliefs in response to evidence in accordance with Bayes' theorem.
On the contrary, the whole thrust of the subjectivist theory is to
claim that the history of the individual's beliefs is irrelevant
to their rationality: all that counts at a given time is that they
conform to the requirements of coherence. It is certainly not
required that the person got to the stage he is in by applying
Bayes' theorem to the coherent degrees of belief he had in some
previous state. No more, then, is it required that a rational
individual pass from his present coherent state to a new coherent
state by conditionalization. [...] For all the subjectivist theory
has to say, he may with equal justification pass from one coherent
state to another by free association, reading tea-leaves, or
consulting his parrot." (maher93:127)

Armendt (1980) has given a Dutch book arguments to show that the
rule of probability kinematics is a requirement of rationality.
But this argument has the same fallacy as the Dutch book arguments
for reflection and conditionalization. Furthermore, my account of
the true status of conditionalization also extends immediately to
probability kinematics. (maher93:128)

This reflects the fact that rational action is determined by
probabilities (plus utilities), and acceptance is not identifiable
with any level of probability. (maher93:150)

The other approach is to abandon the idea that belief is a
qualitative state that you either have to or you don't, and
instead say that it comes in degrees. Your degree of belief in H
could then be measured by the highest odds at which you would be
willing to bet on H. This second suggestions effectively
identifies belief with probability; and in fact, Bayesians since
Ramsey (1926) have referred to subjective probability as "degree
of belief." (maher93:152)

The upshot, then, is that the folk concept of belief appears to
regard belief in H as a single mental states that is expressed
both by a willingness to act as if H were true and also by sincere
intentional assertion of H; and these are in fact two distinct
states [...] Stich cites some psychological research that, he
claims, supports the conclusion that the mental states underlying
assertion and action are distinct. I would like to be able to cite
some empirical support of this kind, for the conclusion I have
reached on more a priori grounds. But unfortunately, the research
cited by Stich is no real support to this conclusion (though it
also does not disconfirm it). (consider this whole page for
the question of partial beliefs versus acceptance, maher93:153)

It seems that many Bayesian philosophers of science think of
subjective probability as the replacement for the notion of
acceptance, and so think that acceptance has no importantant role
to play in the Bayesian philosophy of science. This chapter will
argue that that view is a mistake, by describing three ways in
which the theory of acceptance makes an important contribution to
the Bayesian philosophy of science. (maher93:162)

Thus we now have a representation theorem that establishes an
expected utility representation for cognitive preferences even
when the acceptance of a hypothesis is not regarded as a simple
act. This provides a vindication of the decision theoretic account
of rational acceptance that I gave in section 6.3. It also
provides the foundation for the following discussion of scientific
values. (maher93:207)

Chapter 6 put forward the idea that scientists are concerned to
accept theories that are informative and close to the truth; and
it was assumed there that these values can be represented by a
cognitive utility function. Chapter 8 has provided support for the
idea that cognitive values can be represented by a cognitive
utility function. (maher93:208)

Science values informativeness and closeness to the truth and
nothing else. (maher93:208)

Ramsey had already argued cogently against the existence of such a
thing [logical probability] in (1926), and Carnap's later heroic
efforts to make sense of the notion in the end (1952) only
confirmed that Ramsey had been right. (maher93:221)

Measures of the informativeness of propositions have been
discussed by a number of philosophers of science, and many have
agreed that informativeness is part of the goal of science. As
Bar-Hillel and Carnap (1953) observed, the relevant notion of
information for this purpose is a semantic one, and thus the
purely syntactic measures of Shannon (1949) do not measure what we
are interested in here. (maher93:234)
** jaynesbretthorst03 Jaynes, E.T.: Probability Theory: The Logic of Science
**** although our concern with the nature of logical 
inference leads us to discuss many of the same issues, our language
differs greatly from the stilted jargon of logicians and philosophers.
There are no linguistic tricks, and there is no `meta-language'
gobbledygook; only plain English. We think that this will convey our
message clearly enough to anyone who seriously wants to understand it.
In any event, we feel sure that no further clarity would be achieved
by taking the first few steps down that infinite regress that starts
with: `What do you mean by “exists”?' (E.T. Jaynes, Probability
Theory, xxviii)
**** [the `simple' proof of G"odel's]
(E.T. Jaynes, Probability Theory, 45f)
**** [de Finetti coherence versus 
Cox consistency] (E.T. Jaynes, Probability Theory, 656)
**** Anyone who believes that he is proving things about the 
real world, is a victim of the mind projection fallacy. (E.T. Jaynes,
Probability Theory, 75)
**** [the monkey trial -- no matter the data, the
prior distribution completely determines the posterior distribution]
(E.T. Jaynes, Probability Theory, 162)
**** So, from a pragmatic standpoint, arguments about which prior
probabilities correctly express a state of `complete ignorance', like
those over prior ranges, usually amount to quibbling over pretty small
peanuts. (E.T. Jaynes, Probability Theory, 183)
**** [Against Fisher's ``Let the data speak for 
themselves''] (E.T. Jaynes, Probability Theory, 195)
**** It is now clear that the most ubiquitous reason for using the Gaussian
sampling distribution is not that the error frequencies are known to
be – or assumed to be – Gaussian, but rather because those frequencies
are unknown. One sees what a totally different outlook this is than
that of Feller and Barnard; `normality' was not an assumption of
physical fact at all. It was a valid description of our state of
knowledge. (E.T. Jaynes, Probability Theory, 210)
**** One who studies the literature of these matters perceives that there
is a strong correlation; those who have advocated the non-frequency
view have tended to be physicists, while up until very recently,
mathematicians, statisticians, and philosophers almost invariably
favored the frequentist view. Thus, it appears that the issue is not
merely one of philosophy or mathematics; in some way not yet clear, it
also involves physics. (E.T. Jaynes, Probability Theory, 314f)
**** [Emperor of China fallacy]
(E.T. Jaynes, Probability Theory, 258, 338)
**** As luck would have it, these requirements are compatible; and 
so the problem has one unique solution. [What if we aren't lucky? Is
there a problem overdetermined in the sense that it cannot be
invariant in any of the senses of the word? Is there a more general
theorem that tells us under which circumstances transformation groups
will be successful?] (E.T. Jaynes, Probability
Theory, 392)
**** The onus is always on the user to make sure that 
all the information, which his common sense tells him is relevant to
the problem, is actually incorporated into the equations, and that the
full extent of his ignorance is also properly represented.
(jaynesbretthorst03:339)
**** One man's prior probability is another
man's posterior probability (jaynesbretthorst03:89). Uffink, however,
claims in 1996 that ``Jaynes always rejected this point of view''
(uffink96:13).
** penfield13 Paul Penfield: Information, Entropy and Computation
In the 2013 version, ME is in chapter 9, and Penfield suggests that
Lagrange Multipliers are clumsy and unneeded because he knows an
alternative method. That's worth following up on. In an earlier
version, ME is chapter 10 -- that's what I have printed in my
collection of articles. The material on LMs may be useful. The 2013
version is here:
http://www-mtl.mit.edu/Courses/6.050/2013/notes/chapter9.pdf.
** kyburg95 Henry Kyburg: BR Patrick Maher Betting on Theories
**** see kyburg-01.jpg
** gillies00 Donald Gillies: Philosophical Theories of Probability
Laplace supposes that someone (Ms. A. say) is reliably informed that a
coin is biased but not told the direction of the bias, and that she is
asked to say what is the probability of heads. If Ms. A. holds an
epistemological view of probability, she will answer that the
probability of heads is one half, since, because of her ignorance of
the direction of the bias, there is no reason to prefer one outcome to
the other. If Ms. A. holds an objective view of probability, she will
answer that the probability of heads is p where zero is greater or
equal than p is greater equal than one, and the value of p is
otherwise unknown except for the fact that p is not one half. This
shows and a striking fashion the difference between the two approaches
to probability. {\ldots} Laplace himself comes out unequivocally in
favor of the epistemological view. He writes {\ldots} (21)

The logical theory. This was developed by Keynes in the Cambridge of
the Edwardian era. The logical theory is the one most similar to the
traditional classical view, and perhaps the Cambridge of that time
gave gave rise to a late flowering of the ideas and ideals of the age
of reason. This flowering was brought to an end by the outbreak of the
First World War, which gave such a striking demonstration of that
typically 20th-century combination of irrationality going hand-in-hand
with scientific and technological ingenuity. (24)

Russell was working out the principles of deductive logic used in
mathematics, but what about the reasoning from evidence to hypotheses
and predictions characteristic of science and so many everyday
considerations? It could be argued that, as well as a deductive logic,
one needed an inductive logic to cover such empirical reasoning.
Moreover, this inductive logic would be closely connected to, perhaps
identical with, probability theory. (27)

One immediate consequence of this approach is that it makes all
probabilities conditional. We cannot speak simply of the probability
of a hypothesis, but only of its probability relative to some evidence
which partially entails it. Keynes puts the point as follows: {\ldots}
(30)

In the sense important to logic, probability is not subjective. It
is not, that is to say, subject to human caprice. A proposition is not
probable because we think it so. When once the facts are given which
determine our knowledge, what is probable or improbable in these
circumstances has been fixed objectively and is independent of all
opinion. The theory of probability is logical, therefore, because it
is concerned with the degree of belief which it is rational to
entertain in given conditions, and not merely with the actual beliefs
of particular individuals, which may or may not be rational. (Keynes
1921:4.) (33)

Jaynes (1973) wrote of a interesting paper on our third (geometrical)
paradox about the random cord of a circle. Most unusually, he argued
that one of the three solutions was correct and the other two were
wrong. (46)

Thus the failure to provide a satisfactory solution to the paradoxes
of the principle of indifference seems to me to be fatal to the
logical theory of probability. This point can be reinforced by
comparing the situation here with that in a deductive logic following
the discovery of Russell's paradox. (48)

As de Finetti himself says: {\ldots} if you want to apply mathematics,
you must act as though the measured magnitudes have precise values.
This fiction is very fruitful, as everybody knows; the fact that it is
only a fiction does not diminish its value as long as we bear in mind
that the precision of the results will be what it will be {\ldots} to
go, with the valid help of mathematics, from approximate premises to
approximate conclusions, I must go by way of an exact algorithm, even
though I consider it an artifice. (1931a: 204.) (57)

Unfortunately, however, he would not be allowed to do so according to
de Finetti, for, to quote again a section of the key passage given
above: {\ldots} when experience teaches us the result A on the first N
trials, our judgment will be expressed by the probability P of E
subscript N+1) no longer, but by the probability P of (E subscript
N+1 | A), i.e. that which our initial opinion would already attribute
to the event E subscript N+1 considered as conditioned on the outcome
A. Nothing of this initial opinion is repudiated or corrected; it is
not the function P which has been modified (replaced by another P
star), but rather the argument E subscript N+1 which has been replaced
by E subscript N+1 | A, and this is just to remain faithful to our
original opinion (as manifested in the choice of the function P).
(1937:146.) (79f)

What leads to so much complication is that on this approach it is
necessary to consider all the possibilities which might arise at the
very beginning of the investigation. In order to set up his prior
probabilities, Mr. B has to consider every possible kind of
dependence which might arise in the sequence of events, and assign
each a prior probability. Now there is a very large number of
different forms of dependence. De Finetti mentions Markov chains
of different orders, but there are non-Markovian forms of dependence
as well. (81)

It follows that the Bayesian of the type we are considering in this
section (Mr. B. say) is caught on the horns of a dilemma. Mr. B. may
adopt a rather limited set of hypotheses to perform his Bayesian
conditionalization, but then, as the example of the game of red or
blue shows, if his set excludes the true hypothesis, his Bayesian
learning strategy may never bring him close to grasping what the real
situation is. This is the first, or 'red or blue,' horn of the
dilemma. If Mr. B. responds by saying he is prepared to consider a
wide and comprehensive set of hypotheses, these will surely include
hypotheses from chaos theory and thus anything he does will become
Bayesian, making the whole approach empty. This is the second, or
'chaotic clock,' horn of the dilemma. (84)
** howsonurbach06 [third edition] Colin Howson and Peter Urbach: Scientific Reasoning The Bayesian Approach
Inaugurated in Ramsey's seminal essay 'Truth and Probability' (1926),
the utility-revolution was and still is widely regarded as culminating
successfully 30 years later in Savage's classic work (1954). (57)

But there is also a simple, and compelling, reason why (3) should not
be adopted: it is inconsistent. Given the 'obvious' argument for (3)
[this refers to simple conditionalization], and the fact that it is
often advertised as itself a principle of consistency, or of 'dynamic
coherence', this might seem a surprising claim. Nevertheless it is
easy to prove. (81)

The theorem states that within the class of linear, unbiased
estimators of beta and alpha, least squares estimator is have the
smallest variance. [Could you do regression analysis using maximum
entropy?] (213)

We have argued that the stopping rule is irrelevant in any inductive
inference, and the Bayesian endorsement of this view and the classical
denial of it seem to us decisive arguments in favor of the one and
against the other. But before resting our case, we should visit a
couple of arguments that may appear to show that in fact the Bayesian
is wrong to take no account of the stopping rule. (250)

There are no informationless priors, and the quest for them is the
quest for the chimera. (277)

Thus the prior use of data to furnish constraints on a probability
distribution raises the question whether the maximum-entropy method
might be in conflict with conditionalization (given the latter's own
conditions of validity; see Chapter 3), a question that others have
raised, together with examples where it does seem to be (see
Seidenfeld 1979, Shimony 1985), and which seems not to have been
satisfactorily answered by advocates of next maximum entropy. (278
and 279)

Why shouldn't arbitrary variations in space-time curvature be included
in the list, or even arbitrary coordinate transformations, which are
not mentioned either? [This is in response to Jaynes' paper A
Well-Posed Problem] (285)

There do admittedly exist alleged proofs that the maximum entropy
method is uniquely determined by plausible assumptions; indeed, there
is "quite an industry", to quote Paris (1994, page 79). But closer
investigation reveals that there is often (much) more to these
conditions than meets the eye. (286)

A theorem of Williamson, about separating sets of variables in a
constraint graph, implies that the maximum entropy solution for the
constraints above automatically renders A and B conditionally
independent given C (2005, page 86). This underlines how far the
maximum entropy method transforms null information into positive
information. (fn286)

Given the other problematic features of conditionalization we pointed
to in Chapter 3, we feel that in linking its fortunes to the principle
of minimum information no real advance has been made in justifying its
adoption as an independent Bayesian principle. (287f)

Forster and Sober, scourges of Bayesianism, claimed that a theorem
of Akaike shows that there's actually a great deal more that can be
said, and of a mathematically precise character (292)

AIC and BIC are actually not the only approaches to trying to justify
simplicity considerations in terms of some more tangible
methodological goal, though these deal with rather different
conceptions of simplicity. One, due to Solomonoff and others, appeals
to Kolmogoroff Complexity Theory. Assume that hypotheses assign
probabilities to possible data strings. We can suppose without loss of
generality that both hypotheses and data are coded as finite strings
of zeros and ones. The complexity of any such string is defined to be
the length of the shortest computer program which will generate it.
The fact that such program-lengths across different 'universal'
programming languages (like Lisp, Prolog, Java etc.) can be proved to
be uniformly founded by a constant means that the definition is to
that extent relatively language-independent. Suppose a data sequence
of length N is observed, and that P is the true distribution of the
data. Let the error in predicting the next member of the sequence
between P and any other hypothesized distribution, P', be the
square of the difference between the two probabilities on that member
conditional on the data. Solomonoff showed, under quite general
conditions, that if a certain prior distribution lambda ('the universal
enumerable semi-measure') is employed, which is also a prior
distribution rating complex sequences lower than simpler ones
according to the complexity criterion above, then the expected value
of the error converges to zero (Lee and Vitany 1997). But now we
have yet another criterion justified in terms of an expected value,
and everything we said earlier about the Akaike criterion applies
here equally. (296)

It is, in addition, certainly not sensible to throw away relevant
information, yet this is in effect just what is recommended by those
who tell us that we should always use reference priors wherever
possible, or give the simplest processes the highest a priori
probability. (297)

Given the routine dismissal of the counterfactual move in the
literature, readers may be surprised to learn that it is in fact
standard Bayesian procedure. Once any piece of evidence is 'learned'
it becomes 'old,' and according to those who advance the 'old evidence
problem' as an objection to the Bayesian methodology, it should no
longer confirm any hypothesis (indeed, conditionalizing on E
automatically takes its probability to one). So to regard any
evidence, once known, as confirming one has to go counterfactual.
[Compare this to retrospective conditioning] (299)
** earman92 Earman, John: Bayes or Bust?
**** Recall that Bayes assumed a condition of complete 
ignorance regarding the unknown event. If we ignore the potential
ambiguities in this notion, the point is that such a condition will be
realized only in never-never-land Bayesianism, where an agent begins
as a tabula rasa, chooses her priors, and forever after changes her
probabilities only by conditionalization. A more realistic Bayesianism
would recognize the local and episodic character of problem solving.
In Bayesian terms, we use different probability functions for
different problem-solving contexts, and within a context we may change
probabilities not by conditionalization but by some more radical
means. Thus, far from being a tabula rasa, the typical scientist comes
burdened with a wealth of information in trying to make what the
Bayesian would describe as decisions about prior probabilities. E.T.
Jaynes's modern version of the principle of indifference tries to take
into account some of this information, since it enjoins us to maximize
a quantity he calls ``entropy'' subject to known constraints that can
be expressed in terms of moments of the probability distribution. But
only a small part of information can be expressed in these terms.
(1992__John_Earman__Bayes_or_Bust, 139f)
** fraassen93 van Fraassen, Bas: Symmetries of Probability Kinematics
**** [Reason (a): We may want our posterior opinion to depend on other
factors besides the prior opinion and the given, simple constraint]
Reason (a) is always with us, and rightly keeps us from conceiving
epistemol- ogy as in principle a special sort of arithmetic or other
mechanical procedure. But we should also consider the case -
presumably 'normal' in the sense that deliberation and theoretical
innovation and creativity must be the exception rather than the norm
in our daily life - in which reason (a) is absent. (van Fraassen, Bas:
Symmetries of Probability Kinematics, 306)
** gruenwaldhalpern03 Gr"unwald and Halpern: Updating Probabilities
**** There exist some very simple setting in which 
MRE essentially never gives the right results. (Gr"unwald and Halpern:
Updating Probabilities, 243)
**** Example 1.3 provides some motivation for working in 
the smaller, more naive space. Examples 1.1 and 1.2 show that this is
not always appropriate. Thus, an obvious question is when it is
appropriate. (Gr"unwald and Halpern: Updating Probabilities, 245)
**** There are situations where applying MRE leads to 
paradoxical, highly counter-intuitive results (Gr"unwald and Halpern:
Updating Probabilities, 245)
**** Seidenfeld (1986), strengthening results of 
Friedman and Shimony (1971), show that there is <i>no</i>
sophisticated space in which conditioning will give the same answer as
MRE in this case. (See also (Dawid, 2001), for similar results along
these lines.) (Gr"unwald and Halpern: Updating Probabilities, 246)
**** Working with the naive space, while an attractive 
approach, is likely to give highly misleading answers. That is the
main message of this paper. (Gr"unwald and Halpern: Updating
Probabilities, 246)
**** We show that Jeffrey conditioning in the naive space 
gives the appropriate answers iff a generalized CAR condition holds.
We then show that, typically, applying MRE in the naive space does not
give the appropriate answer. (Gr"unwald and Halpern: Updating
Probabilities, 246)
**** While in these cases the sophisticated space is still 
relatively simple, this is no longer the case for the Judy Benjamin
puzzle. (Gr"unwald and Halpern: Updating Probabilities, 247)
**** In some cases of interest, CAR is (roughly speaking) guaranteed 
<i>not</i> to hold except in ``degenerate'' situations
. (Gr"unwald and
Halpern: Updating Probabilities, 251)
**** Seidenfeld shows that, under very weak conditions, MRE cannot 
coincide with sophisticated conditioning if the observations have the
form ``the conditional probability of $U$ given $V$ is $\alpha$'' (as
is the case in the Judy Benjamin problem). (Gr"unwald and Halpern:
Updating Probabilities, 263)
**** [Useful summary in table form]
(Gr"unwald and Halpern: Updating Probabilities, 264)
**** We show that the CAR framework can be used as a general 
tool to clarify many of the well-known paradoxes of conditional
probability; ... no CAR-like condition can hold in general for cases
where only MRE (and not Jeffrey) updating can be applied ... MRE
updating is not always so bad (Gr"unwald and Halpern: Updating
Probabilities, 264)
** jaynes85 Jaynes, E.T.: Some Random Observations
**** [Hannibal and Phormio]
jaynes85:131 [According to Cicero, while at the court of Antiochus,
Hannibal attended a lecture by Phormio, a philosopher, that ranged
through many topics. When Phormio finished a discourse on the duties
of a general, Hannibal was asked his opinion. He replied: "I have seen
during my life many an old fool; but this one beats them all."]
**** Much earlier, both Boltzmann (1902) and 
Gibbs (1877) had invoked the mathematical equivalent of PME as the
criterion determining Boltzmann's ``most probable distribution'' and
Gibbs' ``grand canonical ensemble.'' (Jaynes, E.T.: Some Random
Observations, 116)
**** In statistical mechanics, the hypothesis space problem 
was solved long ago. Extending Liouville's theorem to quantum
mechanics, the linearly independent ``global'' quantum states of a
system define, according to all present knowledge, the proper space on
which PME leads, unerringly, to correct predictions. (Jaynes, E.T.:
Some Random Observations, 132) [can you apply this to Wagner?]
**** Of course, if philosophers wish to discuss the rationale of science 
amoung themselves, in their own journals, without pretending that they
are making new contributions to science, they have every right to do
so. (Jaynes, E.T.: Some Random Observations, 134)
**** This brings us, obviously, to the matter of Shimony. I am not 
a participant, but, like other readers, only a bewildered onlooker, in
the spectacle of his epic struggles with himself. (Jaynes, E.T.: Some
Random Observations, 134)
**** Errors in this [Shimony's] argument have now been pointed out five 
times, by ... (Jaynes, E.T.: Some Random Observations, 135)
** rott01 Rott, Hans: Change, Choice and Inference: A Study of Belief Revision and Nonmonotonic Reasoning
** skyrms85 Skyrms, Brian: Maximum Entropy Inference as a Special Case of Conditioning
**** degrees of belief about our degrees of belief. Some have doubted 
the meaningfulness or coherence of such a notion, but on closer
examination these fears seem groundless (see Jeffrey, 1974; Skyrms,
1980; Domotor, 1981) (Skyrms, Brian: Maximum Entropy Inference as a
Special Case of Conditioning, 64) [cf. Spohn's two levels, which we
could put in the prospectus as ``Spohn's Two Level Objection'' where
maxent only operates on one level]
** skyrms86 Skyrms, Brian: Dynamic Coherence
**** simply apply Bayes' rule in a larger probability space in 
which what he learned does correspond to a measurable set. This
approach is pursued by Armendt (1980), Good (1981), and Skyrms
(1980a,b). (Skyrms, Brian: Dynamic Coherence, 237) [retrospective
conditioning]
**** It will come as no surprise to those who have studied 
the relation of MAXENT to conditionalization in a larger space that
there are many strategies which conflict with MAXENT and yet satisfy
these conditions for coherence (Dias and Shimony, 1981; Friedman and
Shimony, 1971; Shimony, 1973; Skyrms, 1985; Seidenfeld, 1986). This is
not to say that there may not be more special situations and
interpretations of the constraint in which MAXENT is tied closely to
conditionalization and thus to dynamic coherence (Tjur, 1974; van
Campenhout and Cover, 1981; Zabell, 1974). (Skyrms, Brian: Dynamic
Coherence, 241)
** skyrms87 Skyrms, Brian: Updating, Supposing, and Maxent
**** Updating subjective belief to assimilate a given bit of information
and supposing what the world would be like were that bit of
information true, are distinct mental processes for which distinct
rules are appropriate. (Skyrms, Brian: Updating, Supposing, and
Maxent, 225)
**** Much of the debate appears to proceed on the assumption, tacit or
explicit, that maxent is an inductive rule, i.e. as a rule for
updating subjective probabilities. I want to suggest that this is the
wrong way to look at maxent. Properly viewed, maxent is a rule for
stochastic hypothesizing; a rule for supposing. (Skyrms, Brian:
Updating, Supposing, and Maxent, 225)
**** Notice that the Friedman-Shimony example applies to 
a wide range of minimal revision rules for updating; not just maxent .
Any rule which provides a solution satisfying the constraint must
agree with maxent for E(g)=1 and E(g)=3. Any rule which gives a unique
minimal revision must agree with maxent on E(g)=2 since it takes no
revision to satisfy this constraint. If in addition the rule makes a
monotonic transition in final probability of 2 spots from E(g)=2 to
the extremes, the Friedman-Shimony reasoning applies. (Skyrms, Brian:
Updating, Supposing, and Maxent, 236)
**** Maxent is not a generally valid updating rule
(Skyrms, Brian: Updating, Supposing, and Maxent, 237) [Skyrms'
conclusion, using Shimony, laughable]
** spohn12 Spohn, Wolfgang: The Laws of Belief: Ranking Theory and Its Philosophical Applications
Van Fraassen (1995b) is a sophisticated attempt to develop the
logic of old beliefs in terms of Popper measures and is hence a
major contribution to the topic of this section. Arl{\'o} Costa
further elaborates this point of view in a series of papers (2000,
2001ab). Joyce (1999, chapter 6) builds his account of conditional
beliefs on Popper measures. H{\'a}jek 2003a provides further
affirmation. And that trend continues. (206)

An intuitively and theoretically most satisfying option is
epistemological monism: there is just one basic description of
doxastic states. Monism can take various forms. One form is a
eliminativism: the view that, although we presently have various
ways to describe our doxastic attitudes, only one will be needed
and survive in the end; the other ones can simply be eliminated;
their relation to the basic notion is of no further interest. The
question is: which notion might be the lucky one? It cannot be the
notion of belief (or its sophistication in form of ranks); we
cannot forget about subjective probabilities and confine ourselves
to talking about beliefs. It might be some third notion, who
knows? However, it is idle to speculate; I cannot see any present
candidate that would be able to play that role. Of course, it
might be probability itself; this is radical probabilism and so
ably defended by Richard Jeffrey since his (1965). I feel strongly
attracted by the unity and systematicity of this position; in
comparison all other positions are a jumble. I hope the reader can
sense my efforts to preserve these virtues. Nonetheless, this
position is also deeply unsatisfactory; I find it entirely
incredible that our talk of belief should merely be a convenient
device, yet the mistake ultimately could be eliminated from the
theoretical point of view. We must tell a positive story about
beliefs (201)

Hild's argument thus takesa critical turn against Cox's
line of reasoning. Not only probability theory can be justified
along this line, as many Bayesians fond of it seem to assume,
for alternative accounts of degrees of belief can be so justified
as well. However nobody has provided any argument as to why one
should prefer this rather than that kind of modularity. And it
seems difficult to do so without question begging. (183)

What is my conclusion, then? We do want an account of belief, B, of
acceptance, of taking a proposition to be true, but whatever may
express the same notion, which applies not only to tautologies and
other maximal certainties, but also to contingent propositions. A as
Chapter One urged us, we do want a static and dynamic account of
belief, for otherwise we will not connect up with the topics of
traditional epistemology. Probabilistic epistemology is unable to
provide such an account, as the lottery paradox forces us to recognize
[see moss13:19, ``the Lockean project of analyzing belief in terms of
sufficient credence'']. Hence, the only choice left is to develop such
an account independent of probability theory. This is what we will do
in the next chapters, and this is what ranking theory is all about. So
although we will at first entirely turned away from Bayesianism, it
will soon be obvious that the similarities in relation of our account
to probability theory are very close, indeed so close that one might
see this book as presenting an extension of the Bayesian viewpoint.
However, it will become clear in the course of the book that this
perspective would not be fair, and in Chapter Ten I will argue that
probability and ranking theory are on a par and symmetrically
supplement one another. Still, as these relations will pervade the
entire book. (46)
** jeffrey70 Jeffrey, Richard: Dracula Meets Wolfman: Acceptance Versus Partial Belief
**** The notions of belief and disbelief are familiar enough 
but, I find, unclear. In contrast, I find the notion of subjective
probability, for all its (decreasing) unfamilarity, to be a model of
clarity---a clarity that it derives from its association with the
concepts of utility and preference within the framework of Bayesian
decision theory ... I continue to avoid talk about knowledge and
acceptance of hypotheses, trying to make do with graded belief
(Jeffrey, Richard: Dracula Meets Wolfman: Acceptance Versus Partial
Belief, 183)
**** Wolfman cannot breathe the musty air of Castle 
Dracula, nor can Dracula survive the winds of Wolfman's moors
(Jeffrey, Richard: Dracula Meets Wolfman: Acceptance Versus Partial
Belief, 183)
**** our ordinary notion of belief is only vestigially present in the
notion of degree of belief. I am inclined to think that Ramsey sucked
the marrow out of the ordinary notion, and used it to nourish a more
adequate view (Jeffrey, Richard: Dracula Meets Wolfman: Acceptance
Versus Partial Belief, 171f)
**** Then, as a practical matter, I think one can give
necessary conditions for reasonableness of a set of partial beliefs
that go beyond mere coherence -- in special cases. The result is a
patch-work quilt, where the patches have frayed edges, and there are
large gaps where we lack patches altogether. It is not the sort of
seamless garment philosophers like to wear; but (we ragged pragmatists
say) the philosophers are naked! Indeed we have no proof that no more
elegant garb than our rags is available, or ever will be, but we have
not seen any, yet, as far as we know. We will be the first to snatch
it off the racks, when the shipments come in. But perhaps they never
will. Anyway, for the time being, we are dressed in rags, tied neatly
at the waist with a beautiful cord -- probabilistic coherence. (It is
only the cord that visibly distinguishes us from the benighted masses.)

What might the seamless garment look like? Well, Carnap has an idea:
it will be a conditional probability measure c( / ) defined on a
unified language of science which we shall also used in daily life. In
that language we shall be able to report the weather, meter readings,
and upset stomachs, as well as the laws of physics-chemistry-biology
as we shall then take them to be. For any sentences P and Q in that
language, c(P/Q) will have a definite value ... which will presumably
be computable as accurately as you please, with the aid of superfast,
complex machinery then available. `In principle,' we shall then be
able to separate the inductive logical component (represented by the
function c) from the experiential component (represented by an
enormously long conjunction e of observation reports) in anyone's
beliefs, as they ought to be. (Richards Jeffrey, Acceptance Versus
Partial Belief, 169--170)
** morton99 Morton, Adam: Decision Theory as Philosophy by Mark Kaplan
**** it is hard to translate between Bayes-speak 
and epistemologish (Morton, Adam: Decision Theory as Philosophy by
Mark Kaplan, 507)
** williams80 Williams, P.M.: Bayesian Conditionalisation and the Principle of Minimum Information
The question of the significance of the order in which constraints are
applied requires more delicate and extended discussion in the general case.
This will be dealt with elsewhere. (williams80:143)
* deleted passages
** from prospectus
**** For ideas of simplicity which lead to 
E.T. Jaynes' articulation of the \textsc{pme} in 1957, there was
Richard Avenarius' telling book title \emph{Philosophie als Denken der
Welt gem{\"a}{\ss} dem Princip des kleinsten Kraftma{\ss}es:
Prolegomena zu einer Kritik der reinen Erfahrung} (see
\scite{7}{avenarius76}{}). Avenarius inspired Ernst Mach, who
described the economy of thought in physics (and the sciences
generally) as a result of the desire to \qeins{master the sum of one's
experience by the smallest possible effort} (see \scite{7}{mach82}{}).

The philosopher who in the beginning stages pursued this project most
systematically was Rudolf Carnap in \emph{Der logische Aufbau der
Welt}, whose plan it was \qeins{that qualities should be assigned to
point-instants in such a way as to achieve the laziest world
compatible with our experience {\ldots} the principle of least action
was to be our guide in constructing a world from experience} (see
\scite{7}{quine51}{}). Carnap was one of the first who tried to think
systematically about simplicity, preferring already in his
dissertation \emph{Der Raum} \qnull{Einfachheit des Baues} (simplicity
of the construct) over \qnull{Einfachheit des Bauens} (simplicity of
the construction) (see \scite{8}{carnap22}{82}) and then going on to
write \qeins{{\"U}ber die Aufgabe der Physik und die Anwendung des
Grundsatzes der Einfachstheit} (see \scite{7}{carnap23}{}).Insert a
section here about representation theorems and Ramsey. Paul also wants
to see Carnap's inductive logic here.
**** A person walks into a dimly lit room and slowly adjusts her eyesight
% to the lighting. A doctor entertains a certain probability assessment
% concerning her patient's health and then gathers new evidence by
% receiving a lab report or examining the patient. A scientist conducts
% an experiments and analyzes her data. A politician weighs her options
% before making an important policy announcements and receives input
% from a pollster. 

% We can investigate changes in belief (degrees of belief, or the
% holding of a belief), based on observation, evidence, or other things,
% descriptively or prescriptively. This project is interested in what we
% can say about change in degrees of belief prescriptively, based on new
% evidence. Richard Jeffrey calls it probability kinematics. How should
% an agent revise her degrees of belief if she learned something she
% didn't know before? The best known example of this is
% standard conditioning. If an agent becomes certain of event $E$, then
% the updated probability for event $H$ is 

% % ¬!"£$%^&*()_+{}:@~<>?[];'#,./|\

% \begin{displaymath}
%   P_{\mbox{\footnotesize new}}(H)=P_{\mbox{\footnotesize old}}(H|E)=
% \frac{P_{\mbox{\footnotesize old}}(H\wedge{}E)}{P_{\mbox{\footnotesize old}}(E)}
% \end{displaymath}

% Although there is no logical necessity that an agent should assume
% this updated probability assessment (assuming a different updated
% probability assessment does not result in a logical contradiction),
% there are powerful arguments for the normativity of standard
% conditioning, for example symmetry or a dynamic Dutch Book argument
% (the latter means that under certain conditions you can only insure
% yourself against certain loss if your bets obey standard
% conditioning). 
* oldquotes
** Judy Benjamin
*** Colin Howson and Allan Franklin
**** [soundness and completeness theorem 
for the probability calculus] (Colin Howson and Allan Franklin,
Bayesian Conditionalization and Probability Kinematics, 451)
**** [Jeffrey's innovation: evidence doesn't come to us in the form of
propositions of whose truth we are certain] Jeffrey inaugurated the
study of general probability kinematics (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 453)
**** limitation on Jeffrey's rule: it cannot be 
used to define a posterior probability P' when the E(i) are not
exclusive (Colin Howson and Allan Franklin, Bayesian
Conditionalization and Probability Kinematics, 454)
**** Csiszar states that if any convex set C of constraints is 
closed in the variational distance and some member of C has finite
information relative to P, then there is a unique P' such that P'
minimizes I(P',P). [affine constraints] (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 456)
**** This gloss (the function P' minimizing I(P',P) is as like 
P as it is possible to be given the constraints imposed by the data)
should be treated with great caution. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 456)
**** The requirement that the posterior distribution should be that 
which is in some sense or other the closest, subject to the stated
constraints, to the prior, is not only an extralogical constraint, but
it is also, in our view, one which it is very difficult if not
impossible to defend as a rationality constraint either. (Colin Howson
and Allan Franklin, Bayesian Conditionalization and Probability
Kinematics, 457)
**** [critique of diachronic or dynamic Dutch Book arguments, based 
on Hacking, see also Jon Williamson, Objective Bayesianism, Bayesian
Conditionalisation and Voluntarism, 14] (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 458)
**** Bayesian conditionalization suffices to deal with most if not 
all of the methodologically important cases of adjusting beliefs, even
where uncertain evidence is involved. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 461)
**** There are several things wrong with [Hobson's example, where 
probabilities are calculated with an expectation constraint and the
PME] the X(i) are not likely to be independent with respect to the
probability distribution P', for P' is by assumption an inductive
probability [see Seidenfeld's example in Jon Williamson, Objective
Bayesianism, Bayesian Conditionalisation and Voluntarism, 10f] (Colin
Howson and Allan Franklin, Bayesian Conditionalization and Probability
Kinematics, 464)
**** not to use the rule of Bayesian conditionalization, but some 
other rule, like the principle of minimum information with a uniform
prior and constraints in the form of expectation values, actually
entails inconsistency, i.e. incoherence. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 465)
*** Igor Douven and Jan-Willem Romeijn
**** we argue that Jeffrey's rule can solve the 
Judy Benjamin problem after all {\ldots} we extend the set of distance
functions to ones that take into account the varying degrees to which
propositions may be epistemically entrenched (Igor Douven and
Jan-Willem Romeijn, A New Resolution of the Judy Benjamin Problem, 1)
**** [indicative conditional]
(Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 2)
**** how one could beg any questions simply by registering one's 
intuitive verdict that (1) contains no information relevant to whether
Judy is in Red rather than in Blue territory {\ldots}(Igor Douven and
Jan-Willem Romeijn, A New Resolution of the Judy Benjamin Problem, 4)
**** How is one to update on an indicative conditional 
{\ldots} is there a defensible update rule that agrees with how Judy
should respond to learning (3)? {\ldots} semantics of conditionals
[used to undermine T2 on page 8] (Igor Douven and Jan-Willem Romeijn,
A New Resolution of the Judy Benjamin Problem, 5)
**** [Sarah's example: if it rains tomorrow, we cannot have 
sundowners at the Westcliff. My comment: Sarah of course knows that
rain is independent of sundowners, there is no such certainty in the
JB case.] (Igor Douven and Jan-Willem Romeijn, A New Resolution of the
Judy Benjamin Problem, 7)
**** intuitively, the learning of a conditional is or would be irrelevant 
to one's degree of belief for the conditional's antecedent {\ldots}
the learning of the relevant conditional should intuitively leave the
probability of the antecedent unaltered (Igor Douven and Jan-Willem
Romeijn, A New Resolution of the Judy Benjamin Problem, 9)
**** [Bradley's Adams conditioning]
(Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 9f)
**** {\ldots} really just a Jeffrey update. To be more 
exact, it is a Jeffrey update on the partition
\{urcorner{}A,A\wedge{}B_{1},{\ldots},A\wedge{}B_{n}\}, with
constraints Pr_{1}(\urcorner{}A)=Pr_{0}(\urcorner{}A) and {\ldots} in
the case of Judy only part of that assignment is given. But this
objection overlooks the fact that the context of the Judy Benjamin
case provides us with the additional probabilistic information
{\ldots} a clear separation between probabilities that derive from
explicit information and those that derive from context does not seem
feasible (Igor Douven and Jan-Willem Romeijn, A New Resolution of the
Judy Benjamin Problem, 11)
**** Adams conditioning, or, equivalently, Jeffrey conditioning with the 
explicit constraint of keeping the antecedent's probability fixed in
the update, or, again equivalently, IRE minimization, covers most of
the cases of learning a conditional. Unfortunately, however, it would
be wrong to think that it covers all of them, as Example 2 (jeweller,
Kate and Henry) already shows. (Igor Douven and Jan-Willem Romeijn, A
New Resolution of the Judy Benjamin Problem, 12)
**** where Sarah held onto her probability for the antecedent, Kate
wants to leave the probability of the consequent unaffected {\ldots}
bring to the table the epistemic entrenchments of the propositions
under scrutiny [my comment: translates into finding a Jeffrey
partition] (Igor Douven and Jan-Willem Romeijn, A New Resolution of
the Judy Benjamin Problem, 13)
**** [epistemic entrenchments and 
Hellinger distance function] allows us to regulate whether, and to
what extent, learning a conditional reflects back on the probability
fo the antecedent or rather influences the probability of the
consequent (Igor Douven and Jan-Willem Romeijn, A New Resolution of
the Judy Benjamin Problem, 14)
**** As Bradley stresses, even Bayes' rule ``should not be thought of 
as a universal and mechanical rule of updating, but as a technique to
be applied in the right circumstances, as a tool in what Jeffrey terms
\qnull{the art of judgment}.'' In the same way, determining and
adapting the weights EE supposes, or deciding when Adams conditioning
applies, may be an art, or a skill, rather than a matter of
calculation or derivation from more fundamental epistemic principles.
((Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 16)
*** williamson11 Jon Williamson
**** the difference between the two forms of updating [Bayes, maxent] 
reflects negatively on Bayesian conditionalization rather than on
objective Bayesian updating. (Jon Williamson, Objective Bayesianism,
Bayesian Conditionalisation and Voluntarism, 1)
**** [Probability, Calibration, Equivocation]
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 3)
**** It is objective in the sense that the three principles 
outlined above strongly constrain degrees of belief, leaving little
room for an agent to subjectively choose how strongly to believe a
proposition (Jon Williamson, Objective Bayesianism, Bayesian
Conditionalisation and Voluntarism, 4)
**** [affine constraint, as in Csiszar]
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 5)
**** conditionalisation requires being eternally true of prior beliefs
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 11)
*** Williams, Peter
**** about reversibility of evidence
(136)
**** In summary, the principle of minimum information yields a 
unique prescription for all closed convex constraints satisfied by at
least one distribution having finite information relative to the given
prior. (139)
*** Uffink, Jos
not yet excerpted
*** diaconiszabell82 Diaconis and Zabell
**** retrospective conditioning
(basically what Grove and Halpern are doing) (822)
**** Example 5.1 suggests that any claims to the effect 
that maximum-entropy revision is the only correct route to probability
revision should be viewed with considerable caution because of its
strong dependence on the measure of closeness being used. (829)
*** Fraassen, Hughes, Harman
**** three classes of constraints
(454)
**** five symmetry requirements
(455ff)
**** the three rules
INF Infomin or PME
MTP Maximum Transition Probability
MUD the simplest rule fulfilling the five requirements
**** It is surely significant, and disturbing, that 
INFOMIN did not come out the winner in either test ... the perceived
superiority of INFOMIN (462, with a handwritten note of objection)
*** seidenfeld79 Seidenfeld, Teddy
**** It is interesting to note, as reported 
by Denzau et. al. (1984), the MAXENT solution (A1) is associated with
a LOGIT model by a simple reidentification of parameters (Entropy and
Uncertainty, 282)
**** PME is excessively aprioristic ...
[I think Seidenfeld is here the victim of the meteorologist's fallacy]
(Why I am not, 414)
**** At one pole is subjectivism 
(as defended by Savage and de Finetti) ... At the other pole is
objectivism (as defended by Jeffreys and Jaynes) which argues for a
uniquely admissible probability function given a knowledge state K.
(Why I am not, 416)
**** Seidenfeld's objection
Maximizing entropy is unsatisfactory because the `partial information'
it works with fails to capture the effect of uncertainty about related
nuisance factors ... by conditionalizing on information about a
nuisance parameter one may move from a distribution of lower to higher
entropy, despite the obvious increase in information available (Why I
am not, 434)
*** Aristotle
**** Nicomachean Ethics
Here, as in all other cases, we must set down the appearances
(phainomena) and, first working through the puzzles (diaporesantas),
in this way go on to show, if possible, the truth of all the beliefs
we hold about these experiences; and, if this is not possible, the
truth of the greatest number and the most authoritative. For if the
difficulties are resolved and the beliefs are left in place, we will
have done enough showing. (NE VII, 1145b1ff)
*** Avenarius, Richard
***** die Gesamtheit des in der Erfahrung Gegebenen 
mit dem geringsten Kraftaufwand zu denken (Richard Avenarius
inspirierte die Figur des Professor Avenarius im Roman Die
Unsterblichkeit von Milan Kundera.) -- see Moritz Schlick 1917:
Amongst all the possible views ... mental indolence ... (Yemima
Ben-Menahem, Conventionalism, 113)
*** Bar-Hillel, Yehoshua, and Carnap, Rudolf
see article Semantic Information in keep-2011
*** Burgin, Mark
**** burgin09
***** definition of information in 
Burgin, 316, according to Carnap and Bar-Hillel. Very interesting.
E.g. The more probable a statement is, the less information it
conveys, 320.
*** chalmers11 Chalmers, David
**** scenarios constitute epistemic space. If a subject 
did not know anything, all scenarios would be epistemically possible
for the subject. When a subject knows something, some scenarios are
excluded. Every piece of substantive knowledge corresponds to a
division in epistemic space: some scenarios are excluded out as
epistemically impossible for the subject, while others are left open.
(David Chalmers, The Nature of Epistemic Space, 2)
**** In epistemic logic and the theory 
of belief revision, it is common to model epistemic possibility using
epistemic relations to an underlying space of pos- sible worlds. The
same goes for the theory of subjective probability: a subject's
credences are usually taken to be distributed over a space of
epistemically possible worlds. (David Chalmers, The Nature of
Epistemic Space, 2)
**** Instead, we should try to understand epistemic possibility 
on its own terms. We are not dealing here with counterfactual space:
the space of ways things might have been. Here, we are dealing with
epistemic space: the space of ways things might be. This epistemic
space calls for its own epistemic tools of analysis. (David Chalmers,
The Nature of Epistemic Space, 3)
**** But the notion of possibility invoked here differs from the notion 
of possibility that is usually associated with possible worlds: it is
a sort of epistemic possibility, whereas possible worlds are usually
understood to be associated with a sort of `metaphysical' possibility.
(David Chalmers, The Nature of Epistemic Space, 10)
**** Prima facie, this situation suggests that there is no good candidate 
to be the cardinality of the set of all worlds, and that there may be
no such set. Kaplan's paradox [see Modality, morality, and belief:
essays in honor of Ruth Barcan Marcus, 44f, title A problem in
possible-world semantics] arises at least as strongly when worlds and
propositions are replaced by scenarios and intensions. If anything,
the situation is worse. (David Chalmers, The Nature of Epistemic
Space, 35)
**** In Counterfactuals, Lewis suggests that the cardinality of 
the space of worlds might be beth2 , for reasons tied to the character
of spacetime. But it is hard to see why our spacetime should restrict
the space of worlds. (David Chalmers, The Nature of Epistemic Space,
37)
*** halpern03 Halpern, Joseph
**** Another famous justification of probability is 
due to Cox (1946), who showed that any function that assigns degrees
to events and satisfies certain minimal properties (such as the degree
of belief in U is a decreasing function in the degree of belief in U)
must be isomorphic to a probability measure. Unfortunately, Cox's
argument is not quite correct as stated; his hypotheses need to be
strengthened (in ways that make them less compelling) to make it
correct [Halpern 1999a; Halpern 1999b; Paris 1994]. (Reasoning About
Uncertainty, 65)
**** Given this intuition, it is perhaps not surprising 
that there are proponents of maximum entropy and relative entropy who
recommend that if an agent's information can be characterized by a set
C of constraints, then the agent should act "as if" the probability is
determined by the measure that maximizes entropy relative to C (i.e.,
the measure that has the highest entropy of all the measures in C).
Similarly, if the agent starts with a particular measure . it and gets
new information characterized by C, he should update to the measure
,a' that satisfies C such that the relative entropy between and ,u is
a minimum. Maximum entropy and relative entropy have proved quite
successful in a number of applications, from physics to
natural-language modeling. Unfortunately, they also exhibit some
counterintuitive behavior on certain applications. Although they are
valuable tools, they should be used with care.(Reasoning About
Uncertainty, 110)
**** [For the correspondence of ME and RW 
(random worlds) and their overlap in the unary case, whereas RW also
covers the nonunary case, see pp416--420. For the origin of the RW
approach see p. 429.]
*** Mach, Ernst
**** Die ökonomische Natur der physikalischen Forschung
***** Sowohl die Mitteilung als das Bedürfnis des 
Einzelnen, seine Erfahrungssumme mit dem kleinsten Gedankenaufwand zu
beherrschen, zwingt zu ökonomischer Ordnung. Hiermit ist aber auch die
ganze rätselhafte Macht der Wissenschaft erschöpft. Im einzelnen mag
sie uns nichts zu bieten, was nicht jeder in genügend langer Zeit auch
ohne alle Methode finden könnte.
(http://www.gleichsatz.de/b-u-t/trad/mach2.html)
*** Quine, WVO
**** Two Dogmas
***** the plan was that qualities should be assigned to point-instants in such 
a way as to achieve the laziest world compatible with our experience.
The principle of least action was to be our guide in constructing a
world from experience. (37)
** Information Epistemology
*** ingardenurbanik62
**** information seems intuitively a much simpler and 
more elementary notion than that of probability. It gives more a
cruder and global description of some situations physical or other
than probability does. Therefore, information represents a more
primary step of knowledge than that of cognition of probabilities
(just as probability description is cruder and more global than
deterministic description). Furthermore, a prinicipal separation of
notions of probability and information seems convenient and useful
from the point of view of statistical physics. In physics there
prevail situations where information is known (e.g.\ entropy of some
macroscopic systems) and may be measured with a high degree of
accuracy, whereas probability distribution is unknown and practically
cannot be measured at all {\ldots} Finally, it may be remarked that a
new axiomatic definition of information, free of the inessential
connection with probability, clears the way for future generalizations
of this notion. (ingardenurbanik62:136)
*** bernardo79
**** This pragmatic approach led to
Jose M. Bernardo's suggestion of Reference Posterior Distributions.
{\rppd}s agree with the Principle of Maximum Entropy in applicable
cases and thus also with the Principle of Indifference. Instead of
measuring and maximizing missing information, however, {\rppd}s
measure and maximize expected information. Let $p(\theta)$ be our
prior density. Then the expected information IE is:
\begin{displaymath} \mbox{IE}=\int p(x)\int p(\theta\vert
x)\log\frac{p(\theta\vert x)}{p(\theta)}d\theta\, dx \end{displaymath}
where $p(x)=\int p(x\vert\theta)p(\theta)d\theta$ and $p(\theta\vert
x)=p(x\vert\theta)p(\theta)/p(x)$ (Bernardo, 1979, p115). Again,
$p_{k}=\frac{1}{n}$ for the straightforward discrete case, but this
time we also learn that for the continuous case the distribution which
maximizes expected information is the normal distribution. (my priors
paper)
*** clarkebarron90
**** The relative entropy is a mathematical expression 
that admits several different interpretations in information theory
and statistics. These include the redundancy in source coding
problems, the risk in statistical estimation, and the error exponents
in hypothesis testing, among others. (clarkebarron90:453)
**** It is seen that $D(P^{n}_{\theta}\|M_{n})$ is 
a) the cumulative risk of Bayes' estimators of the density function,
b) the redundancy of a source code based on $M_{n}$, c) the exponent
of error probability for Bayes' tests of a simple versus composite
hypothesis, and d) a bound on the financial loss in a stock-market
portfolio selection problem. (clarkebarron90:455)
*** goguen97
**** It is said that we live in an 
Age of Information, but it is an open scandal that there is no theory,
nore even definition, of information that is both broad and precise
enough to make such an assertion meaningful. (goguen97:27)
*** guiasu77
**** Therefore, the continuous entropy $H_{\rho}$ may be interpreted 
as being (up to an additive constant) the variation of information
when we pass from the initial uniform probability distribution on the
interval $[a,b]$ to the new probability measure defined by the
probability distribution function $\rho(x)$ (any such a probability
measure is absolutely continuous with respect to the uniform
probability distribution on the interval $[a,b]$). Thus, we can
utilize, in the continuous case, Boltzmann's continuous entropy as
well as Shannon Entropy in the discrete case, both being interpreted
as the variation of information when we pass from the initial uniform
distribution to the corresponding probability measures. (guiasu77:28)
**** Theorem 3.1 shows that though the usual logical order, according 
to which information is defined by means of probability, can be
reversed, and one can introduce information first, without using
probabilities, probabilities inevitably come in at a later stage. The
fact that a theory which starts with the aim of defining information
without probability leads to the proof of the existence of probability
supports the view that the notion of information cannot be separated
from that of probability. To each event $A$ there correspond two
numbers: its probability $p(A)$ and its information content $I(A)$
which are connected by the formulas $I(A)=\log_{e}\frac{1}{p(A)},
p(A)=e^{-I(A)}$ (guiasu77:36f)
*** hjorland07
**** [objective versus subjective understanding of 
information] (hjorland07:1449)
**** The problem is also about whether problems of 
information science are best served with theories like Shannon and
Weaver's information theory or with theories more related to
semiotics. In the history of information science, the tendency has
been a development from information theory toward more semiotic
theories. (See also Werzig, 2003.) (hjorland07:1455)
*** jaynes57
**** the maximum-entropy distribution may be asserted for the
positive reason that it is uniquely determined as the one which is
maximally noncommittal with regard to missing information, instead of
the negative one that there was no reason to think otherwise
(Jaynes, 1957, p623)
**** there is nothing in the general
laws of motion that can provide us with any additional information
about the state of a system beyond what we have obtained from
measurement (Jaynes, 1957, 624)
*** khinchin57
*** kolmogorov68
**** the need for attaching definite meaning 
to the expressions $H(x|y)$ and $I(x|y)$, in the case of individual
values $x$ and $y$ that are not viewed as a result of random tests
with a definite law of distribution, was realized long ago by many who
dealt with information theory. (kolmogorov68:662)
**** The meaning of the new definition is very simple. Entropy 
$H(x|y)$ is the minimal length of the recorded sequence of zeros and
ones of a \qnull{program} $P$ that permits construction of the value
of $x$, the value of $y$ being known {\ldots} Although Martin-L{\"o}f
and I realized the importance of the new concept, the development was
hindered because the simplest formulas that can be produced as a
result of simple algebraic transposition of (1) [Shannon's Entropy]
could not be derived from the new definitions (kolmogorov68:662)
**** The preceding rather superficial discourse should 
prove two general theses: 1) Basic information theory concepts must
and can be founded without recourse to the probability theory, and
such a manner that \qnull{entropy} and \qnull{mutual information}
concepts are applicable to individual values. 2) Thus introduced,
information theory concepts can form the basis of the term random,
which naturally suggests that random is the absence of periodicity.
(kolmogorov68:663f)
**** by using probability theory, we resort to 
considerably rougher generalization. A realistic interpretation of
probability results is always statistical, and error estimates are
considerable rougher that in the information theory exposition
developed by us. (kolmogorov68:664)
**** Credit for noting this relatively simple condition 
evidently belongs to Solomonov and me. (kolmogorov68:664) [compare
Matthew Effect]
*** kolmogorov68a
**** Discussions of information theory do not go into this 
combinatorial approach at any length, but I consider it important to
emphasize its logical independence of probabilistic assumptions.
(kolmogorov68a:158)
**** If we make the variable $x$ and $y$ \qnull{random variables} 
with given joint probability distributions, we can obtain a
considerably richer system of concepts and relationships
(kolmogorov68a:161)
**** {\ldots} War and Peace {\ldots} 
(kolmogorov68a:162)
*** loeve55
**** Probability Theory
Synopsis:

(i) Constructive definition of conditional expectation:

\begin{displaymath}
  E_{B}X=\int_{B}XdP
\end{displaymath}

or, equivalently,

\begin{displaymath}
  P(B)E_{B}X=\int_{B}XdP
\end{displaymath}

then define

\begin{displaymath}
  P_{B}A=E_{B}I_{A}
\end{displaymath}

[page 338, more detail 339f]

(ii) the constructive definition fails if partition is not countable
-> use Radon-Nikodym

conditional expectation is a function for which

\begin{displaymath}
  \int_{N}(E^{\mathcal{B}}X)dP=\int_{B}XdP
\end{displaymath}

and

\begin{displaymath}
  P^{\mathcal{B}}=E^{\mathcal{B}}I_{A}
\end{displaymath}

or

\begin{displaymath}
  \int_{B}(P^{\mathcal{B}}A)dP_{\mathcal{B}}=PAB
\end{displaymath}

[page 341]

(iii) then show that the generalized definition accords with the
intuitive, constructive definition where applicable
*** solomonov64
**** That these kinds of models might be valid is 
suggested by \qnull{Occam's Razor,} one interpretation of which is that
the more \qnull{simple} or \qnull{economical} of several hypotheses is
the more likely. Turing machines are then used to explicate the
concepts of \qnull{simplicity} or \qnull{economy}---the most
\qnull{simple} hypothesis being that with the shortest
\qnull{description.} (solomonov64:3)
**** It is possible to devise a complete theory of 
inductive inference using Bayes' Theorem, if we are able to assign an
a priori probability to every conceivable sequence of symbols. In
accord with this approach, it is felt that sequences should be given
high a priori probabilities if they have shortest descriptions and/or
many different descriptions {\ldots} any regularity in a corpus may be
utilized to write a shorter description of that corpus {\ldots} the
high a priori probability assigned to a sequence with a short
description corresponds to one possible interpretation of
\qnull{Occam's Razor.} The assignment of high a priori probabilities
to sequences with many descriptions corresponds to a feeling that if
an occurrence has many possible causes, then it is more likely.
(solomonov64:7)
**** Suppose that all of the sensory observations 
of a human being since his birth were coded in some sort of uniform
digital notation and written down as a long sequence of symbols. Then,
a model that accounts in an optimum manner for the creation of this
string, including the interaction of the man with his environment, can
be formed by supposing that the string was created as the output of a
universal machine of random input. (solomonov64:13)
**** The laws of science that have been discovered 
can be viewed as summaries of large amounts of empirical data about
the universe. (solomonov64:15)
*** turing37
**** Turing (1937) has shown that it is impossible 
to devise a Turing machine that will always be able to tell, in a
finite time, whether an arbitrary string will be \qnull{meaningful}
for another particular universal Turing machine. (solomonov64:9f)
*** wallacedowe99
**** The aim in this stream is to find the hypothesis
$H$ which leads to the shortest such stream $I$, which may be regarded
as the shortest message encoding the data given in $S$ {\ldots} The
minimization of #I [length of the program which reproduces the data
$S$] is, as shown by the equation above, equivalent to maximization of
$h(H) x f(S|H)=Prob(H,S)$, i.e. the joint probability of hypothesis
and data. It is thus formally equivalent to choosing the hypothesis of
highest Bayesian posterior probability given $S$. (271f) [nice summary
on 270 of Kolmogorov Complexity and Turing machines]
*** zhulu04
**** We should also note that, counter-intuitively, non-informative 
priors and flat priors (such as the uniform distribution) do not
coincide (cf.\ Mu and Zhu, 2004)
**** The lesson from this discussion is extremely 
interesting; it tells us that flat priors (such as the uniform prior)
are not always the same thing as non-informative priors. A seemingly
informative prior can actually be quite weak in the sense that it does
not influence the posterior opinion very much. It is clear in our
example that the MLE is the result of using a weak prior, whereas the
most intuitive non-informative prior (the uniform prior) is not as
weak or non-informative as one would have thought. (6)
* chapters
** Chapter Overview 2015-08-18
1. Introduction

The introduction has little original research. This is different for the other chapters, which have little summary of other people's work and mostly my own arguments. The introduction serves to show what the connection is between partial belief reasoning and information theory. The steps are as follows: (1) Bayesian conditionalization does not cover certain cases. There are affine constraints (the formal representation of evidence) which are not conducive to standard conditioning. The Bayesian approach to partial belief reasoning is assumed throughout the thesis. At no point am I trying to convince anyone to be a Bayesian. I am only interested what someone who is already a Bayesian should believe in addition to traditional Bayesian doctrine. That additional piece will be the norms of information theory, which implies that one should not follow popular epistemological currents and allow for indeterminate credal states or endorse the geometry of reason. (2) There are various ideas how one could come up with norms with respect to these affine constraints that are not conducive to standard conditioning. Most of them are eclectic and ad hoc. Information theory, by contrast, provides norms for these cases that cover a great deal of territory and that are intuitively simple. (3) I will give the formal background for Jaynes' principle of maximum entropy and the principle of minimum cross-entropy. These principles give us a clear and general formal methodology to get from affine constraints to updated probabilities. They are in harmony with each other and with Bayesian conditionalization.

2. Judy Benjamin

Judy Benjamin is one of the most compelling counter-examples to the norms of information theory. In this chapter, I show how a more detailed investigation of this alleged counter-example reveals that all is well with the principle of minimum cross-entropy. This is the article I published in Synthese.

3. Maximum Entropy and Probability Kinematics Constrained by Conditionals

Wagner's Linguist scenario is another counter-example to the norms of information theory, much less well-known than Judy Benjamin but in some ways more illuminating. The Linguist scenario is only a counter-example because Wagner assumes indeterminate credal states in the background (he does not address this issue). The counter-example is solved for information theory once we establish that you cannot consistently accept both the norms of information theory AND indeterminate credal states for rational agents. Thus the burden of proof is on me to show that indeterminate credal states for rational agents are a bad idea. This is the article I published in Entropy.

4. Augustin's Concessions: A Problem for Indeterminate Credal States

This chapter seeks to show that indeterminate credal states for rational agents are a bad idea. It is basically finished, although it will go through more editing as I gather external feedback.

5. Asymmetry and the geometry of reason

This is the chapter I am currently working on. I have it basically finished and already presented it at the Causal and Probabilistic Reasoning conference at the Munich Center for Mathematical Philosophy. I was especially pleased that Wolfgang Spohn thought I had a knock-down argument against the geometry of reason, although he doesn't care much for James Joyce's epistemic utility approach, which is fundamental to the geometry of reason. This chapter seeks to show that the geometry of reason (which imposes a Euclidean topology on probability distributions/credence functions) disappoints a whole host of reasonable expectations one would have. The best alternative to the geometry of reason is information theory. The topology that information theory imposes on credence functions is much more complicated than the Euclidean topology. Most relevantly, it is asymmetrical, so it's not even a proper metric.

I am currently struggling with what seems to be a deep problem with this asymmetric topology. The asymmetries are astonishingly irregular. I can't imagine an epistemic justification for this irregularity. The geometry of reason, of course, is super-regular (because it is symmetric) -- that can't be right either. This chapter shows how the symmetry conflicts with some very basic intuitions we have about credence functions.

Epistemic justification and asymmetry are still a mystery to me. If I manage to solve it, there may be another chapter dealing with this problem.

6. Prevision Betting

This chapter could be optional, depending on the desired length for the dissertation. When I worked on indeterminate credal states, I noticed that despite my opposition to them they have a very interesting property which seems to have gone unnoticed: they beat sharp credences in simple betting scenarios. Peter Walley has a very short appendix about this in his book on imprecise credences, but I think I can show with much greater formal rigour how right he was on this issue, defending imprecise credences. The purpose of this chapter would be to defuse this problem for sharp credences, and I have a pretty good idea on how this could be done. I have some of the formal apparatus worked out for this chapter, but only a few pages of writing.

7. Conclusion

Pulling everything together: (1) Counter-examples to information theory can be shown to be not as compelling as they are at first blush. (2) Information theory beats the geometry of reason (advocated by people like Jim Joyce, Hannes Leitgeb, Richard Pettigrew) hands down. (3) Information theory and a rejection of indeterminate credal states are wedded to each other. This is a problem since indeterminate credal states are very popular now. In summary, information theory should be taken much more seriously in formal epistemology, not just as a tool, but as a norm with a great deal of generality.
** Epistemology and Evidence
*** Ideas
**** This is a paper about
the difference between what is evidential and what is epistemological.
Here is a good line by Romeijn: ``I think it is rather natural to
explore the idea that it after all comes from evidence and so can be
subsumed under normal evidence handling.''

The reason why this is important becomes clear when you read Huisma's
job offer example, where something that is clearly evidential suddenly
becomes relevant epistemologically:

``It is easy to come up with examples in which MAXENT fails. My job
offer story is one of them. By the way, the information Harry receives
does alter his credences. His prior is affected by the knowledge that
Tom would like to move west. That is why his credence that Tom will
accept the job offer given that the offer comes with a relocation to
San Francisco is high and his credence that Tom will accept the job
offer given that the job offer comes with a relocation to New Jersey
is low. He just doesn't know yet which of these two possibilities
applies to the actual job offer. He updates according to the first one
when he learns from Sue that the job offer is likely to come with a
relocation to the West. All these examples obviously also indicate
that there is something amiss with the Shore and Johnson axioms.''
(personal email)

See also two levels in prospectus.tex and Carrie Jenkins' thoughts on
this. 
**** What is information? It is a 
mathematical object, like geometry for Poincare (see Mojtaba). It
relates to evidence the way geometry relates to physical space. 
*** Old Evidence
this is the file evidence.org from a while ago with some useful information
**** levi
the subjective Bayesian conception of perfect rationality entails
perfect accuracy about one's own credences (Milne, 1991, A Dilemma)

what is evidence? 

C.I. Lewis
certain
P(E)=1

R. Jeffrey
uncertain
P(E)<1 or P(E)=1

I. Levi
uncertain
P(E)=1

interesting case on page 206 of Levi.

Having admitted no new evidence at time $t'$, Jones at that time ought
surely to consider the draw from the urn to be a `random' one.
$\mbox{prib}(E|H)$ ought surely to equal $\mbox{prob}(E|H)$. Yet,
Jeffrey's procedure would require otherwise. If $\mbox{prob}(E)$ does
not equal $\mbox{prib}(E)$ but $\mbox{prob}(H|E)=\mbox{prib}(H|E)$, as
it does according to Jeffrey's principle, coherence dictates that
$\mbox{prib}(E|H)$ cannot equal $\mbox{prob}(E|H)$. (see for this levi.tex)
**** correspondence
***** 2010-08-07 to Paul Bartha
Paul,

Here is a brief heads-up about what I want to talk about to you. I am
mostly concerned about my SSHRC application and want to make sure I at
least give myself a chance by being more focused on a particular,
viable issue. As you know, I have been vaguely (!) interested in the
philosophy of science and epistemology, more particularly in Bayesian
epistemology. I really enjoyed writing my paper about prior
probabilities for your course a few years ago. I have since then done
my seminars for the Master's Degree and, on the one hand, picked up a
few other interests (again rather vaguely related to ethics and the
philosophy of mind), on the other hand, learned that to be
philosophically productive I need to be more specific about what it is
I want to think about and work on. This hasn't been an easy process as
I tend to be all over the map with my interests, but about six months
ago I realized that the concept of evidence would make a nice
condensation point for interests I've already entertained for a while.
I didn't take any courses last term (I was going to, but UBC didn't
allow it as I had already completed my program), and so I was free to
do my own reading to get an overview of the topic ``evidence.''

I feel like there are two avenues available to me: (1) I could focus
on the debate between internalists and externalists and try to give an
account of evidence in externalist terms. Richard Feldman is the
internalist that I've read most of, his evidentialism (together with
Earl Conee) claims that epistemically justified beliefs supervene on
evidence. This is quite similar to what Bayesian epistemologists would
say, except that Feldman and Conee are classical foundationalists,
where some beliefs are justified without reference to other beliefs
(e.g. Sosa's indexical, phenomenological, and SGA, simple geometric
and arithmetic, beliefs), whereas Bayesians would consider subjective
probabilities as their foundation. Feldman has been quite detailed
about what he considers to be the evidence on which, given
supervenience, we must base our beliefs if we desire epistemic
justification. Feldman doesn't shy away from deontological
epistemology, but again, he is quite specific and detailed about what
that means. I like Feldman's style and thinking. 

But then, there is externalism. When I wrote my paper about Hartry
Field's apriori, I first came across Tyler Burge, his
anti-individualism, content preservation, and perceptual entitlements.
I was curious to see what an externalist, Burge-inspired account of
evidence would look like, for it must look quite different than
Feldman's. (Two people may have exactly the same evidence but one
ought to believe that a tiger killed the man, while the other ought to
believe that it was a shmiger---our mental states, including our
propositional attitudes, are not independent of our relations to our
physical and social environment.) The best I could find of such an
externalist account (the best was quite good in this case!) was
Timothy Williamson's The Limits of Knowledge. It's a great book (beach
reading in South Carolina, in my case), accounting for knowledge as a
primary and prime epistemological concept. ``Prime'' means more
specifically that knowledge cannot be dissected into internalist
(justified plus X) and externalist (true) components, ``primary''
means more generally that knowledge should be the starting point of
epistemological thinking, having justification, belief, and warrant in
its wake rather than being a composite of such notions. (Williamson
compares the philosophical concept of knowledge to the mathematical
concept of a set: both are powerful in building theory, but it is not
possible to give a sharply defined theoretical account of them.)

Williamson's understanding of knowledge is strictly externalist: what
we know is not determined only by what is going on in our minds, as
knowledge must always be of true propositions (Williamson maintains
that knowledge is always propositional, and he is not a coherentist
about truth); but knowledge is also, and here Williamson shows his
true externalist colours, a mental state. So knowledge is a mental
state that is irreducibly linked to how things are in our physical and
social environment. What then is evidence? Williamson says E=K,
evidence and knowledge are co-extensive. This is surprising, but
Williamson makes a good case. Even on a Bayesian account, where P[old](E)
may be a number strictly between 0 and 1, once we conditionalize on E
our new probability function P[new](E)=1 (knowledge!), as
P[new](H)=P[old](H|E) and thus P[new](E)=P[old](E|E)=1.

There is a lot to think about here. Although Williamson's account of
evidence is highly virtuous (how simple: E=K!), there are problems. It
is not generally intuitive that our evidence can't sometimes be false,
although we sincerely believe it is evidence. In Feldman's case, of
course, this happens all the time, because, terribly simplified, as
far as Feldman is concerned, E=B, B being a specified set of beliefs.
What the detective knows is part of her evidence (what she herself
witnessed or now knows based on reliable testimony), but aren't there
other parts of her evidence which are not sufficiently justified to
constitute knowledge? Both Feldman and Williamson address this
question and draw very interesting conclusions about self-knowledge,
skepticism, and, as Williamson calls it, luminosity. Williamson
basically says that we just don't know what we know (knowledge is
non-luminous, and so are all other epistemologically interesting
mental states, thus the title The Limits of Knowledge)---and that's
precisely what justifies us in NOT being skeptical about our
environment.

I think that's enough of a topic. What is evidence, mostly in
externalist terms, as the internalists already have a good idea of
what they mean by it and the debate is more technical about whether
the beliefs that are our evidence are accessible or occurrent or some
type of mixture of both. But is there an alternative to Williamson's
externalist account of evidence? Perhaps not, I don't know, as I don't
know whether internalism or externalism is correct, but the
possibilities of saying something of interest seem to be there. There
are also all sorts of instructive associations with Bayesian
epistemology, both in the externalist and in the internalist picture.

exotic/quixotic

(2) Here is the problem I have with Williamson's account: I find it
hard to believe that when we form and test a (scientific) hypothesis
we base it on knowledge, compare i with alternative hypotheses and
then pick out the best one, always holding our evidence fixed because
we already know it. This, I suppose, is Quine's picture of science
always being underdetermined by the data, allowing for alternative
hypotheses based on the data we have secured. By contrast, I would
suggest that in most cases our data overdetermine our science. We have
too much data, not too little. The first consequence is that our
evidence is not as secure as Williamson has us believe. As we evaluate
our hypotheses we concurrently evaluate our evidence (also a Quineian
thing, I guess). On Williamson's picture this is impossible, as the
probability of our evidence must always be 1, which puts it beyond
doubt.

What is it then that decides between <E,H1> and <E,H2>, if both pairs
exhibit the overdetermination I just talked about? My proposition is
that it is the amount of information given: whichever hypothesis,
together with our evidence, delivers less information is the BETTER
hypothesis. I first ran into the information idea when I wrote the
paper about prior probabilities. Back then it was used to give
preference to sets of prior probabilities: the less information the
better (the principle of indifference is entailed, as not being
indifferent is too much information). I find it interesting that
information is hardly talked about in epistemology, given that just as
is the case with probabilities there is some hard math associated with
information that could be very instructive. My favourite is Shannon's
Information Entropy, the only quantity which is positive, increases
with increasing uncertainty and is additive for independent sources of
uncertainty (sounds like Kolmogoroff's axioms for probability---but
the math is quite different!). The worst case scenario for <E,H> is if
it contains a contradiction: that's information overload, as a
contradiction would severely constrain reality. (Information, as I
understand it now, is a constraint on the actual world, for example:
``this car is blue'' contains the information that the car is blue,
not red, which is a constraint on what this world is like. One could
say that ``this car is blue and it is not blue,'' being a
contradiction, would make all propositions true, and so suddenly lift
all constraints on the actual world. This contradicts what I just said
earlier, so I obviously need to work out the details and lift the fog
from my currently obfuscated thinking.)

Another interesting consequence of this idea is that if my science is
underdetermined by my data I cannot get away with any old hypothesis
that is consistent with my evidence. It must also be the hypothesis
which together with my evidence yields the minimum amount of
information. I am not permitted to insert prejudice at this point. In
fact, the best hypothesis would be the one that gives their proper
places to all the hypotheses that are consistent with the evidence, if
possible with probability assignments as Bayesian epistemology would
do it if it had all the numbers. There is an interesting parallel here
between Bayesian epistemology and what you might call ``information
epistemology.'' Both can be mathematically precise, but both work in
practice on presenting a persuasive pattern about holding certain
beliefs together and revising them.

I realize that this may be another instance of my exotic/quixotic
philosophical quests when I should be concentrating on more viable,
technical issues, for example (1). I would love to talk this through
with you, as well as more mundane issues to pay attention to as I put
together my SSHRC application and begin PhD studies. How keen should
one be on narrowing down one's philosophical interests in order to
prepare for the PhD thesis? How small should the projects be that one
undertakes initially? I jealously remember Roger's presentation on the
Raven's Paradox which was so wonderfully concise, unpretentious, and
valuable. Anyways, enough to talk about. I'll be in touch with you
about a post August 15 appointment.

Stefan
**** book summaries
***** Timothy Williamson: Knowledge and Its Limits
****** summary
***** Earl Conee and Richard Feldman: Evidentialism
****** summary
(1) Earl Conee: First Things First

Deals with skepticism. Nothing interesting, except the conclusion,
which concludes that evidence is an epistemic first cause. Evidence
lets us challenge our first reasons. ``It makes possible a wholly
reasonable and universal epistemology'' (36)

(2) Earl Conee: The Basic Nature of Epistemic Justification

Coherentism and Foundationalism (37)

Externalism and Internalism (46)

A Comprehensive Unification (51)

combine ``foundational coherentism'' with ``external internalism''

(3) Conee and Feldman: Internalism Defended

What Is Internalism? (54)

good quotes from leading internalists (Plantinga, Steup, Pollock, and
Sosa)

actually, leading critics of internalism are (61) Goldman, Plantinga,
and William Alston

Supervenience of doxastic attitudes on mental states (S) and the same
beliefs are justified for mental duplicates (M) (56)

critics of internalism tie internalism to deontology, but that's
wrong, say Conee and Feldman: ``blameless belief is not always
justified'' (63), with examples.

stored beliefs, forgotten evidence, and concurrent retrieval

Conee and Feldman prefer mentalism to accessibilism (81)

there is a response to Timothy Williamson on (81)

(4) Conee and Feldman: Evidentialism

Doxastic attitude D toward proposition p is epistemically justified
for S at t if and only if having D toward p fits the evidence S has at
t. (83) [for a definition without the word fit see (102)]

justification and responsible action (acquiring evidence when you
ought to): Conee and Feldman versus Kornblith

``it is appropriate to speak of epistemic obligations. But it is a
mistake to think that what is epistemically obligatory, i.e.,
epistemically justified, is also morally or prudentially obligatory,
or that it has the overall best epistemic consequences'' (92)

the principle of well-foundedness WF (93), followed by a response to
reliabilism (BonJour's clairvoyant)

good summary and conclusion on (100)

in the afterword, Conee and Feldman speak of their bedrock epistemic
view as a supervenience thesis:

``The epistemic justification of anyone's doxastic attitude toward any
proposition at any time strongly supervenes on the evidence that the
person has a the time'' (101)

Fantl and McGrath's criticism: pragmatic considerations (Morton's
fire and locked door example). Same situation (locked door), same
evidence, different situations, different doxastic attitudes.

(5) Richard Feldman: Authoritarian Epistemology

difference between epistemic, moral, and prudential justification for
believing a proposition see quote on (112)

example of the logic student and half theorems, half non-theorems in
the back of the logic book (112f).

Foundationalism: Chisholm, Pollock, Fumerton. ``brute epistemic
facts.'' (117) 

Authoritarian Epistemologies:

(a) Individual Subjectivism (Richard Foley, John Pollock): it is
epistemically rational to believe a proposition if sufficient
reflection would support it. S's ``deepest epistemic standards''
(119).

(b) Expertism, same as (a), but deepest epistemic standards are replaced by an
epistemic authority (Nelson Goodman, Richard Nisbett, previously
Stephen Stich)

(c) Supernaturalism (Alvin Plantinga) (121).

Richard Feldman responds with Socrates' challenge to Eutyphro: is the
pious loved by the gods or is what is loved by the gods pious.

LJ Cohen's analogy between language and epistemology (131)

(6) Conee and Feldman: The Generality Problem for Reliabilism

Conclusion: the generality problem for reliabilism is not solvable.

``beliefs are justified by fitting the perceptual evidence, however
infrequently the belief-forming processes tend to produce truths'' (in
a deceptive world, for example)

(7) Richard Feldman: The Ethics of Belief

Good stuff on epistemic deontologism and doxastic voluntarism (166f)

``It is wrong, always, everywhere, and for anyone to believe anything
upon insufficient evidence'' (William K. Clifford) (176)

Epistemic Value (181f) Richard Feldman thinks we ought to not believe
on insufficient evidence and believe on sufficient evidence.

``We avoid the problems associated with identifying epistemic value
with true belief or knowledge if instead we say that what have
epistemic value are rational beliefs '' (184) ... ``rationality
consists in making one's belief conform to one's evidence'' (185)
[but, according to Quine, there are always ways of making your belief
conform to you evidence, in my scheme you'd also want to pursue
information density]

Three objections: (a) evidence one should have had, (b) the duty to
gather evidence, (c) being rational by avoiding evidence

(8) Richard Feldman: The Justification of Introspective Beliefs

Two theses characterize foundationalism. One is that there are beliefs
are propositions whose justification does not depend on other beliefs.
Beliefs or propositions that have this status are said to be basic or
foundationally justified. The second foundationalist thesis is that
everything that is non-foundationally justified has that status in
virtue of its relation to things that are foundationally justified. A
third thesis characterizes what is plausibly described as classical
foundationalism. This is the idea that internal (or mental) factors
determine which believes are justified. In particular, external
factors such as contingent reliability or causal connectedness are not
among the conditions for justification, unless they are implied by the
internal factors. (199)

Sosa's critique (which Feldman
is trying to dispel): 48 and 3 speckles.

Sosa's three kinds of concepts (in ``Privileged Access''): indexical,
phenomenal, and SGA (simple geometric and arithmetic) (205).

(9) Richard Feldman: Having Evidence

Coherence Theory, defended by BonJour, Structure of Empirical
Knowledge.

What is evidence: what you are currently thinking of, what you can
retrieve, etc.? (Feldman thinks the former, with qualifications.)

(10) Earl Conee: The Truth Connection

What is the knowledge-truth connection?

(11) Earl Conee: Heeding Misleading Evidence

Professor Smith's belief that it is raining on the Olde Quadd at noon
(although it is film crews producing that effect). Sometimes, you can
be lisled out of knowing.

(12) Conee and Feldman: Making Sense of Skepticism

Non-Evidentialist Theories (280f): (a) causal theory (Alvin Goldman): belief is
causally connected to the facts in the right way. (b) tracking theory
(Robert Nozick). (c) reliabilism. (d) proper function theory (Alvin
Plantinga). A belief is warranted iff it results from the proper
functioning of the believer's cognitive system in a suitable
environment (two more conditions) (281). These Non-Evidentialist
Theories are often combined with contextualism.

``According to the externalist concept, an experience provides
evidential support for a belief provided there is a reliable cognitive
process that begins with the experience and yields the belief.
According to the internalist concept, evidential support is understood
in terms of influence on subjective probabilities. Since purely
sensory features of sense experiences can influence the strength of
beliefs about the external world, on this conception they can be
evidence for external world propositions. Since brains in vats or
victims of deceptive demons adjust their subjective probabilities in
light of experiences in just the way in which normal people do, their
experience have the same (internalist) evidential value as the
experiences of normal people. But the reliable connections differ, so
their experiences do not have the same (externalist) evidential value
as the experience of normal people. In Hill's view, since it is the
externalist evidential value that is actually crucial for knowledge,
the skeptic's argument fails. Hill says that there is a tendency to
confuse these two conceptions of evidential support, and this explains
the appeal of the skeptical argument to non-skeptics. Granting for the
sake of argument that there were these two concepts of evidential
support [Footnote: we doubt that these are pre-theoretical conceptions
of evidential support. In our view, the proposed internalist
conception of evidence is an implausible psychological reduction of
the relation of evidential support, and the externalist conception is
a reliabilist's invention.], we find here no explanation of the appeal
of the skeptical argument. Presumably, the appeal is supposed to
derive from our considering the argument while thinking of the
internalist notion of evidential support, subjective probability. (The
argument obviously has no appeal while thinking of the externalist
notion.) However, using the internalist notion, the argument is
distinctly unappealing. Both ordinary people and they are envatted
counterparts find themselves strongly inclined to believe the ordinary
external world propositions on the basis of their sensory experiences.
None of them has any inclination to believe skeptical hypotheses on
the basis of their experiences. Hence, if people were using the
internalist notion in thinking about skeptical arguments, they would
conclude that the experiences provide a vastly better evidential
support for ordinary external world beliefs than for skeptical
hypotheses. So the skeptical argument would obviously fail.'' (289)
**** quotes
***** Feldman, Richard, and Conee, Earl
****** Earl Conee and Richard Feldman: Evidentialism
******* Evidence is an 
epistemic first cause. (Earl Conee and Richard Feldman: Evidentialism,
36)
******* [argument against evidentialism 
Jeremy Fantl and Matthew McGrath (fantlmcgrath02)] (coneefeldman04,
103)
******* [difference between a belief being prudent, morally justified, and 
epistemically justified] (coneefeldman04, 112)
******* By an evidentialist standard, it does not matter 
if some such possibility of of obscurely false beliefs is actual. The
beliefs are justified by fitting the perceptual evidence, however
infrequently the belief-forming processes tend to produce truths. This
seems to us to be the intuitively correct result. In contrast,
theories that rely on reliability are in trouble if the truth
tendencies of ordinary beliefs are much worse than people usually
think. (coneefeldman04, 165)
******* defenses of coherence theory 
lehrer74, bonjour85 (coneefeldman04, 224)
******* five non-evidentialist theories 
(coneefeldman04, 280)
******* 
***** Putnam, Hilary
****** Hilary Putnam: The Collapse of the Fact/Value Dichotomy
******* As the economist-philosopher Vivian Walsh 
has written, ``To borrow and adapt Quine's vivid image, if a theory
may be black with fact and white with convention, it might well (as
far as logical empiricism could tell) be red with values. Since for
them confirmation or falsification had to be a property of a theory as
a whole, they had no way of unraveling this whole cloth.'' Thus
Walsh (and before him, Quine's friend Morton White) made the point
that after Carnap's abandonment (between 1936 and 1939) of the picture
of ``factual'' sentences as individually capable of confrontation with
sense experience (which was, as we have seen, just the traditional
empiricist picture) and Quine's critique of the logical positivists'
picture of what they called the language of science as neatly divided
into a ``factual'' part and an ``analytic'' part, the whole argument for
the classical fact/value dichotomy was in ruins, and that, "as far as
logical empiricism could tell," science might presuppose values as
well as experiences and convention. Indeed, once we stop thinking of
``value'' as synonymous with ``ethics,'' it is quite clear that it does
presuppose values---it presupposes epistemic values.  (Hilary Putnam,
The Collapse of the Fact/Value Dichotomy, 30)
*******  The classical pragmatists, Peirce, James, Dewey 
and Mead, all held that value and normativity permeate all of
experience. In the philosophy of science, what this point of view
implied is that normative judgments are essential to the practice of
science itself. These pragmatist philosophers do not refer only to
the kind of normative judgments that we call ``moral'' or ``ethical'';
judgments of ``coherence,'' ``plausibility,'' ``reasonableness,''
``simplicity,'' and of what Dirac famously called the beauty of a
hypothesis, are all normative judgments in Charles Peirce's sense,
judgments of ``what ought to be'' in the case of reasoning.  (Hilary
Putnam, The Collapse of the Fact/Value Dichotomy, 30f)
******* Carnap tried to avoid admitting this 
by seeking to reduce hypothesis-selection to an algorithm---a project to
which he devoted most of his energies beginning in the early 1950s,
but without success. In Chapter 7, I shall look in detail at this and
other unsuccessful attempts by various logical positivists (as well as
Karl Popper) to avoid conceding that theory selection always
presupposes values, and we shall see that they were, one and all,
failures.  (Hilary Putnam, The Collapse of the Fact/Value Dichotomy,
31)
******* As Williams admits, it seems impossible 
to explain in "absolute" terms how "content" is possible-that is, how
thought, belief; and reference are possible.  (Hilary Putnam, The
Collapse of the Fact/Value Dichotomy, 44)
******* recognizing that our judgments claim 
objective validity and recognizing that they are shaped by a
particular culture and by a particular problematic situation are not
incompatible  (Hilary Putnam, The Collapse of the Fact/Value
Dichotomy, 45)
******* I showed, first, that both historically and conceptually 
those arguments originated in an impoverished empiricist (and later in
an equally impoverished logical positivist) conception of fact, and
second, that if we do not see that facts and values are deeply
``entangled'' we shall misunderstand the nature of fact as badly as
logical positivists understood the nature of value.  (Hilary Putnam,
The Collapse of the Fact/Value Dichotomy, 46)
******* that vocabulary consists almost entirely 
of ``entangled'' concepts, concepts that connot be simply factored
into a ``descriptive part'' and an ``evaluative part.''  (Hilary
Putnam, The Collapse of the Fact/Value Dichotomy, 62)
******* As Peirce once put it, in science we do not 
have or need a firm foundation; we are on swampy ground, but that is
what keeps us moving.  (Hilary Putnam, The Collapse of the Fact/Value
Dichotomy, 102)
******* There is an objection I recall having once seen 
Lyotard make against Habermasian discourse ethics, to the effect that
discourse ethics marginalizes or excludes the ``inarticulate.''
(Hilary Putnam, The Collapse of the Fact/Value Dichotomy, 130, Putnam
thinks this objection is unfair because we ought to listen to
``William James' beautiful demand that we "listen to the cries of the
wounded"'', 131)
******* Madmen sometimes have consistent
delusional systems; so madness and sanity can both have a `circular'
aspect. I may not have succeeded, in this paper, in breaking the
'delusional system' of a committed logical behaviourist; but I hope to
have convinced the uncommitted that that system need not be taken
seriously. If we have to choose between 'circles,' the circle of
reason is to be preferred to any of the many circles of unreason.
(Hilary Putnam, 54, Brains and Behavior)
***** Williamson, Timothy
****** Timothy Williamson: Knowledge and Its Limits
******* If I had to summarize this book in two words 
they would be: knowledge first. It takes a simple distinction between
knowledge and ignorance as a starting point from which to explain
other things, not as something itself to be explained. In that sense
the book reverses the direction of explanation predominant in the
history of epistemology. (Timothy Williamson: Knowledge and Its
Limits, v)
******* Once we cease to assume that belief is 
conceptually prior to knowledge, we can experiment with using the
concept of knowledge to elucidate the concept of justification and
evidence. Chapter 9 makes the experiment. It argues that one's total
evidence is simply one's total knowledge. The hypothesis is
inconsistent with the evidence if and only if it is inconsistent with
known truths; it is a good explanation of the evidence if and only
if it is a good explanation of known truths. One's evidence justifies
belief in the hypothesis if and only if one's knowledge justifies that
belief. Knowledge figures in the account primarily as what justifies,
not as what gets justified. (Timothy Williamson, Knowledge and Its
Limits, 9)
******* What results is the rule that one should 
judge (or believe $p$) only if one knows $p$. That would make some
sense of the claim that belief aims at knowledge. It also harmonizes
with the account of evidence: to believe $p$ without knowing $p$ is to
exceed once evidence. Although we may have qualms about applying the
notion of a rule to mental acts in addition to speech acts, the idea
that belief is governed by a norm of knowledge is at least as
intelligible as the idea that it is governed by a norm of truth.
(Timothy Williamson, Knowledge and Its Limits, 11)
******* See also Fodor 1998 for a discussion 
of the demise of definition. (Timothy Williamson, Knowledge and Its
Limits, 31)
******* The main idea is simple. A propositional 
attitude is factive if and only if, necessarily, one has it only to
truths. Examples include the attitudes of seeing, knowing, and
remembering. Not all factive attitudes constitutes states; forgetting
is a process. Call those attitudes which do constitute states stative.
The proposal is that knowing is the most general factive stative
attitude, that which one has to a proposition if one has any factive
stative attitude to it at all. Apparent counterexamples to this
conjecture are discussed below. The point of the conjecture is to
illuminate the central role of the concept of knowing in our thought.
It matters to us because factive stative attitudes matter to us.
(Timothy Williamson: Knowledge and Its Limits, 34)
******* Furthermore, the claim that belief is what 
aims at knowledge is consonant with the suggestion in disjunctive
accounts that illusion is somehow parasitic on veridical perception.
Properly developed, the insight behind disjunctive theories leads to a
non-conjunctive account of knowledge and a non-disjunctive account of
belief. (Timothy Williamson: Knowledge and Its Limits, 48)
******* The idea that the mental (or psychological)
component of knowing is simply believing seems to be expressed in a
remark by Stephen Stich, endorsed by Jaegwon Kim: ``what knowledge
adds to belief is psychologically irrelevant'' (Stich 1978:574, quoted
in Kim 1993:188; Kim 1993:175--193 is a clear statement of the kind
of view opposed here).  (Timothy Williamson, Knowledge and Its Limits,
55)
******* A condition C is composite if and only if 
it is the conjunction of some narrow condition D. with some
environmental condition E. As a special case, a narrow mental
condition is trivially composite, for it is the conjunction of itself
with the environmental condition that holds in all cases whatsoever. C
is prime if and only if it is not composite. The line of thought that
began with the here-and-nowness of causation led to the conclusion
that mental conditions are composite. (Timothy Williamson: Knowledge
and Its Limits, 66)
******* We should not assume without argument that 
subatomic physics will embody locality principles of the kind that
would guarantee a clear-cut distinction between those features which
contribute to internal physical states and those which do not. The
arguments for primeness are not restricted to mental conditions; they
apply to other sorts of physical condition too. (Timothy Williamson:
Knowledge and Its Limits, 74)
******* Consider also Putnam's example 
(1978:42): ``Professor X is found stark naked in the girls' dormitory
at 12 midnight. Explanation: (?) He was stark naked in the girls'
dormitory at midnight minus epsilon, and he could neither leave the
dormitory nor put on his clothes by midnight without exceeding the
speed of light. But (covering law:) nothing (no professor, anyhow) can
travel faster than light.'' (Timothy Williamson: Knowledge and Its
Limits, 76)
******* Our best theory is intended to capture 
significant generalizations. The action would have been performed in
many cases other than alpha, in which D and E does not obtain; D and E
is sufficient but nothing like necessary for F. A theory which relies
on conditions like D and E may leave uncaptured a significant
generalization relating F to C. What has not been shown is that
significant generalizations about prime conditions can be replaced by
significant generalizations about compound conditions. (Timothy
Williamson: Knowledge and Its Limits, 81)
******* Luminous conditions are curiosities. Far from forming 
a cognitive home, they are remote from ordinary interests. The
conditions with which we engage in our everyday life are, from the
start, non-luminous. (Timothy Williamson: Knowledge and Its Limits,
109)
******* Therefore we must use methods to reach 
the truth. Rationality is a method. We can follow rules of rationality
because we are always in a position to know what they require. If the
argument of section 8.6 is correct, this picture of rationality is
mistaken. Just as one cannot always know what one's evidence is, so
one cannot always know what rationality requires of one. Just like
evidence, the requirements of rationality can differ between
indiscriminable situations. Rationality may be a matter of doing the
best one can with what one has, but one cannot always know what one
has, or whether one has done the best one can with it. (Timothy
Williamson: Knowledge and Its Limits, 179)
******* Nothing has been said here to undermine 
that requirement. In still more problematic contexts, paradoxes throw
all of our very standards of rationality into doubt, and we fall back
still further on what workable methods we can find. Cognition is
irremediably opportunistic. (Timothy Williamson: Knowledge and Its
Limits, 180)
******* We can fall into skepticism if we 
attribute too much self-knowledge to the subject in bad cognitive
circumstances, for the asymmetry in knowledge between the good and bad
cases requires an asymmetry in self-knowledge. Once we relax our
claims to self-knowledge, we strengthen our claim to knowledge of the
external world. Skeptical arguments fail when the depend on exempting
an internal world of appearances for they depend on misconceiving
appearances as just what they appear to be. The ruthless skeptic
grants no exceptions. If the skeptic must argue that we never even
know how things appear to us, should we still harbor the sneaking
suspicion that skepticism is right after all? (Timothy Williamson:
Knowledge and Its Limits, 183)
******* Tradition has it that the main problems 
of philosophy include the nature of knowledge. But in recent decades
questions of knowledge seem to have been marginalized by questions of
justification. Thus, according to Crispin Wright, "knowledge is not
really the proper central concern of epistemological-skeptical inquiry
... we can live with the concession that we do not, strictly, know
some of the things we believe ourselves to know, provided we can
retain the thought that we are fully justified in accepting them"
(1991:88; Wright's italics). Similarly, John Earman argues that
accounts of knowledge are irrelevant to the philosophy of science,
because in it ``the main concern is rarely whether or not a scientist
`knows' that some theory is true but rather whether or not she is
justified in believing it'' (1993:37). Once Gettier showed in 1963
that justified true belief is insufficient for knowledge, and
therefore that knowledge is unnecessary for justified true belief, it
became natural to ask: if you can have justified true beliefs, why
bother with knowledge? (Timothy Williamson: Knowledge and Its Limits,
184)
******* On that supposition, if justified belief is 
central to epistemological-skeptical inquiry and the philosophy of
science, then so too is knowledge. Now assume further that what
justifies belief is evidence (this assumption is briefly discussed in
section 9.8). Then the supposition just made is equivalent to the
principle that knowledge, and only knowledge, constitutes evidence.
This chapter defends that principle; it equates S's evidence with S's
knowledge, for every individual or community S and any possible
situation. Call this equation E=K. (Timothy Williamson: Knowledge and
Its Limits, 185)
******* The proposed account uses the concept of 
knowledge in partial elucidation of the concept of evidence and
justification. To some people it will therefore seem to get things
back to front. For although knowledge is more than justified true
belief, many philosophers still expect to use concepts such as
evidence and justification in a more complex explanation of the
concept knows; it would then be circular to use the latter to explain
the former. Others prefer to use concepts of a different kind, such as
causation or reliability, to explain the concept knows; but even they
are likely to regard the concept knows as so much in need of
explanation itself that its pre-theoretic use would lack explanatory
value. (Timothy Williamson: Knowledge and Its Limits, 185)
******* As chapter 8 noted, alternative theories of 
evidence distort the concept in the attempt to make evidence something
that we can infallibly identify. Characteristically, they interiorize
evidence; it becomes one's present experience, one's present degrees
of belief, or the like. Those attempts are quaint relics of Cartesian
epistemology. Knowledge of the present contents of one's own mind is
neither unproblematic nor prior to knowledge of other things. It is
not obvious to me how many shades of blue I am presently experiencing,
or to what degree I believe that there was once life on Mars. If one's
evidence were restricted to the contents of one's own mind, it could
not play the role that it actually does in science. The evidence for
the proposition that the sun is larger than the earth is not just my
present experiences or degrees of belief. (Timothy Williamson:
Knowledge and Its Limits, 193)
******* I have seen draws 1 to n; each was red {\ldots}
Consider two false hypotheses: h: Draws 1 to n were red; draw n+1 was
black. h[star]: Draw 1 was black; draws 2 to n+1 were red. (200)
******* That propositional evidence is knowledge entails that 
propositional evidence is true. That is intuitively plausible; if
one's evidence included falsehoods, it would rule out some truths, by
being inconsistent with them. One's evidence may make some truths
improbable, but it should not exclude them outright. Although we may
treat false propositions as evidence, it does not follow that they are
evidence. (Timothy Williamson: Knowledge and Its Limits, 201)
******* The maxim ``Proportion your belief to your evidence'' requires 
more than the mere internal coherence of one's belief system; it does
so because evidence must be true. (Timothy Williamson: Knowledge and
Its Limits, 202)
******* It takes a particularly sharp form in a Bayesian 
context. The standard way of accomodating new evidence e is by
conditionalizing on it. The new unconditional  probability of a
proposition is its old probability conditional on e {\ldots} In
particular, P new(e)=P old (e|e)=1. (Timothy Williamson: Knowledge and
Its Limits, 205)
******* For Maher (Subjective and Objective Confirmation, 158), ``E is
evidence iff E is known directly by experience.'' (Timothy Williamson:
Knowledge and Its Limits, 207)
******* It can be argued that the subjective Bayesian conception 
of perfect rationality entails perfect accuracy about one's own
credences (Milne, 1991, A Dilemma {\ldots}). (Timothy Williamson:
Knowledge and Its Limits, 210)
******* What then, are probabilities on evidence? We should resist demands 
for an operational definition; such demands are as damaging in the
philosophy of science as they are in science itself. To require
mathematicians to give a precise definition of ``set'' would be to
abolish set theory. Sometimes the best policy is to go ahead and
theorize with a vague but powerful notion. (Timothy Williamson:
Knowledge and Its Limits, 211)
******* non-Bayesian theories of evidential probability 
in the literature. See e.g. Kyburg 1974 and Plantinga 1993 (Warrant
and Proper Function). (Timothy Williamson: Knowledge and Its Limits,
213)
******* Both BCOND [Bayesian Conditioning] and JCOND [Jeffreys Conditioning] 
allow propositions to acquire probability 1, but not to lose it. They
are asymmetric between past and future. Thus a model on which all
updating is by Jeffrey [sic!] or Bayesian conditionalization embodies
the empirical assumption that evidence is cumulative, in the sense of
MONOTONICITY. In many cases this assumption is false. Bayesians have
forgotten forgetting. (Timothy Williamson: Knowledge and Its Limits,
219)
******* Subjective Bayesians might identify one's evidence 
with one's beliefs (understood as propositions of subjective
probability 1) rather than with one's knowledge (E=B). Given E=B, one
can manufacture evidence for one's favourite theories by manipulating
oneself into a state of certainty about appropriate propositions
{\ldots} That does not capture the spirit of the injunction to
proportion one's belief to one's evidence. (Timothy Williamson:
Knowledge and Its Limits, 222)
***** Quine, WOV
****** WOV Quine: From Stimulus to Science
******* God is by definition good, He would not 
give us a clear and distinct but false idea.  (WOV Quine, From
Stimulus to Science, 4)
******* Unlike the old epistemologists, we seek 
no firmer basis for science than science itself  (WOV Quine, From
Stimulus to Science, 16)
******* It has been held by positivists of one or 
another stripe over the past century or two that a closed sentence is
meaningless unless it has empirical content---exception being made
perhaps for mathematics. The schematism of observation categoricals
affords, it would seem, the standard of having empirical content. A
set of sentences that has critical mass, as we may say---that is, that
implies some synthetic observation categoricals---may be said to have
those categoricals as its empirical content.  (WOV Quine, From
Stimulus to Science, 48)
******* [The state lottery is] a public subsidy of intelligence 
[since] it yields public income that is calculated to lighten the tax
burden of us prudent abstainers at the expense of the benighted masses
of wishful thinkers.
******* The lore of our fathers is a fabric 
of sentences. In our hands it develops and changes, through more or
less arbitrary and deliberate revisions and additions of our own, more
or less directly occasioned by the continuing stimulation of our sense
organs. It is a pale gray lore, black with fact and white with
convention. But I have found no substantial reasons for concluding
that there are any quite black threads in it, or any white ones.
(Hilary Putnam, The Collapse of the Fact/Value Dichotomy, 12)
**** ideas
***** What is evidence? Evidence is what my 
hypothesis sets out to explain. The question is not: do you have
evidence for your hypothesis? It is: what are you trying to explain
and how good is your hypothesis at doing it? If I have no evidence,
then my problem is that there is no substance, in reference to which
my hypothesis is explanatory.
***** According to Williamson, E=K, and knowledge is 
a mental state in an externalist sense. Thus evidence is a mental
state in an externalist sense. It is analytically indivisible, differs
from belief, has probability 1, is defeasible in time. Evidentialism
is false because two jurors, for example, may have the same evidence,
yet for one, it is the hypothesis that she was killed by tigers which
best fits the evidence, whereas for the other, it is the hypothesis
that she was killed by shmigers which best fits the evidence.
***** Conee and Feldman's evidentialism is vacant because 
their notion of evidence is circularly dependent on the evidence that
makes a belief epistemically justified. Evidence is what justifies a
belief epistemically. It is then no wonder that evidence and only
evidence justifies epistemically. Tell us what evidence is without
reference to epistemic justification and then produce the aha moment
that based on the same evidence you are not going to get diverging
epistemically justified beliefs.
***** page 180 in C&F
should you believe a proposition based on a modest amount of evidence?
C&F say yes but how can you believe both p and "p, but maybe not p"
***** thoughts in diachronische vernetztheit
in sudelbuch 13 -- use for evidence -- ancestral beliefs. what are the
ancestral beliefs of phenomenological and indexical beliefs -- well,
the meaning of the words (Nietzsche and Descartes) -- is the light
turned on -- you must know what light means -- Kripke's idea that
every word only has finite evidence of what its meaning is (also
Quine).

... wir sind diachronisch mit einer Zeit vernetzt, die der unseres
Bewusstseins vorangeht ... meine Entscheidungen gehen auf eine
Ereignis- und Reaktionsverkn"upfung zur"uck, die Millionen Jahre alt
und mir v"ollig unbewusst ist. Quine geht von einem
Wissenschaftsmodell aus, in dem unsere rohen Erfahrungen
Erkl"arungshypothesen entgegengestellt werden, von denen wir
diejenigen als vorl"aufig richtig empfinden, die die rohe Erfahrung am
unkompliziertesten erkl"aren. Diachronische Vernetztheit widerlegt
diesen Wissensbegriff. Wir treten mit einer Anschauungsweise an die
Dinge heran, die schon Teil unseres Denkapparates ist. Was wir wissen,
ist demnach hardware und nicht software ... in dem, was wir wissen,
sind wir der Geschichte ausgeliefert (Nietzsche)

Diachronische Vernetztheit: nothing is foundationally justified
(contra Conee and Feldman). Every belief has a pedigree of ancestral
beliefs (there are no prior probabilities, there is only belief
revision; any prior probabilities there might be would be genetically
hardwired). Belief revision proceeds according to Le Ch^atelier's
principle. (Le Ch^atelier's principle can be used to predict the
effect of a change in conditions on a chemical equilibrium. The
principle is named after Henri Louis Le Ch^atelier. Le Ch^atelier's
Principle can be summarized thus: If a chemical system at equilibrium
experiences a change in concentration, temperature, or total pressure,
the equilibrium will shift in order to minimize that change.)
***** Tyler Burge: entitlement to bring 
our data together in a coherent pattern, in content.
***** Phenomenological beliefs do not carry the
subjective probability 1 -- they are highly defeasible. That's in
contradiction to classical foundationalism. It's easy to suspend
belief in phenomenological beliefs, but you can't suspend belief in
innate beliefs. Doubt in innate beliefs can only occur over
evolutionary history.
***** our interesting beliefs are 
beliefs that are defeasible and cannot therefore be evidence. there is
a god -- not defeasible, not interesting. there is not a god --
defeasible, interesting. the world is round not square -- defeasible,
interesting. we also cannot know it. 
***** The theistic proposition 
(``there is a God,'' ``God exists'') is
indefeasible in the sense that we cannot currently conceptualize a
proposition C which is inconsistent with it. Thus there cannot be
evidence for it (is that true? -- Russell thought that there wasn't
enough evidence for God, is that a vacuous truth?)
***** Against Williamson, hypotheses are beliefs 
under consideration. Evidence is not knowledge, but it is the set of
beliefs which with reference to our hypothesis we hold fixed, although
they are second in line for consideration if inconsistencies arise. If
an inconsistency arises, we first try to tweak the hypothesis, but in
the end we would be just as happy to avoid the inconsistency by
tweaking the evidence. Example: E1: g is a linear function. E2: (1,-1)
is in g. E3: (3,3) is in g. E4: (67,131) is in g. H: g(x)=2x-3. (more
on page 15 of handwritten notes on Conee and Feldman). 
***** I've always felt that, contra Quine, overdetermination, not 
underdetermination, is the problem. We suffer from a lack of
alternatives, not an excess of them. We did not decide to endorse
relativity theory because, compared to its competitors, it was
theoretically more virtuous. We endorsed it because it finally gave us
an alternative to relieve the pressure of overdetermination. In the
case of light being a wave or a particle, in the case of the future
being a subset of spacetime or a consequence of quantum mechanics, we
live with the overdetermination, there being no alternatives. We
believe it all, despite the appearance of inconsistency. For less
scientific beliefs, this is standard procedure. (The Christian faith
is a paradigm in its dialectical commitment to believe in God as
atheoi, atheistically.)
***** What matters is belief revision, not knowledge 
acquisition. (The Bayesians are right, Williamson is wrong.) If, which
is rare, probability language applies, rationality is coextensive with
Bayesianism. If not, there must be a conversation about which belief
systems are less inconsistent. If, as is likely the case, there is no
appropriate measure of inconsistency (inconsistent may be an adjective
that does not allow comparatives), we may refer to information
density. Generally, disagreement arises over what the evidence and
what the hypothesis are, rather than how well-fitted the hypothesis is
to the evidence. In other (Quinean) words, the evidence is never
fixed. If you doubt my conclusion, you are as likely to question my
evidence as you are to question my fitting procedure. There is no
primacy of doubting the validity of the argument versus doubting the
validity of the premises.
***** graded belief, epsilon probabilities
see ./essays/truthAndKnowledge/truthAndKnowledge.org

see Sudelbuch 13, 2010-06-09; I can say, it will rain tomorrow and I
am right eighty percent of the time. I cannot say, there is a 25 
percent chance of rain tomorrow and I am right 80 percent of the time.
Once you express your beliefs in probabilities, they are no longer
Searlean pegs.
***** excerpt Sudelbuch 13, 2009-06-24, about 
the Eigenheit of the World.
***** beliefs are like Searle's names: they lack 
specificity in order to mean anything at all. See ``the uniqueness and
immense pragmatic convenience of proper names in our language lie
precisely in the fact that they enable us to refer publicly to objects
without being forced to raise issues and come to agreement on what
descriptive characteristics exactly constitute the identity of the
object. They function not as descriptions, but as pegs on which to
hang descriptions. Thus the looseness of the criteria for proper names
is a necessary condition for isolating the referring function from the
describing function of language.'' (In ``Proper Names,'' Mind 67
(1958): 166-173, p171,
http://mind.ucsd.edu/syllabi/00-01/phil_lang/readings/searle-01.html)
***** Following Williamson, there wouldn't be much 
reason to believe such things as that the Earth is sphere-like rather
than cube-like or that atoms exist because we have no evidence for it.
There isn't anything we <i>know</i> which makes these propositions
more likely, only the overall coherence of scientific testimony. How
do I know that I have a brain?

** Epistemological Entrenchment and Adams Conditioning
*** text
{\noindent} \textsc{Epistemic Entrenchment, Adams Conditioning, and
  the Principle of Maximum Entropy}

\begin{abstract}
  \noindent 
\end{abstract}

\kapt{Introduction}

There is a school of thought that defends the following principle:

\begin{quote}
  (A) Unless otherwise specified, evidence in the form of a
  conditional should not affect the posterior probability of the
  antecedent.
\end{quote}

Leaving the antecedent unaffected is called Adams conditioning. There
are without doubt many situations in which our intuitions require that
evidence in the form of a conditional does not affect the posterior
probability of the antecedent (see examples below). I take issue,
however, with the ceteris paribus clause. We should use the principle
of maximum entropy to determine the posterior probabilities.

\begin{quote}
  (\textsc{maxent}) Evidence in the form of an affine constraint
  should affect the posterior probabilities minimally in terms of
  information.
\end{quote}

If all else is equal, or (as we put it above) we receive no other
specifications, the result of applying \textsc{maxent} will diverge
from Adams conditioning. The reason for this is that it is Adams
conditioning which requires further specification, not the principle
of maximum entropy. I propose the following amendment to (A)

\begin{quote}
  (A*) Given certain specifications, it is appropriate to use Adams
  conditioning in order to obtain posterior probabilities.
\end{quote}

Examples:

\begin{enumerate}
\item Sarah and Marian have arranged to go for sundowners at the
  Westcliff hotel tomorrow. Sarah feels there is some chance that it
  will rain, but thinks they can always enjoy the view from inside. To
  make sure, Marian consults the staff at the Westcliff hotel and
  finds out that in the event of rain, the inside area will be
  occupied by a wedding party. So she tells Sarah: If it rains
  tomorrow, we cannot have sundowners at the Westcliff. Upon learning
  this conditional, Sarah sets her probability for sundowners and rain
  to zero, but she does not adapt her probability for rain. (Example
  nearly verbatim in \scite{8}{douvenromeijn09}{7}.)
\item A jeweller has been shot in his store and robbed of a golden
  watch. However, it is not clear at this point what the relation
  between these two events is; perhaps someone shot the jeweller and
  then someone else saw an opportunity to steal the watch. Kate thinks
  there is some chance that Henry is the robber. On the other hand,
  she strongly doubts that he is capable of shooting someone, and
  thus, that he is the shooter. The inspector, after hearing the
  testimonies of several witnesses, tells Kate: If Henry robbed the
  jeweller, then he also shot him. As a result, Kate becomes more
  confident that Henry is not the robber, while her probability for
  Henry having shot the jeweller does not change. (Example nearly verbatim in
  \scite{8}{douvenromeijn09}{12}.)
\item In the recent movie \emph{Private Benjamin}, Goldie Hawn enters
  the army and during war games, she and her patrol are dropped in a
  swampy area which they have to patrol. The war games area is divided
  into the region of the Blue Army, to which Judy Benjamin and her
  fellow soldiers belong, and that of the Red Army. Each of these
  regions is further divided into Headquarters Company Area and Second
  Company Area. The patrol has a map which none of them understands,
  and they are soon hopelessly lost. Using their radio they are at one
  point able to contact their own headquarters. After describing
  whatever they remember of their movements, they are told by the duty
  officer: I don't know whether or not you have strayed into Red Army
  territory. But if you have, the probability is 3/4 that you are in
  their Headquarters Company Area. At this point the radio gives out. (Example
  nearly verbatim in \scite{8}{fraassen81}{376f}.)
\item Judy Benjamin's platoon is lost in the wilderness. She believes
  that she is in the Blue territory, but she is not sure whether she
  is in the Second Company area or the Headquarters area. She calls
  her own Headquarters and gives a description of her surroundings.
  She is told: Well, if we don't assume that you are in the Blue
  territory, then you are in the Second Company area. Then radio
  contact is lost. (Example nearly verbatim in
  \scite{8}{nayaketal96}{76}.)
\item Suppose that grain is stored in a chamber with two outflow
  pipes, A and B. Pipe A empties into a second chamber X, while pipe B
  empties into both chamber X and another chamber Y. Suppose that we
  know the amount of grain stored in the first chamber, as well as the
  amount that ends up in chamber X when the outflow pipes are opened
  so that we are able to estimate with accuracy the probability of any
  piece of stored grain ending up in chamber X. Say it's one-half. We
  also know that any grain that goes down A ends up at chamber X, but
  we can only roughly estimate from the size and position of the pipes
  the probability that it goes down pipe A or B, and with what
  probability it will end up in chamber X in the event of it going
  down pipe B. Suppose now that sampling from the mouth of pipe B
  shows that we need to revise the degree to which we believe that a
  stored piece of grain will go down this pipe from, say, one-third to
  one-quarter. If our conditional degrees of belief in the grain
  landing up in chamber X given that it goes down B stays the same,
  then as a matter of consistency we should change our probability for
  the grain ending up in chamber X. But this would be the wrong thing
  to do, since we already know how much grain lands up there. So,
  contrary to the conditioning model, our conditional degrees of
  belief ought to change in response to the change in probability for
  the grain going down pipe B. (Example nearly verbatim in
  \scite{8}{bradley05}{360f}.)
\end{enumerate}

\kapt{References}

\nocite{*} 
\bibliographystyle{ChicagoReedweb} 
\bibliography{bib-6991}

\end{document}
*** there is some good info on 
Adams conditioning and the way it applies/cannot apply to the Sleeping
Beauty problem and the Judy Benjamin problem in Bovens article on SB
and JB
*** Nayak version of the JB problem
P(B)=.99 P(R)=.01, then intuitively if R then P(RHQ)=3P(RSC) will
increase P(R), contra the PME. Reason: info is not independent of
P(B), even if nothing but the conditional is provided (this compares
to Kate and Henry, no Adams conditioning here).
*** email for Paul
[never sent] <2012-10-24 Wed>

Paul,

Halpern thought that there was an analogy between the Three-Prisoners
Dilemma and JB. In both cases, he claimed, you could construct
``naive'' spaces and conditionalize in them instead of the more
appropriate sophisticated space. This can only be successful, so
Halpern, if the CAR (coarsening at random) condition holds, which is
rare, and in the case of maximum entropy conditioning (such as JB)
impossible except in trivial cases. Result: the TP Dilemma shows how
conditionalization can go wrong if a naive space is used and CAR
doesn't hold (the famous 1/2 probability to survive when it should
only be 1/3), ditto for JB: using the principle of maximum entropy in
the naive space is fallacious because CAR doesn't hold. In my paper, I
argue that the analogy is misguided.

That was a long introduction for trying to say that I think that just
as in the TP-JB case the analogy between Judy Benjamin and Sleeping
Beauty (by Bovens), the SB-JB case, is also misguided. The reason for
this is that in the SB case, self-locating is at issue (if I
understand your article on this correctly, self-locating is an
irreducible component of this puzzle), whereas in the JB case it's
epistemic entrenchment.

Judy's information is ``If you are in Red then P(RHQ)=3 times
P(RSC).'' Some claim that ceteris paribus if evidence comes in the
form of a conditional it should not affect our credence in the
antecedent (for example, Igor Douven). I disagree (after all, I am
claiming that the probability of Red is reduced from 50% to ~47%). The
credence in the antecedent should only not be affected if I already
know that my observation is independent of the antecedent's
probability. That's a far cry from ceteris paribus. There are many
examples in which this independence should not be assumed. I argue
that JB is one of them.

The interesting thing about SB is that ``Adams conditioning'' (leaving
the antecedent alone) is completely irrelevant here. JB is a problem
of Adams conditioning (or epistemic entrenchment), SB is a problem of
self-locating. Thus, Bovens' claim that by parity of reasoning a
solution for the JB problem is also one for SB is implausible. Much
more in the spirit of your article, it's the ``self-locating'' that's
at issue for SB.

I am saying this not only because I don't see a way to proceed on the
JB-SB analogy, as Bovens does, but also because I am becoming more and
more aware of the fact that epistemic entrenchment, so popular in the
recent literature, is incompatible with the principle of maximum
entropy. In keeping with my current prejudice for maxent, I think this
may just be the worse for epistemic entrenchment. Epistemic
entrenchment seeks solutions outside of Bayesian epistemology for
problems that maxent has already solved without the subjective
entrenchments.

Stefan
*** Read The Logic of Probabilistic Conditionals
at http://plato.stanford.edu/entries/logic-conditionals/
*** The Problem with Adams Conditioning
There is a school of thought that defends the following principle: ...
see epent.tex
*** Show that the intuitions leading to epistemic entrenchment are
compatible with maxent. Consult the Judy Benjamin problem (especially
in Douven and Romeijn, Hellinger's Distance), Bradley's Grain Pipe
problem. Show that Bovens' analogy between SB and JB fails because SB
is immune to EE considerations (due to self location). Read Nayak's
1996 piece, he works epistemic entrenchment into the JB problem.
*** Bradley's Grain Pipes
see Schmierbuch 549ff This is a Jeffrey's Rule problem. How does Ep
Ent come into it?
*** Judy Benjamin
This, according to Douven and Romeijn, is the usual epistemic
entrenchment and applies in full force to the Judy Benjamin problem.
They give an example where the epistemic entrenchment could go the
other way and leave the consequent rather than the antecedent
unaltered (Kate and Henry, see \scite{8}{douvenromeijn09}{13}). The
idea of epistemic entrenchment is at odds with \textsc{maxent} and
seems to imply just what the full employment theorem claims: judgments
so framed \qeins{will depend on the judgmental skills of the agent,
  typically acquired not in the inductive logic class but by subject
  specific training} \scite{2}{bradley05}{349}. To pursue the
relations between epistemic entrenchment, \textsc{maxent}, and the
full employment theorem would take us too far afield at present and
shall be undertaken elsewhere. For the Judy Benjamin problem, it is
not clear why Douven and Romeijn think that the way the problem is
posed implies a strong epistemic entrenchment for Adams conditioning
(Adams conditioning is the kind of conditioning that will leave the
antecedent alone). Scenarios II-III provide realistic alternatives
where Adams conditioning is inappropriate. 

Judy Benjamin may also receive ({\ref{eq:hdq}}) because her informers
have found out that Red Headquarters troops have occupied the entire
Blue territory ($q_{1}=3p_{1},q_{2}=p_{2},q_{3}=0$, the epistemic
entrenchment is with respect to $q_{2}$); because they have found out
that Blue troops have occupied two-thirds of the Red Second Company
area ($q_{1}=p_{1},q_{2}=(1/3)p_{2},q_{3}=(4/3)p_{3}$, the epistemic
entrenchment is with respect to $q_{1}$); or because they have found
out that Red Headquarters troops have taken over half of the Red
Second Company area ($q_{1}=(1/2)p_{1},q_{2}=(3/2)p_{2},q_{3}=p_{3}$,
the epistemic entrenchment is with respect to $q_{3}$ and what Douven
and Romeijn take to be an assumption in the wording of the problem).
There is nothing in the problem that supports Douven and Romeijn's
narrowing of the options. The table reiterates these options, with the
third, shaded line representing intuition (T1) and the epistemic
entrenchment defended by Douven and Romeijn.

\rowcolors{4}{lightgray}{lightgray}
\begin{tabular}{|l|c|c|c|}\hline
Epistemic entrenchment & $q_{1}$ & $q_{2}$ & $q_{3}$ \\ \hline
with respect to $A_{1}$ & 1/4 & 3/4 & 0 \\ \hline
with respect to $A_{2}$ & 1/12 & 1/4 & 2/3 \\ \hline
with respect to $A_{3}$ & 1/8 & 3/8 & 1/2 \\ \hline
\end{tabular}

*** bibliography
@article{fraassen81,
  title =	 {A Problem for Relative Information Minimizers in Probability Kinematics},
  author =	 {Van Fraassen, B.C.},
  journal =	 {The British Journal for the Philosophy of Science},
  volume =	 {32},
  number =	 {4},
  pages =	 {375--379},
  year =	 {1981}
}

@inproceedings{nayaketal96,
  title =	 {Learning from Conditionals: Judy Benjamin's Other Problems},
  author =	 {Nayak, A. and Pagnucco, M. and Foo, N.Y. and Peppas, P.},
  booktitle =	 {ECAI},
  pages =	 {75--79},
  year =	 {1996},
  organization = {PITMAN}
}

@article{fraassenetal86,
  title =	 {A Problem for Relative Information Minimizers, Continued},
  author =	 {Van Fraassen, B.C. and Hughes, R.I.G. and Harman, G.},
  journal =	 {The British Journal for the Philosophy of Science},
  volume =	 {37},
  number =	 {4},
  pages =	 {453--463},
  year =	 {1986}
}

@article{bradley05,
  title =	 {Radical Probabilism and Bayesian Conditioning},
  author =	 {Bradley, R.},
  journal =	 {Philosophy of Science},
  volume =	 {72},
  number =	 {2},
  pages =	 {342--364},
  year =	 {2005},
  publisher =	 {Philosophy of Science Association},
  address =	 {East Lansing, MI}
}

@article{douvenromeijn09,
  title =	 {A New Resolution of the Judy Benjamin Problem},
  author =	 {Douven, I. and Romeijn, J.W.},
  year =	 {2009},
  publisher =	 {London School of Economics},
  address =	 {London, UK},
  journal =	 {CPNSS Working Paper},
  volume =	 {5},
  number =	 {7},
  pages =	 {1--22}
}

@article{bovens10,
  title =	 {Judy Benjamin is a Sleeping Beauty},
  author =	 {Bovens, Luc},
  journal =	 {Analysis},
  volume =	 {70},
  number =	 {1},
  pages =	 {23--26},
  year =	 {2010},
  publisher =	 {Oxford University Press}
}

@inproceedings{gardenfors88,
  title =	 {Revisions of Knowledge Systems Using Epistemic Entrenchment},
  author =	 {G{\"a}rdenfors, P. and Makinson, D.},
  booktitle =	 {Proceedings of the 2nd conference on Theoretical aspects of reasoning about knowledge},
  pages =	 {83--95},
  year =	 {1988},
  organization = {Morgan Kaufmann Publishers Inc.},
  stefanspdf =	 {1988__Gaerdenfors_Makinson__Revisions_of_Knowledge_Systems_Using_Epistemic_Entrenchment}
}

@article{dubois91,
  title =	 {Epistemic Entrenchment and Possibilistic Logic},
  author =	 {Dubois, D. and Prade, H.},
  journal =	 {Artificial Intelligence},
  volume =	 {50},
  number =	 {2},
  pages =	 {223--239},
  year =	 {1991},
  publisher =	 {Elsevier}
}

@article{nayak94,
  title =	 {Iterated Belief Change Based on Epistemic Entrenchment},
  author =	 {Nayak, A.C.},
  journal =	 {Erkenntnis},
  volume =	 {41},
  number =	 {3},
  pages =	 {353--390},
  year =	 {1994},
  publisher =	 {Springer}
}

@article{rott92,
  title =	 {Preferential Belief Change Using Generalized Epistemic Entrenchment},
  author =	 {Rott, H.},
  journal =	 {Journal of Logic, Language and Information},
  volume =	 {1},
  number =	 {1},
  pages =	 {45--78},
  year =	 {1992},
  publisher =	 {Springer}
}
* ideas
** This needs to be appended to Augustin's Concessions in dissertation
\begin{quotex}
  \beispiel{Wagner's Linguist}\label{ex:linguist} A linguist hears the
  utterance of a native and concludes that the native cannot be part
  of certain population groups, depending on what the utterance means.
  The linguist is uncertain between some options about the meaning of
  the utterance. (For full details see \scite{8}{wagner92}{252}; and
  \scite{8}{spohn12}{197}.)
\end{quotex}

The mathematician Carl Wagner proposes a natural generalization of
Jeffrey Conditioning for his Linguist example (see
\scite{7}{wagner92}{}). Since the principle of maximum entropy is
already a generalization of Jeffrey Conditioning, the question
naturally arises whether the two generalizations agree. Wagner makes
the case that they do not agree and deduces that the principle of
maximum entropy is sometimes an inappropriate updating mechanism, in
line with many earlier criticisms of the principle of maximum entropy
(see van Fraassen,\fixref{7}{fraassen81}{} 1981;
\scite{7}{shimony85}{}; \scite{7}{skyrms87updating}{}; and, later on,
\scite{7}{grovehalpern97}{}). What is interesting about this case is
that Wagner uses instates for his deduction, so that even if you agree
with his natural generalization of Jeffrey Conditioning (which I find
plausible), the inconsistency with the principle of maximum entropy
can only be inferred assuming instates. Wagner is unaware of this, and
it can be shown that on the assumption of sharp credences Wagner's
generalization of Jeffrey conditioning accords with the principle of
maximum entropy (see \scite{7}{lukits15}{}).

This will not convince Booleans, since they are already unlikely to
believe in the general applicability of the principle of maximum
entropy (just as Wagner's argument is unlikely to convince a proponent
of the principle of maximum entropy, since they have a tendency to
reject instates). The battle lines are clearly drawn. Wagner's
argument, instead of undermining the principle of maximum entropy,
shows that instates are as wedded to rejecting the claims of the
principle of maximum entropy as the principle of maximum entropy is
wedded to sharp credences (these marriages are only unilaterally
monogamous, however, as it is perfectly coherent to reject both the
principle of maximum entropy and the Boolean position; or to reject
both the Laplacean position and instates).

Endorsement of instates, however, implies that there are situations of
probability update in which the posterior probability distribution is
more informative than it might be in terms of information theory.
Indeterminate credences violate the relatively natural intuition that
we should not gain information from evidence when a less informative
updated probability will do the job of responding to the evidence.
This is not a strong argument in favour of sharp credences. I consider
it to be much easier to convince someone to reject instates on
independent conceptual grounds than to convince them to reconsider the
principle of maximum entropy after its extensive criticism.
** Philosophers are sometimes accused of 
belabouring a narrow range of problems which themselves are probably
based on implausible assumptions or doubtful relevance. I recognize
that my own work may suffer from this defect. I lack the ability to
articulate it, but my work has a larger philosophical point in mind
which more recognizably matters than Bayesian updating and maximum
entropy: epistemological pessimism, i.e. the view that the increasing
irrelevance of metaphysical questions in the 20th century is matched
by an increasing irrelevance of epistemological questions now. Not
only do we not know what there is, we do not know what we know. Humans
are living beings, not knowing beings. If knowledge defines them, it
does so in the sense that humans are deceived beings. Surrounded by
metaphysical illusions, humans are by their constitution deluded.
Their delusions are what makes them alive: creative, tragic, and
humorous. <2015-02-18 Wed>

See more under Epistemological Pessimism in hypomnemata
** Information is a mathematical object
like Poincare's geometry (consult Mojtaba about details). It still tells us something about the world (even though it is conventional).
** A solution for Gillies red/blue problem: infoBayesians do not
only pay attention to frequencies, they also pay attention to minimal
descriptions. For 0100100010000100000 the probability of a 1 is not 5
out of 21 but much higher because it is 1's turn in the pattern. 
** about the objection of excessive apriorism
(both in Gillies and in Seidenfeld): an infoBayesians does not need
all of her prior probabilities to be fixed a priori chronologically,
but only logically. Prior (or conditional) probabilities can be
reconstructed by retrospective conditioning, precisely because there
is a way to arrive at them objectively, without being influenced by
the evidence (even though we already know what the evidence is we can
abstract away from it).
** conditioning on conditionals
** There is a mysticism in the rejection of 
maxent as a generally valid method of update about which I am
intuitively suspicious. It is one of life's big question where one
wants to allow mysticism and where one does not. 
* structure
** first pass
relationship information and probability -- what kind of commodity is
information (primary, derivative)

define IT in terms of PT (A. Khinchin) or the other way around
(Ingarden; Kolmogorov; de Feriet)

axiomatizations of IT: Shannon; Fadeev; Khinchin

read Guiasu

continuity of standard conditioning, Jeffrey conditioning, and the PME

read Skyrms, Higher Order Degrees of Belief

Lagrange multipliers and the Radon-Nikodym Theorem

remark: interesting how information and ranks resemble each other
here: The certain event does not contain any information, while the
impossible event contains infinite information: I(omega) = 0, I(empty
set) = +inf

Bayesian assumptions (Deb Mayo, Wolfgang Spohn, Halpern, Wagner)

Prior probabilities

The detractors: Carnap, Jeffrey, van Fraassen, Judy Benjamin, Shimony,
Seidenfeld, Wagner (see Spohn, 197), epistemic entrenchment (Douven
and Romeijn) and conditionals

The attractors: Cox, Shore and Johnston (there is an equivalent for
ranking theory), Caticha and Giffin, Jaynes

belief change and probability kinematics
** prospectus chapter outline
*** Introduction
*** Affine Constraints
*** The Principle of Maximum Entropy: Virtues
*** The Principle of Maximum Entropy: Vices
*** Judy Benjamin
*** The Shimony Objection
*** The Seidenfeld Objection
*** The Wagner Objection
*** Coarsening at Random
*** Families
*** Epistemic Entrenchment
*** Epistemological Implications
* buffer
r
