% This is the official version. For shorter versions, see directory
% diff.

% http://tinyurl.com/nrhqdxg

% TBD: 

% What exactly is Linda's evidence differential compared to
% Betsy -- the analytic expression may help.

\documentclass[11pt]{article}
\usepackage{october}
% For BJPS
% \hyphenpenalty=10000
% \hbadness=10000

\begin{document}
% For BJPS
% \raggedright
% \doublespacing

\title{Semantics of Not Knowing}
\author{Stefan Lukits}
\date{}
\maketitle
\newcounter{expls}
% \doublespacing

\begin{abstract}
  {\noindent}Many Bayesian epistemologists now accept that it is not necessary for a rational agent to hold sharp credences. There are various compelling formal theories how such a non-traditional view of credences can accommodate decision making and updating. They are motivated by a common complaint: that sharp credences can fail to represent incomplete evidence. I show that the critical response of those who want to maintain the traditional view with only sharp credences is insufficient. Their criticism, however, opens the door to semantic questions which make indeterminate credences vulnerable on a deeper level. This paper uses both conceptual arguments and hands-on examples to demonstrate that rational agents should always have sharp credences. It is also articulated and substantiated that agents with indeterminate credal states make long term gains betting against agents with sharp credences. This on the surface inconvenient fact can be explained and does not favour indeterminacy over sharp credences.
\end{abstract}

\section{Introduction}
\label{Introduction}

Traditionally, Bayesians used to require for a rational agent to hold sharp credence functions. It has recently become popular to drop this requirement. There are now Bayesians who permit a rational agent to hold indeterminate credal states (from now on instates) based on incomplete or ambiguous evidence. I will refer to Bayesians who continue to adhere to the classical theory of sharp credences for rational agents as \qnull{Laplaceans} (e.g.\ Adam Elga and Roger White). I will refer to Bayesians who do not believe in the requirement for a rational agent to hold sharp credences as \qnull{Booleans} (e.g.\ Peter Walley and James Joyce; see Boole, 1854, chapters 16--21, for alternative methods to the ones suggested by Laplace which result in imprecise epistemic probabilities).

There is some terminological confusion around the adjectives \qnull{imprecise,} \qnull{indeterminate,} and \qnull{mushy} credences. In the following, I will exclusively refer to indeterminate credences or credal states (instates) and mean by them a credal state (a set of credence functions, which some Booleans require to be convex) which it may be rational for an agent to hold within an otherwise orthodox Bayesian framework. After describing the appeal of indeterminacy and showing how contemporary Laplacean objections fail, I will point to more serious failings of indeterminacy in semantic terms and show how a proper semantics of not knowing, which we could also call a semantics of partial belief, solves the problems for sharp credences that Booleans address by introducing instates. There is a sense in which, by linking knowledge of chances to its reflection in credences, Booleans seek to reconcile traditional knowledge epistemology concerned with full belief and formal epistemology concerned with partial belief. There are other more recent reconciliation projects (see Spohn, 2012; and Moss, 2013). If my paper is correct then the Boolean approach will not contribute to this reconciliation because it mixes full belief and partial belief metaphors in ways that are semantically problematic.

\texttt{<x1.1>}Sharp credences confront a genuine conceptual crisis with intuitions about betting behaviour, completeness for preferences, and how reasonable it is to demand precision from agents, even if they are rational. Indeterminacy appears to provide an elegant solution to overcome this crisis as well as a powerful formal theory to uphold what many find so compelling about the Bayesian legacy. In the face of these virtues, I maintain that indeterminacy adds an unnecessary layer to the semantics of partial belief which has in its wake counter-intuitive consequences and solves nothing that cannot be solved by a carefully articulated version of the classical Bayesian commitment to sharp credences.\texttt{</x1.1>}

\texttt{<x1.2>}A sharp credence, as much as the term suggests precision and a measure of certainty, is a representation of an epistemic state chracterized by uncertainty and lack of information. Importantly, it does not represent the evidence which informs the epistemic state, and it makes no claim of such a representation.\texttt{</x1.2>} Instates are often lauded as doing much better representing uncertainty together with the evidence that constrains it, but they can no more give an adequate representation of evidence than sharp credences. This paper defends a $0.5$ sharp credence in heads in all three cases: for a coin of whose bias we are completely ignorant; for a coin whose fairness is supported by a lot of evidence; and even for a coin about whose bias we know that it is either 1/3 or 2/3 for heads.

One potential Boolean claim is that agents who use instates do better than Laplaceans when they bet on the truth of events for which they have varying degrees of evidence. Walley gives an example where a Laplacean does much worse at predicting Soccer World Cup games than Boolean peers who use upper and lower previsions. Upper and lower previsions are instates for which it is rational to accept or reject bets if they fall within the margin of indeterminacy. 

First I will show on a much more general level how Walley's claims are justified in practice (bettors using upper and lower previsions do better than bettors using linear previsions, i.e.\ sharp credences). Then I will explain why this is the case, how a Laplacean can protect herself against this disadvantage by drawing proper distinctions between credence and evidence, and how indeterminacy emerges as the loser when the contest is about clarity in one's semantics. The problem will be mixed metaphors: the Boolean mixes semantic levels that ought for good reasons to remain separate. Indeterminacy imposes a double task on credences (representing both uncertainty and available evidence) that they cannot coherently fulfill.

I will present several examples where this double task stretches instates to the limits of plausibility. Joyce's idea that credences can represent balance, weight, and specificity of the evidence is inconsistent with the use of indeterminacy (and Joyce himself, in response to the dilation problem, gives the argument why this is the case). The implicit Boolean claim that certain properties of the evidence (its ambiguity, its completeness, conflicts within it) can be recovered from instates is inconsistent with an effective Boolean answer to the dilation problem.

The Laplacean approach of assigning subjective probabilities to partitions of the event space (e.g.\ objective chances) and then aggregating them by David Lewis' summation formula into a single precise credence function is semantically tidy and shares many of the formal virtues of Boolean theories. If the bad taste about numerical precision in our fuzzy and nebulous world lingers, I will point to philosophical projects in other domains where the concepts we use are sharply bounded, even though our ability to conceive of those sharp boundaries or know them is limited.

\section{Motivation for Instates}
\label{MotivationForIndeterminateCredalStates}

We want to motivate indeterminacy for the credences of a rational agent, independent of how they are elicited, as forcefully as possible so that the reader will see (a) the appeal of such indeterminacy, (b) the insufficiency of the critical response, and (c) the need for careful articulation of the Laplacean approach that mandates a rational agent to hold sharp credences together with an explanation of how it addresses the concerns which motivate some to resort to indeterminacy.

\texttt{<x2.1>}When textual criticism compares variant readings of ancient texts in order to recover the most probable reading of the original, it follows a well-accepted rule not to recommend the easiest reading, i.e.\ the one that flows most naturally with the surrounding text, but the (often more difficult) reading which best explains the variants in the manuscripts. A similar dynamic is at work here: motivating indeterminacy will make clear that acceptance of indeterminacy is the easiest reading and on the surface best responds to intuitions we have about the credences of a rational agent. We will address, however, the ways in which indeterminacy itself violates intuitions, especially those for semantic clarity and simplicity (the latter viewed in terms of reducing hierarchical nesting of uncertainty versus tidily separating the evidential and epistemic dimension of partial beliefs). The Laplacean approach, which does not permit indeterminacy, explains why this is the case and, despite being the more difficult reading, ultimately yields a more integrated package that accords better with our intuitions and requirements for a coherent formal and semantic theory.\texttt{</x2.1>}

\texttt{<x2.2>}Our conclusion is that a rational agent is best off in terms of her own goals when she entertains sharp credences with respect to propositions about events that come her way. Whether this is advisable for human or machine intelligence is a different kettle of fish. My topic is the logic of partial beliefs, and I readily admit that such a logic may be computationally intractable or, given finite resources, be an irrational way of keeping track of beliefs.\texttt{</x2.2>}

\texttt{<x2.3>}Despite this disclaimer, we begin with an example that motivates instates based on human betting behaviour. It is nonetheless forceful. For the Ellsberg paradox (see \scite{8}{ellsberg61}{650ff}), you have two urns, both containing 100 red and black balls. Urn I contains an unknown ratio of the two colours, whereas the ratio for Urn II is 50:50. In experiments, subjects usually prefer to bet on Red$_{II}$ rather than Red$_{I}$ and Black$_{II}$ rather than Black$_{I}$. If these preferences stem from sharp subjective probabilities, then

\begin{equation}
  \label{eq:s1}
  1=P(R_{II})+P(B_{II})>P(R_{I})+P(B_{I})=1
\end{equation}

leads to a violation of probability axioms by reductio. A slight variation shows that such preferences also violate L.J. Savage's Sure Thing principle, without the possibly doubtful numerical mapping from preferences to subjective probabilities (see \scite{8}{ellsberg61}{653f}). The intuition behind the Ellsberg paradox remains a strong motivation for instates, often expressed in terms of biased coins.\texttt{</x2.3>}

Let a \textsc{coin} be a Bernoulli generator that produces successes and failures with probability $p$ for success, labeled $H$, and $1-p$ for failure, labeled $T$. Physical coins may serve as examples, if we are willing to set aside that most of them are approximately fair. Imagine three \textsc{coin}s for which we have evidence that \textsc{coin}$_{I}$ is fair, \textsc{coin}$_{II}$ has an unknown bias, and \textsc{coin}$_{III}$ has as bias either $p=1/3$ or $p=2/3$. The Laplacean approach permits a sharp $0.5$ credence in $H$ for a rational agent in all three cases. A Boolean approach wants to see the difference in the evidential situation reflected in a rational agent's credal state and at least permit, as credence in $H$, $\{x|x=0.5\}$ for \textsc{coin}$_{I}$, $\{x|0\leq{}x\leq{}1\}$ for \textsc{coin}$_{II}$, and $\{x|1/3\leq{}x\leq{}2/3\}$ or $\{1/3,2/3\}$ for \textsc{coin}$_{III}$. 

\texttt{<x2.4>}Here are a few concise statements by Booleans:

\begin{quotex}
  [A] refusal to make a determinate probability judgment does not derive from a lack of clarity about one's credal state. To the contrary, it may derive from a very clear and cool judgment that on the basis of the available evidence, making a numerically determinate judgment would be unwarranted and arbitrary. \scite{3}{levi85}{395}
\end{quotex}

\begin{quotex}
  If there is little evidence concerning [a claim,] then beliefs about [that claim] should be indeterminate, and probability models imprecise, to reflect the lack of information. We regard this as the most important source of imprecision. \scite{3}{walley91}{212--213}
\end{quotex}

\begin{quotex}
  Imprecise probabilities and related concepts [{\ldots}] provide a powerful language which is able to reflect the partial nature of the knowledge suitably and to express the amount of ambiguity adequately. \scite{3}{augustin03}{34}
\end{quotex}

\begin{quotex}
  As sophisticated Bayesians like Isaac Levi (1980), Richard Jeffrey (1983), Mark Kaplan (1996), have long recognized, the proper response to symmetrically ambiguous or incomplete evidence is not to assign probabilities symmetrically, but to refrain from assigning precise probabilities at all. Indefiniteness in the evidence is reflected not in the values of any single credence function, but in the spread of values across the family of all credence functions that the evidence does not exclude. This is why modern Bayesians represent credal states using sets of credence functions. It is not just that sharp degrees of belief are psychologically unrealistic (though they are). Imprecise credences have a clear epistemological motivation: they are the proper response to unspecific evidence. \scite{3}{joyce05}{170f}
\end{quotex}

\begin{quotex}
  Precise degrees of belief are the wrong response to the sorts of evidence that we typically receive [{\ldots}] since the data we receive is often incomplete, imprecise or equivocal, the epistemically right response is often to have opinions that are similarly incomplete, imprecise or equivocal. \scite{3}{joyce10}{283}
\end{quotex}\texttt{</x2.4>}

Consider the following reasons that motivate Booleans to permit instates for rational agents:

\begin{enumerate}[(A)]
\item The greatest emphasis motivating indeterminacy rests on lack of evidence or conflicting evidence and the assumption that single probability measures (sharp credences) do not represent such evidence as well as credal states composed by sets of probability measures (instates).
\item The preference structure of a rational agent may be incomplete so that representation theorems do not yield single probability measures to represent such incomplete structures.
\item There are more technical and paper-specific reasons, such as Thomas Augustin's attempt to mediate between the minimax pessimism of objectivists and the Bayesian optimism of subjectivists using interval probability (see \scite{8}{augustin03}{35f}); Alan H{\'a}jek and Michael Smithson's belief that there may be objectively indeterminate chances in the physical world (see \scite{8}{hajeksmithson12}{33}); and Jake Chandler's claim that \qeins{the sharp model is at odds with a trio of plausible propositions regarding agnosticism} \scite{2}{chandler14}{4}.
\end{enumerate}

This paper mostly addresses (A), while taking (B) seriously as well and pointing towards solutions for it. I am leaving (C) to more specific responses to the issues presented in the cited articles, and for the remainder of this section I am adding a reason (D) that is poorly documented in the literature.

\texttt{<x2.5>}One motivation for permitting a rational agent to have a range of probability measures rather than mandating her to hold a single one as her credence is (D) that she would do better making decisions and accepting advantageous bets. Even though Booleans seldom raise this issue, I find it worth pursuing. Before we do this, it is necessary to make brief reference to the variety of versions which accommodate indeterminacy as we have sketched it: upper and lower probabilities, choquet capacities, belief and possibility functions, coherent lower previsions, sets of probability measures, partial preference orderings, and sets of desirable gambles (the list is from \scite{8}{walley00}{126}). The proliferation of versions is not a problem for Booleans, neither in principle because the debate is vigorous and useful which of them best captures requirements for rationality, nor in practice because the versions agree on large parts of the terrain (see \scite{8}{levi85}{390}; and \scite{8}{walley91}{50f}).\texttt{</x2.5>}

\texttt{<x2.6 comment="if cut one sentence summary instead">}For our purposes, we accept Walley's theory of upper and lower previsions, which is motivated by coherence on the one hand and avoidance of sure loss on the other hand. Upper and lower previsions have a behavioural interpretation as maximum buying prices and minimum selling prices for gambles. If the agent's lower prevision is $1/3$ and the upper prevision $2/3$, she would accept a bet paying \$1 if $H$ for thirty cents and reject such a bet for seventy cents, but if the price of the bet is between one and two thirds of a dollar it would be rational for her to either accept or reject the bet. Walley conducted an experiment with 17 participants, who had various levels of understanding Bayesian theory, asking them for upper and lower probabilities entering into bets about the games played in the Soccer World Cup 1982 in Spain. One of the participants, a \qeins{dogmatic Bayesian lecturer} (see \scite{8}{walley91}{633}), only used single sharp subjective probabilities, while the others used intervals. The dogmatic Bayesian lecturer finished a distant last when the bets were evaluated. Walley admits that this result may have been due to the lecturer's eccentric assessments (for the game between the Soviet Union and Brazil, for example, his distribution between a Win, a Draw, and a Loss was 10-80-10).\texttt{</x2.6>}

\texttt{<x2.7 comment="if cut one sentence summary instead">}I replicated the experiment using two computer players, Betsy and Linda, with rudimentary artificial intelligence and made them specify betting parameters (previsions) for games played in the Soccer World Cup 2014 in Brazil. I used the Poisson distribution (which is an excellent predictor for the outcome of soccer matches) and the FIFA ranking to simulate millions of counterfactual World Cup results and their associated bets, using Walley's evaluation method. Betsy, who used upper and lower previsions, had a slight but systematic advantage over Linda, who used linear previsions. Betsy's expected gain for a whole tournament was approximately \$2 (very little compared to the stakes, as one can see by considering the standard deviation of approximately \$46 for this expected gain, i.e. 67\% of Betsy's overall gain from a tournament was between -\$44 and +\$48). The surprising fact that she did consistently better than Linda remains in need of explanation. In section \ref{WalleysWorldCupWoes}, I will provide an explanation and show how it can support rejecting instates for rational agents, counter-intuitive as that may sound.\texttt{</x2.7>}

\section{Arbitrage Opportunities and Dilation}
\label{ArbitrageOpportunitiesAndDilation}

From a collection of arguments against indeterminacy I draw on two that sound compelling and that in the final analysis fail. One by Adam Elga (see \scite{7}{elga10}{}) charges indeterminacy with making a rational agent vulnerable to sure loss and ends in the statement: \qeins{Perfectly rational agents always have perfectly sharp probabilities} \scite{2}{elga10}{1}.

The other by Roger White (see \scite{7}{white10}{}) is initially more semantically minded with an analysis of the Chance Grounding Thesis (CGT), of which I will also make use in my criticism of indeterminacy. For the remainder of White's paper, however, the focus moves to dilation, which according to White saddles the indeterminacy approach with unacceptable counter-intuitive results. Joyce has reponded in favour of indeterminacy both to Elga and to White and in my view has successfully defended his position.

For Elga, the issue is that while it is rational for an agent with an upper and lower provision to reject both an $x$ bet for $H$ (shorthand for \qnull{receiving \$1 if $H$ is true for the price of $x$}) and a $1-x$ bet against $H$ (or, equivalently, for $T$), if $x$ is between the two previsions; it should also be rational to accept both bets if they are an $x+\delta$ bet for $H$ and a $1-x+\delta$ bet for $T$, where $\delta$ is chosen small enough to keep the prices of the bets within the previsions. These bets will lead to a sure loss and an arbitrage opportunity for bookies against our supposedly rational agent.

There is no reason to reinvent the wheel here: both Chandler and Joyce address Elga's objection, and while Chandler's defence of indeterminacy against Elga does not persuade me (see \scite{8}{chandler14}{10}), Joyce's defence does (see \scite{8}{joyce10}{314}). Similarly, for White's objection, I am satisfied with Joyce's response. Joyce deals with White's objection in detail in his 2010 paper (for a concise summary see \scite{8}{bradleysteele13}{13}). As opposed to Elga's objection, White's objection has far-reaching semantic implications. 

You have two Bernoulli Generators, \textsc{coin}$_{a}$ and \textsc{coin}$_{b}$. You have good evidence that \textsc{coin}$_{a}$ is fair and no evidence about the bias of \textsc{coin}$_{b}$. Furthermore, the two generators are not necessarily independent. Their results could be 100\% correlated or anticorrelated, they may be independent, or the correlation could be anywhere between the two extremes. You toss \textsc{coin}$_{a}$. Without looking at the result, your credence in $H$ is a sharp $0.5$, even if you are open to instates, because you have good evidence for the fairness of \textsc{coin}$_{a}$. Then you toss \textsc{coin}$_{b}$. This time you look at the result and the moment you learn it, your credence in $H$ for \textsc{coin}$_{a}$ dilates from a sharp $0.5$ to the vacuous credal state covering the whole interval $[0,1]$ (provided that this was your credence in $H$ for \textsc{coin}$_{b}$, as stipulated). Even though you have just received information (the result of \textsc{coin}$_{b}$'s toss), your credence in $H$ for \textsc{coin}$_{a}$ dilates. Usually, we would expect more information to sharpen our credal states (see Walley's \qeins{the more information the more precision} principle and his response to this problem in 1991,\fixref{8}{walley91}{207 and 299} 207 and 299).

White did not discover the phenomenon of dilation (see the detailed study in \scite{7}{seidenfeldwasserman93}{}), but he was able to find examples where the consequences appear grotesque, especially in his bonbon case (see \scite{8}{white10}{183}).

\begin{quotex}
  Having noodled about this puzzle on and off for some time, I discovered that the general phenomenon of dilation is old news. Some statisticians and philosophers have studied how the phenomenon arises in other cases and appear to have taken it in their stride. This is not a reductio but a result, they might say. I want to suggest that the present case brings out particularly forcefully how bizarre this phenomenon is, at least in the present case where we are assuming evidential symmetry between $p$ and not-$p$. \scite{3}{white10}{177}
\end{quotex}

White's claim is also that dilation contradicts Bas van Fraassen's reflection principle (see van Fraassen, 1984\fixref{7}{vanfraassen84}{}).

In Joyce's response to White, two semantic concessions to White (J1) and (J2) show why the dilated instates give us the right result. I agree with Joyce: dilation is what you would expect if (J1) credences do not adequately represent evidence (the same instate can reflect different evidential situations); and if (J2) instates do not reflect knowledge claims about objective chances (Joyce rejects White's Chance Grounding Thesis CGT, see \scite{8}{joyce10}{289}). 

\addtocounter{expls}{1}

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Dilating Urns.} You draw from an urn with 200 balls (100 red, 100 black) and receive the information that the urn actually had two chambers, one with 99 red balls and 1 black ball, the other with 1 red ball and 99 black balls.
\end{quotex}

Dilation from a sharp $0.5$ to an indeterminate $\{0.01,0.99\}$ or $[0.01,0.99]$ (depending on whether convexity is required) is unproblematic, although the example already prefigures that there is something odd about the Boolean semantic approach. The example licences a 99:1 bet for one of the colours, but this is a problem that arises out of Boolean semantics without dilation, which we will address again in Example \ref{monkey}.

Booleans have the resources to extract themselves from the problem of dilation, but only at the cost of making Joyce's semantic concessions (J1) and (J2) which we will use against them. These semantic concessions are inescapable, not only on account of dilation. If one were to be committed to the principle of regularity, that all states of the world considered possible have positive probability (for a defence see \scite{7}{edwardsetal63}{}); and to the solution of Henry Kyburg's lottery paradox, that what is rationally accepted should have probability 1 (for a defence of this principle see \scite{7}{douvenwilliamson06}{}); and the CGT, that one's spread of credence should cover the range of possible chance hypotheses left open by the evidence (implied by much of Boolean literature); then one's instate would always be vacuous. Booleans must deny at least one of the premises to avoid the conclusion. Joyce denies the CGT, but then he continues to make implicit use of it when he repeatedly complains that sharp credences \qeins{ignore a vast number of possibilities that are consistent with [the] evidence} (for example in \scite{8}{joyce05}{170}).

A sharp credence constrains partial beliefs in objective chances by Lewis' summation formula (which we will provide in the next section). No objective chance is excluded by it (principle of regularity) and any updating will merely change the partial beliefs, but no full beliefs. Instates, on the other hand, by giving ranges of acceptable objective chances suggest that there is a full belief that the objective chance does not lie outside what is indicated by the instate. A Boolean can avoid this situation by accepting Joyce's concession (J2). 

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Bavarian King.} Matthias Perth, an Austrian civil servant, observes the Bavarian king at the Congress of Vienna in 1815 and writes in his diary that the king \qeins{appears to be a man between 45 and 47 years old} (see \texttt{http://www.das-perth-projekt.at}).
\end{quotex}

If Perth then learns that the king was 49 years old, he must revise, not just update, his earlier judgment. The appropriate formal instrument is belief revision, not probability update, and whoever wants to use it leaves what Levi calls the Ample Bosom of Mother Bayes (see \scite{8}{levi85}{392}), unless there is a substantial reconciliation project between formal and traditional epistemology operating in the background. I do not see this project articulated in the Boolean literature (for an example of such a project see \scite{7}{spohn12}{}, especially chapter 10). Sarah Moss also undertakes it and assumes the Boolean approach (see \scite{7}{moss13}{}), but I fail to see how the Boolean approach is essential to her reconciliation or how her reconciliation gives independent arguments for the Boolean approach. If Perth had wanted to express a sharp credence, he would have said, \qeins{my best guess is that the king is 46 years old,} and the information that the king was 49 would have triggered the appropriate update, without any revision of full beliefs.

White's objection fails, however, because dilation for indeterminate credences is in principle not any more surprising than a piece of information that increases the Shannon entropy of a sharp credence. It is true for both sharp and indeterminate credences that information can make us less certain about things. Once Booleans have brought their house in order to accommodate White's objection using concessions (J1) and (J2), they open the door to semantic problems. We finally get to inquire what kind of coherence there is in defending indeterminacy when it neither fulfills the promise of representing evidence nor the promise of reconciling traditional full belief \qnull{knowledge} epistemology and Bayesian partial belief epistemology as outlined in the CGT, but only adds another hierarchical layer of uncertainty to a numerical quantity (a sharp credence) whose job it already is to represent uncertainty, thus unnecessarily introducing regress problems. We will turn to these semantic considerations now, show how they display the virtues of sharp credences in responding to the forceful motivations for instates while making those instates look semantically otiose. Then we will show in the last section how sharp credences have an elegant solution for being outperformed by instates in betting scenarios, and there we will rest our case.

\section{Semantics of Partial Belief}
\label{SemanticsOfPartialBelief}

Instates are suggestive of a measurement that wants to represent numerically the mass of an object and then also make claims about its density. With sharp credences, the semantic roles of evidence, information, and uncertainty are appropriately differentiated. Rational decision making, inference, and betting behaviour are based on sharp credences together with the evidence that is at its foundation. Information represents evidence, and sharp credences represent uncertainty. Measurement is in any case a misleading analogy for credences. Measurements are always imprecise. Epistemic credences, however, are not measurements, especially not of objective chances. They represent uncertainty. They are more like logical truth values than they are like measurements. \scite{8}{levi85}{407}, makes this category mistake, whereas \scite{8}{walley91}{249}, is clear on the difference.

\texttt{<x4.1>}It is a slippery affair to determine what evidence is, which I will leave to others. My claim is that a rational agent is someone who can distill information from evidence which places numerically precise constraints on relatively prior probability distributions, which then can be updated to form posterior probability distributions and the credences associated with them. Note that relatively prior probability distributions are not ignorance priors or non-informative priors, which I would call absolutely prior probability distributions. I have no answers where absolutely prior probability distributions come from, how they are justified, or in what sense they are objective. I am not concerned whether all rational agents, if they have the same evidence, should arrive at the same credal states; or even if they should all update a given relatively prior credal state to the same posterior credal state, if they have the same evidence. Sometimes there may be different ways to translate or interpret evidence into information.\texttt{</x4.1>}

It is important not to confuse the claim that it is reasonable to hold both $X$ and $Y$ with the claim that it is reasonable to hold either $X$ (without $Y$) or $Y$ (without $X$). It is the reasonableness of holding $X$ and $Y$ concurrently that is controversial, not the reasonableness of holding $Y$ (without holding $X$) when it is reasonable to hold $X$. We will later talk about anti-luminosity, the fact that a rational agent may not be able to distinguish psychologically between a $54.9$ cent bet on an event and a $45.1$ bet on its negation, when her sharp credence is $0.55$. She must reject one of them not to incur sure loss, so proponents of indeterminacy suggest that she choose one of them freely without being constrained by her credal state or reject both of them. I claim that a sharp credence will make a recommendation between the two so that only one of the bets is rational given her particular credence, but that does not mean that another sharp credence which would give a different recommendation may not also be rational for her to have.

I am sympathetic to the viewpoint that once a rational agent has a relatively prior credal state and has formalized her evidence in terms of information, then the probability distributions forming her posterior credal state should be unique. Joyce, with his \qnull{committee member} approach, shows how this kind of updating can be done for instates (see \scite{8}{joyce10}{288}; also \scite{8}{bradleysteele13}{6}).

On the one hand (the Laplacean approach), you can have partial beliefs about how a parameter is distributed and then use Lewis' summation formula (see \scite{8}{lewis81}{266f}) to integrate over them and condense them to a sharp credence. Walley comments on this \qeins{reduction} in his section on Bayesian second order probabilities (see \scite{8}{walley91}{258f}), but he mistakenly represents the Laplacean approach as a second order approach, as if the probability distributions that are summarized by Lewis' formula are of the same kind as the resulting credences. They are not. They are objective chances or other partitions of the event space and the subjective probabilities that are associated with them. It is the Boolean approach which has elements of a second order approach and thus makes itself vulnerable to regress problems by adding another dimension of uncertainty to a parameter (the credence) which already represents uncertainty.

On the other hand (the Boolean approach), you can try to represent your uncertainty about the distribution of the parameter by an instate. I want to show that the Laplacean approach can be aligned with the forceful motivations we listed in the previous section to introduce instates, as long as we do not require that a sharp credence represent the evidence as well as the epistemic state of uncertainty in the agent. We have learned that this requirement can be reduced ad absurdum even for instates (J1).

One of Joyce's complaints is that a sharp credence of $0.5$ for a \textsc{coin} contains too much information if there is little or no evidence that the \textsc{coin} is fair. This complaint, of course, is only effective if the indeterminacy of the credence is anticorrelated to the amount of information in the evidence. In (J1), however, Joyce admits that instates cannot represent the evidence without violating the reflection principle due to White's dilation problem. He is quite clear that the same instate can represent different evidential scenarios (see, for example, \scite{8}{joyce10}{302}). (J1) may not be sufficient to defend against the information argument, but Walley's and Joyce's claim that instates are less informative than sharp credences has no foundation in information theory (see \scite{8}{walley91}{34}; and \scite{8}{joyce10}{311} for examples, but this attitude is passim). To compare instates and sharp credences informationally, we would need a non-additive set function obeying Shannon's axioms for information. This is a non-trivial task. I have not succeeded solving it (nor do I need to carry the Booleans' water), but I am not at all convinced that it will result in an information measure which assigns, for instance, more information to a sharp credence such as $\{0.5\}$ than to an instate such as $\{x|1/3\leq{}x\leq{}2/3\}$.

Returning to (J1) and the problem of inadequate representation, Augustin recognizes this long before Joyce, with specific reference to instates: \qeins{The imprecise posterior does no longer contain all the relevant information to produce optimal decisions. Inference and decision do not coincide any more} \scite{2}{augustin03}{41} (see also an example for inadequate representation of evidence by instates in \scite{8}{bradleysteele13}{16}). At best, instates fare no better than sharp credences, at worst they unhelpfully mimic saying something about the evidence that is much better said elsewhere.

Not only can we align sharp credences with the motivations to introduce instates, we can also show that instates perform worse semantically because they mix evidential and epistemic metaphors in deleterious ways. Sharp credences have one task: to represent epistemic uncertainty and serve as a tool for updating, inference, and decision making. They cannot fulfill this task without continued reference to the evidence which operates in the background. To use an analogy, credences are not sufficient statistics with respect to updating, inference, and decision making. What is remarkable about Joyce's response to White's dilation problem is that Joyce recognizes that instates are not sufficient statistics either. But this means that they fail at the double task which has been imposed on them: to represent both epistemic uncertainty and the evidence.

In the following, I will provide a few examples where it becomes clear that instates have difficulty representing uncertainty because they are tangled in a double task which they cannot fulfill.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Aggregating Expert Opinion.} You have no information whether it will rain tomorrow ($R$) or not except the predictions of two weather forecasters. One of them forecasts 0.3 on channel GPY, the other 0.6 on channel QCT. You consider the QCT forecaster to be significantly more reliable, based on past experience.
\end{quotex}

An instate corresponding to this situation may be $[0.3,0.6]$ (see \scite{8}{walley91}{214}), but it will have a difficult time representing the difference in reliability of the experts. A sharp credence of $P(R)=0.53$, for example, does the right thing. Such a credence says nothing about any beliefs that the objective chance is restricted to a subset of the unit interval, but it accurately reflects the degree of uncertainty that the rational agent has over the various possibilities. Beliefs about objective chances make little sense in many situations where we have credences, since it is doubtful even in the case of rain tomorrow that there is an urn of nature from which balls are drawn. What is really at play is a complex interaction between epistemic states (for example, experts evaluating meteorological data) and the evidence which influences them.

A sharp credence is often associated with probability distributions over chances, while an instate puts chances in sets where they all have an equal voice. This may also be at the bottom of Susanna Rinard's objection (see \scite{8}{white10}{184}) that Joyce's committee members are all equally enfranchised and so it is not clear how extremists among them could not always be replaced by even greater extremists even after updating on evidence which should serve to consolidate indeterminacy. Joyce has a satisfactory response to this objection (see \scite{8}{joyce10}{291}), but I do not see how the response addresses the problem of aggregating expert opinion without the kind of summation that Laplaceans find unobjectionable, even though information is lost and can only be recouped by going back to the evidence. More generally, the two levels for sharp credences, representation of uncertainty and distributions over partitions, tidily differentiate between the epistemic and the evidential dimension; instates, on the other hand, just add another level of uncertainty on top of the uncertainty that is already expressed in the partial belief and thus do not make the appropriate semantic distinctions.

As we will see in the next example, it is an advantage of sharp credences that they do not exclude objective chances, even extreme ones, because they are fully committed to partial belief and do not suggest, as indeterminate credences do, that there is full belief knowledge that the objective chance is a member of a proper subset of the possibilities.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1}\label{monkey} Precise Credences.} Your sharp credence for rain tomorrow, based on the expert opinion of channel GPY and channel QCT (you have no other information) is $0.53$. Is it reasonable, considering how little evidence you have, to reject the belief that the chance of rain tomorrow is $0.52$ or $0.54$; or to prefer a $52.9$ cent bet on rain to a $47.1$ cent bet on no rain?
\end{quotex}

The first question, of course, is confused, but in instructive ways (a display of this confusion is found in \scite{8}{hajeksmithson12}{38f}, and their doctor and time of the day analogy). A sharp credence rejects no hypothesis about objective chances (unlike an instate). It often has a subjective probability distribution operating in the background, over which it integrates to yield the sharp credence (it would do likewise in H{\'a}jek and Smithson's example for the prognosis of the doctor or the time of the day, without any problems). \texttt{<x4.2>}This subjective probability distribution may look like this:

\begin{tabular}{|lcr|}
  \hline
  $P(\pi(R)=0.00)$ & = & $0.0001$ \\ \hline
  $P(\pi(R)=0.01)$ & = & $0.0003$ \\ \hline
  $P(\pi(R)=0.02)$ & = & $0.0007$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.30)$ & = & $0.0015$ \\ \hline
  $P(\pi(R)=0.31)$ & = & $0.0016$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.52)$ & = & $0.031$ \\ \hline
  $P(\pi(R)=0.53)$ & = & $0.032$ \\ \hline
  $P(\pi(R)=0.54)$ & = & $0.030$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
\end{tabular}

It is condensed by Lewis' summation formula to a sharp credence, without being reduced to it:

\begin{equation}
  \label{eq:s2}
  C(R)=\int_{0}^{1}\zeta{}P(\pi(R)=\zeta)\,d\zeta\mbox{ \texttt{</x4.2>}}
\end{equation}

Lewis' 1981 paper \qeins{A Subjectivist's Guide to Objective Chance} addresses the question what the relationship between $\pi$, $P$, and $C$ is. The point is that we have properly separated the semantic dimensions and that the Laplacean approach is not a second order probability approach. The partial belief epistemology deals with sharp credences and how they represent uncertainty and serve as a tool in inference, updating, and decision making; while Lewis' Humean speculations and his interpretation of the principal principle cover the relationship between subjective probabilities and objective chance.

Instates, by contrast, mix these semantic dimensions so that in the end we get a muddle where a superficial reading of indeterminacy suddenly follows a converse principal principle of sorts, namely that objective chances are constrained by the factivity of a rational agent's credence when this credence is knowledge (Lewis actually talks about such a converse, but in completely different and epistemologically more intelligible terms, see \scite{8}{lewis81}{289}). Sharp credences are more, not less, permissive with respect to objective chances operating externally (compared to the internal epistemic state of the agent, which the credence reflects). By the principle of regularity and in keeping with statistical practice, all objective chances as possible states of the world are given positive subjective probabilities, even though they may be very small. Instates, on the other hand, mix partial belief epistemology with full belief epistemology and presumably exclude objective chances which lie outside the credal state from consideration because they are fully known not to hold (see \scite{8}{levi81}{540}, \qeins{inference derives credal probability from knowledge of the chances of possible outcomes}).

The second question is also instructive: why would we prefer a $52.9$ cent bet on rain to a $47.1$ cent bet on no rain, given that we do not possess the power of descrimination between these two bets? The answer to this question ties in with the issue of incomplete preference structure referred to above as motiviation (B) for instates.

\begin{quotex}
  It hardly seems a requirement of rationality that belief be precise (and preferences complete); surely imprecise belief (and corresponding incomplete preferences) are at least rationally permissible. \scite{3}{bradleysteele13}{2}
\end{quotex}

\texttt{<x4.3>}In personal communication, Yang Liu at Columbia University posed this problem to me more forcefully: the development of representation theorems beginning with Frank Ramsey (followed by increasingly more compelling representation theorems in \scite{7}{savage54}{}; and \scite{7}{jeffrey65}{}; and numerous other variants in contemporary literature) puts the horse before the cart and bases probability and utility functions of an agent on her preferences, not the other way around. Once completeness as an axiom for the preferences of an agent is jettisoned, indeterminacy follows automatically. Indeterminacy may thus be a natural consequence of the proper way to think about credences in terms of the preferences that they represent.\texttt{</x4.3>}

In response, preferences may very well logically and psychologically precede an agent's probability and utility functions, but that does not mean that we cannot inform the axioms we use for a rational agent's preferences by undesirable consequences downstream. Completeness may sound like an unreasonable imposition at the outset, but if incompleteness has unwelcome semantic consequences for credences, it is not illegitimate to revisit the issue. Timothy Williamson goes through this exercise with vague concepts, showing that all upstream logical solutions to the problem fail and that it has to be solved downstream with an epistemic solution (see \scite{7}{williamson96}{}). Vague concepts, like sharp credences, are sharply bounded, but not in a way that is luminous to the agent (for anti-luminosity see chapter 4 in \scite{7}{williamson00}{}). Anti-luminosity answers the original question: the rational agent prefers the $52.9$ cent bet on rain to a $47.1$ cent bet on no rain based on her sharp credence without being in a position to have this preference necessarily or have it based on physical or psychological ability (for the analogous claim about knowledge see \scite{8}{williamson00}{95}).

In a way, advocates of indeterminacy have solved this problem for us. There is strong agreement among most of them that the issue of determinacy for credences is not an issue of elicitation (sometimes the term \qnull{indeterminacy} is used instead of \qnull{imprecision} to underline this difference; see \scite{8}{levi85}{395}). The appeal of preferences is that we can elicit them more easily than assessments of probability and utility functions. The indeterminacy issue has been raised to the probability level (or moved downstream) by indeterminacy advocates themselves who feel justifiably uncomfortable with an interpretation of their theory in behaviourist terms. So it shall be solved there, and this paper makes an appeal to reject indeterminacy on this level. The solution then has to be carried upstream (or lowered to the logically more basic level of preferences), where we recognize that completeness for preferences is after all a desirable axiom for rationality. Isaac Levi agrees with me on this point: when he talks about indeterminacy, it proceeds from the level of probability judgment to preferences, not the other way around (see \scite{8}{levi81}{533}).

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Monkey-Filled Urns.} E.T. Jaynes describes an experiment with monkeys filling an urn randomly with balls from another urn, for which sampling provides no information and so makes updating vacuous (see \scite{8}{jaynesbretthorst03}{160}). Here is a variant of this experiment for which a sharp credence provides a more compelling result than the associated instate: Let urn $A$ contain 4 balls, two red and two black. A monkey randomly fills urn $B$ from urn $A$ with two balls. We draw from urn $B$.
\end{quotex}

The sharp credence of drawing a red ball is $0.5$, following Lewis' summation formula for the different combinations of balls in urn $B$. This solution is more intuitive in terms of further inference, decision making, and betting behaviour than a credal state of $\{0,1/2,1\}$ or $[0,1]$ (depending on the convexity requirement), since this instate would licence an exorbitant bet in favour of one colour, for example one that costs \$9,999 and pays \$10,000 if red is drawn and nothing if black is drawn.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Three Prisoners.} Prisoner $X_{1}$ knows that two out of three prisoners ($X_{1},X_{2},X_{3}$) will be executed and one of them pardoned. He asks the warden of the prison to tell him the name of another prisoner who will be executed, hoping to gain knowledge about his own fate. When the warden tells him that $X_{3}$ will be executed, $X_{1}$ erroneously updates his probability of pardon from $1/3$ to $1/2$, since either $X_{1}$ or $X_{2}$ will be spared.
\end{quotex}

Walley maintains that for the Monty Hall problem and the Three Prisoners problem, the probabilities of a rational agent should dilate rather than settle on the commonly accepted solutions. For the Three Prisoners problem, there is a compelling case for standard conditioning and the result that the chances of pardon for prisoner $X_{1}$ are unchanged after the update (see \scite{8}{lukits14}{1421f}). Walley's dilated solution would give prisoner $X_{1}$ hope on the doubtful possibility (and unfounded assumption) that the warden might prefer to provide $X_{3}$'s (rather than $X_{2}$'s) name in case prisoner $X_{1}$ was pardoned.

This example brings an interesting issue to the forefront. Sharp credences often reflect independence of variables where such independence is unwarranted. Booleans (more specifically, detractors of the principle of indifference or the principle of maximum entropy, principles which are used to generate sharp credences for rational agents) tend to point this out gleefully. They prefer to dilate over the possible dependence relationships (independence included). White's dilation problem is an instance of this. The fallacy in the argument for instates, illustrated by the Three Prisoners problem, is that the probabilistic independence of sharp credences does not imply independence of variables (only the converse is correct), but only that it is unknown whether there is dependence, and if yes, whether it is correlation or inverse correlation.

In the Three Prisoners problem, there is no evidence about the degree or the direction of the dependence, and so prisoner $X_{1}$ should take no comfort in the information that she receives. The prisoner's probabilities will reflect probabilistic independence, but make no claims about causal independence. Walley has unkind things to say about sharp credences and their ability to respond to evidence (for example that their \qeins{inferences rarely conform to evidence}, see \scite{8}{walley91}{396}), but in this case it appears to me that they outperform the Boolean approach.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Wagner's Linguist.} A linguist hears the utterance of a native and concludes that the native cannot be part of certain population groups, depending on what the utterance means. The linguist is uncertain between some options about the meaning of the utterance. (For full details see \scite{8}{wagner92}{252}; and \scite{8}{spohn12}{197}.)
\end{quotex}

The mathematician Carl Wagner proposed a natural generalization of Jeffrey Conditioning for his Linguist example (see \scite{7}{wagner92}{}). Since the principle of maximum entropy is already a generalization of Jeffrey Conditioning, the question naturally arises whether the two generalizations agree. Wagner makes the case that they do not agree and deduces that the principle of maximum entropy is sometimes an inappropriate updating mechanism, in line with many earlier criticisms of the principle of maximum entropy (see van Fraassen,\fixref{7}{fraassen81}{} 1981; \scite{7}{shimony85}{}; \scite{7}{skyrms87updating}{}; and, later on, \scite{7}{grovehalpern97}{}). What is interesting about this case is that Wagner uses instates for his deduction, so that even if you agree with his natural generalization of Jeffrey Conditioning (which I find plausible), the inconsistency with the principle of maximum entropy can only be inferred assuming instates. Wagner is unaware of this, and I am showing in another paper (in process) how on the assumption of sharp credences Wagner's generalization of Jeffrey conditioning accords with the principle of maximum entropy.

This will not convince Booleans, since they are already unlikely to believe in the general applicability of the principle of maximum entropy (just as Wagner's argument is unlikely to convince a proponent of the principle of maximum entropy, since they are more likely to reject instates). The battle lines are clearly drawn. Wagner's argument, instead of undermining the principle of maximum entropy, just shows that instates are as wedded to rejecting the claims of the principle of maximum entropy as the principle of maximum entropy is wedded to sharp credences.

Endorsement of instates, however, implies that there are situations of probability update in which the posterior probability distribution is more informative than it might be in terms of information theory. Indeterminate credences violate the relatively natural intuition that we should not gain information from evidence when a less informative updated probability will do the job of responding to the evidence. This is not a strong argument in favour of sharp credences. The principle of maximum of entropy has received a thorough bashing in the last forty years. I consider it to be much easier to convince someone to reject instates on independent (semantic) grounds than to convince them to give the principle of maximum entropy a second chance. But the section on semantics comes to an end here, and we want to proceed to the intriguing issue of who does better in betting situations: instates or sharp credences.

\section{Evidence Differentials and Cushioning Credences}
\label{WalleysWorldCupWoes}

I have given away the answer already in the introduction: instates do better. It is surprising that, except for a rudimentary allusion to this in Walley's book, no Boolean has caught on to this yet. After I found out that agents with instates do better betting on soccer games, I let Betsy and Linda play a more basic betting game. An $n$-sided die is rolled (by the computer). The die is fair, unbeknownst to the players. Their bets are randomly and uniformly drawn from the simplex for which the probabilities attributed to the $n$ results add up to 1. Betsy also surrounds her credences with an imprecision uniformly drawn from the interval $(0,y)$. I used Walley's pay off scheme (see \scite{8}{walley91}{632}) to settle the bets.

\texttt{<x5.1>}Here is an example: let $n=2$, so the die is a fair \textsc{coin}. $X$'s and $Y$'s bets are randomly and uniformly drawn from the line segment from $(0,1)$ to $(1,0)$ (these are two-dimensional Cartesian coordinates), the two-dimensional simplex (for higher $n$, the simplex is a pentatope generalized for $n$ dimensions with side length $2^{1/2}$). The bets may be $(0.21,0.79)$ for Linda and $(0.35\pm{}0.11,0.65\pm{}0.11)$ for Betsy, where the indeterminacy $\pm{}0.11$ is also randomly and uniformly drawn from the imprecision interval $(0,y)\subseteq(0,1)$. The first bet is on $H$, and Betsy is willing to pay $22.5$ cents for it, while $X$ is willing to pay $77.5$ cents against it. The second bet is on $T$ (if $n>2$, there will not be the same symmetry as in the \textsc{coin} case between the two bets), for which Linda is willing to pay $77.5$ cents, and against which Betsy is willing to pay $22.5$ cents. Each bet pays \$1 if successful. Often, $Y$'s credal state will overlap with $X$'s sharp credence so that there will not be a bet.\texttt{</x5.1>}

\texttt{<x5.2>}Here is a table of the results. Each result is based on 100,000 die rolls. The second column shows the mean gain for Linda, the third column shows the standard deviation, the fourth column shows the percentage of bets which are called off. The table is for $y=1$.

\begin{tabular}{|l|r|r|r|}
  \hline
  $n=2$ & 0.14 & 18.8 & 25.2 \\ \hline
  $n=3$ & -1.67 & 13.7 & 39.1 \\ \hline
  $n=4$ & -1.73 & 10.4 & 48.1 \\ \hline
  $n=5$ & -1.39 & 8.2 & 54.5 \\ \hline
  $n=6$ & -1.22 & 6.6 & 59.1 \\ \hline
  $n=7$ & -1.01 & 5.5 & 62.8 \\ \hline
\end{tabular}

Here are the results if Betsy is not as generous with her indeterminacy, $y=0.3$ (note that fewer bets are called off). The second column still shows Linda's mean gain.

\begin{tabular}{|l|r|r|r|}
  \hline
  $n=2$ & 5.82 & 28.0 & 0.0 \\ \hline
  $n=3$ & -0.55 & 21.8 & 0.0 \\ \hline
  $n=4$ & -2.32 & 17.0 & 0.0 \\ \hline
  $n=5$ & -2.89 & 13.7 & 0.4 \\ \hline
  $n=6$ & -2.74 & 11.3 & 1.4 \\ \hline
  $n=7$ & -2.52 & 9.6 & 3.2 \\ \hline
\end{tabular}

We should get similar results if we do this analytically instead of using computer simulation. I will pursue this further for the final version of the paper. The math is not complicated, but unwieldy. The following expression yields the expected gain for Linda:

\begin{eqnarray}
  \label{eq:s3}
  EX =
  \frac{p_{x}}{n}\left(\sum_{j=0}^{n-1}\int_{0}^{1}\int_{0}^{x}\int_{0}^{x-y}\sum_{k=0}^{n-1}g(x,y,s,k,j)\,ds\,d\upsilon(y)\,d\xi(x)\right)+
  \notag \\
  \frac{p_{y}}{n}\left(\sum_{j=0}^{n-1}\int_{0}^{1}\int_{0}^{1}\int_{0}^{y-s}\sum_{k=0}^{n-1}g(x,y,s,k,j)\,d\xi(x)\,d\upsilon(y)\,ds\right)
\end{eqnarray}

where $p_{x}$ and $p_{y}$ are the respective probabilities that $X$ and $Y$ win a bet and $g$ is $X$'s gain given $X$'s credence $x$ and $Y$'s credal state $y\pm{}s$ on roll $j$, given result $k$. $\xi(x)$ and $\upsilon(y)$ are the distributions of the credences given our method of simplex point picking (for these distributions, one must use the Cayley-Menger Determinant to find out the volume of generalized pentatopes involved).\texttt{</x5.2>} The computer simulation clearly shows that except for $n=2$, the \textsc{coin} toss, Betsy does better. A defence of sharp credences for rational agents needs to have an explanation for this. We will call it partial belief cushioning, which is based on an evidence differential between the bettors.

In many decision-making contexts, we do not have the luxury of calling off the bet. We have to decide one way or another. This is a problem for instates, as Booleans have to find a way to decide without receiving instructions from the credal state. Booleans have addressed this point extensively (see for example \scite{8}{joyce10}{311ff}; for an opponent's view of this see \scite{8}{elga10}{6ff}). The problem for sharp credences arises when bets are noncompulsory, for then the data above suggest that agents holding instates sometimes do better. Often, decision making happens as betting vis-{\`a}-vis uninformed nature or opponents which are at least as uninformed as the rational agent. Sometimes, however, bets are offered by better informed or potentially better informed bookies. In this case, even an agent with sharp credences must cushion her credences and is better off by rejecting bets that look attractive in terms of her partial beliefs. 

If an agent does not cushion her partial beliefs (whether they are sharp or indeterminate), she will incur a loss in the long run. Since cushioning is permitted in Walley's experimental setup (the bets are noncompulsory), Laplacean agents should also have access to it and then no longer do worse than Boolean agents. One may ask what sharp credences do if they just end up being cushioned anyway and do not provide sufficient information to decide on rational bets. The answer is that sharp credences are sufficient where betting (or decision making more generally) is compulsory; the cushioning only supplies the information from the evidence in as much as betting is noncompulsory and so again properly distinguishes semantic categories. This task is much harder for Booleans, although I do not claim that it is insurmountable: instates can provide a coherent approach to compulsory betting. What they cannot do, once cushioning is introduced, is outperform sharp credences in noncompulsory betting situations.

Here are a few examples: even if I have little evidence on which to base my opinion, someone may force me to either buy Coca Cola shares or short them, and so I have to have a share price $p$ in mind that I consider fair. I will buy Coca Cola shares for less than $p$, and short them for more than $p$, if forced to do one or the other. This does not mean that it is now reasonable for me to go (not forced by anyone) and buy Coca Cola shares for $p$. It may not even be reasonable to go (not forced by anyone) and buy Coca Cola share for $p-\delta$ with $\delta{}>0$.

It may in fact be quite unreasonable, since there are many players who have much better evidence than I do and will exploit my ignorance. I suspect that most lay investors in the stock market make this mistake: even though they buy and sell stock at prices that seem reasonable to them, professional investors are much better and faster at exploiting arbitrage opportunities and more subtle regularities. If indices rise, lay investors will make a little less than their professional counterparts; and when they fall, lay investors lose a lot more. In sum, unless there is sustained growth and everybody wins, lay investors lose in the long term.

A case in point is the U.S. Commodity Futures Trading Commission's crackdown on the online prediction market Intrade. Intrade offered fair bets for or against events of public significance, such as election results or other political events which had clear yes-or-no outcomes. Even though the bets were all fair and Intrade only received a small commission on all bets, and even though Intrade's predictions were remarkably accurate, the potential for professional arbitrageurs was too great and the CFTC shut Intrade down (see \texttt{https://www.intrade.com}).

Cushioning does not stand in the way of holding a sharp credence, even if the evidence is dim. The evidence determines for a rational agent the partial beliefs over possible states of the world operating in the background. The better the evidence, the more pointed the distributions of these partial beliefs will be and the more willing the rational agent will be to enter a bet, if betting is noncompulsory. The mathematical decision rule will be based on the underlying distribution of the partial beliefs, not only on the sharp credence. As we have stated before, the sharp credence is not a sufficient statistic for decision making, inference, or betting behaviour; and neither is an instate. 

The rational agent with a sharp credence has resources at her disposal to use just as much differentiation with respect to accepting and rejecting bets as the agent with instates. Often (if she is able to and especially if the bets are offered to her by a better-informed agent), she will reject both of two complementary bets, even when they are fair. On the one hand, any advantage that the agent with an instate has over her can be counteracted based on her distribution over partial beliefs that she has with respect to all possibilities. On the other hand, the agent with instates suffers from a semantic mixing of metaphors between evidential and epistemic dimensions that puts her at a real disadvantage in terms of understanding the sources and consequences of her knowledge and her uncertainties.

\section{References}
\label{References}

% \nocite{*} 
\bibliographystyle{ChicagoReedweb} 
\bibliography{bib-7293}

\end{document} 
