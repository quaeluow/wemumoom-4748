        Synopsis for "Semantics of Not Knowing"

                                     Stefan Lukits


Traditional Bayesian epistemology used to include the requirement for a
rational agent to hold a sharp credence function. It has recently become
popular to drop this requirement. There are now Bayesian theories which
permit a rational agent to hold indeterminate credal states based on incom-
plete or ambiguous evidence. I will refer to Bayesians who continue to adhere
to the classical theory of sharp credences for rational agents as 'Laplaceans'
(e.g. Adam Elga and Roger White). I will refer ot Bayesians who do not
believe in the requirement for a rational agent to hold sharp credences as
'Booleans' (e.g. Peter Walley and James Joyce; see Boole, 1854, chapters 16--
21, for alternative methods to the ones suggested by Laplace which resulted
in imprecise epistemic probabilities).
After describing the appeal of indeterminacy and showing how contempo-
rary Laplacean objections fail, I will point to more serious failings of in-
determinacy in semantic terms and show how a proper semantics of not
knowing, which we could also call a semantics of partial belief, solves the
problems for sharp credences that Booleans seek to address by abolition.
There is a sense in which, by linking knowledge of chances to its reflection
in credences, Booleans seek to reconcile traditional knowledge epistemology
concerned with full belief and formal epistemology concerned with partial
belief. There are other more recent reconciliation projects (see Spohn, 2012;
and Moss, 2013), but if my paper is correct then the Boolean approach will
not contribute to this reconciliation because it mixes full belief and partial
belief metaphors in ways that are semantically problematic.

A sharp credence, as much as the term suggests precision and a measure
of certainty, is a representation of an epistemic state chracterized by un-
certainty and lack of information. Importantly, it does not represent the
evidence which informs the epistemic state, and it makes no claim of such a
representation. Indeterminate credal states are often lauded as doing much
better representing uncertainty together with the evidence that constrains

                                             1


it, but they can no more give an adequate representation of evidence than
sharp credences. Thus it is legitimate to have a 0.5 sharp credence in heads
for a coin of whose bias we are completely ignorant; for a coin whose fairness
is supported by a lot of evidence; and even for a coin about whose bias we
know that it is either 1/3 or 2/3 for heads.
One potential Boolean claim is that agents who use indeterminate credal
states do better than Laplaceans when they bet on the truth of events for
which they have varying degrees of evidence. Peter Walley gives an exam-
ple where a Laplacean does much worse at predicting soccer games than
Boolean peers. I show that the result is due to an unreasonable restriction
on the betting behaviour of the Laplacean. Once this restriction is lifted,
Laplaceans do just as well as Booleans, except that they are not tangled in
the semantic problem of the double task, where indeterminate credal states
are supposed to reflect both the uncertainty of an agent and other properties
of her evidence.
I will present several examples where this double task stretches indetermi-
nate credal states to the limits of plausibility, for example when they need to
aggregate expert opinion or account for dilation. Joyce's idea that credences
can represent balance, weight, and specificity of the evidence is inconsistent
with the use of indeterminacy (and Joyce himself, in response to the dila-
tion problem, gives the argument why this is the case). The implicit Boolean
claim that evidence can be recovered from indeterminate credal states is in-
consistent with an effective Boolean answer to the dilation problem.

The Laplacean approach of assigning subjective probabilities to distributions
and then aggregating them by David Lewis's summation formula into a
single precise credence function is semantically clean and shares many of the
formal virtues of Boolean theories. If the bad taste about numerical precision
in our fuzzy, nebulous world lingers, we can point to philosophical projects in
other domains where the concepts we use are sharply bounded, even though
our ability to conceive of those sharp boundaries or know them is limited,
for example Timothy Williamson's work on vagueness and knowledge as a
mental state.






                                             2


