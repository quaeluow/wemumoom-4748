Traditional Bayesian epistemology used to include the requirement for
a rational agent to hold a sharp credence function. It has recently
become popular to drop this requirement. There are now Bayesian
theories which permit a rational agent to hold indeterminate credal
states based on incomplete or ambiguous evidence. I will refer to
Bayesians who continue to adhere to the classical theory of sharp
credences for rational agents as \qnull{Laplaceans} (e.g.\ Adam Elga
and Roger White). I will refer to Bayesians who do not believe in the
requirement for a rational agent to hold sharp credences as
\qnull{Booleans} (e.g.\ Peter Walley and James Joyce; see Boole, 1854,
chapters 16--21, for alternative methods to the ones suggested by
Laplace which result in imprecise epistemic probabilities).

After describing the appeal of indeterminacy and showing how
contemporary Laplacean objections fail, I will point to more serious
failings of indeterminacy in semantic terms and show how a proper
semantics of not knowing, which we could also call a semantics of
partial belief, solves the problems for sharp credences that Booleans
address by introducing indeterminate credal states. There is a sense
in which, by linking knowledge of chances to its reflection in
credences, Booleans seek to reconcile traditional knowledge
epistemology concerned with full belief and formal epistemology
concerned with partial belief. There are other more recent
reconciliation projects (see Spohn, 2012; and Moss, 2013), but if my
paper is correct then the Boolean approach will not contribute to this
reconciliation because it mixes full belief and partial belief
metaphors in ways that are semantically problematic.

A sharp credence, as much as the term suggests precision and a measure
of certainty, is a representation of an epistemic state chracterized
by uncertainty and lack of information. Importantly, it does not
represent the evidence which informs the epistemic state, and it makes
no claim of such a representation. Indeterminate credal states are
often lauded as doing much better representing uncertainty together
with the evidence that constrains it, but they can no more give an
adequate representation of evidence than sharp credences. This paper
is concerned with the semantic legitimacy of having a $0.5$ sharp
credence in heads for a coin of whose bias we are completely ignorant;
for a coin whose fairness is supported by a lot of evidence; and even
for a coin about whose bias we know to be either 1/3 or 2/3 for heads.

One potential Boolean claim is that agents who use indeterminate
credal states do better than Laplaceans when they bet on the truth of
events for which they have varying degrees of evidence. Peter Walley
gives an example where a Laplacean does much worse at predicting
soccer games than Boolean peers. I show that the result is due to an
unreasonable restriction on the betting behaviour of the Laplacean.
Once this restriction is lifted, Laplaceans do just as well as
Booleans, except that they are not tangled in the semantic problem of
the double task, where indeterminate credal states are supposed to
reflect both the uncertainty of an agent and other properties of her
evidence.

I will present several examples where this double task stretches
indeterminate credal states to the limits of plausibility, for example
when they need to aggregate expert opinion or account for dilation.
Joyce's idea that credences can represent balance, weight, and
specificity of the evidence is inconsistent with the use of
indeterminacy (and Joyce himself, in response to the dilation problem,
gives the argument why this is the case). The implicit Boolean claim
that certain properties of the evidence (its ambiguity, its
completeness, conflicts within it) can be recovered from indeterminate
credal states is inconsistent with an effective Boolean answer to the
dilation problem.

The Laplacean approach of assigning subjective probabilities to
partitions of the event space (e.g.\ objective chances) and then
aggregating them by David Lewis's summation formula into a single
precise credence function is semantically tidy and shares many of the
formal virtues of Boolean theories. If the bad taste about numerical
precision in our fuzzy, nebulous world lingers, I can point to
philosophical projects in other domains where the concepts we use are
sharply bounded, even though our ability to conceive of those sharp
boundaries or know them is limited, for example Timothy Williamson's
work on vagueness and knowledge as a mental state.
