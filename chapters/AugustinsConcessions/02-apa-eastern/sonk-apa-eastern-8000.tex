\documentclass[11pt]{article}
\usepackage{october}

\begin{document}

\title{Augustin's Concessions: A Problem for Indeterminate Credal States}
\author{Stefan Lukits}
\date{}
\maketitle
\newcounter{expls}

\section{Introduction}
\label{Introduction}

The claim is that rational agents are subject to a norm requiring
sharp credences. I defend this claim in spite of the initially
promising features of indeterminate credal states (from now on
instates) to address problems which sharp credences have as they
reflect evidence. Traditionally, Bayesians have maintained that a
rational agent, when holding a credence, holds a sharp credence. It
has recently become popular to drop the requirement for credence
functions to be sharp. There are now Bayesians who permit a rational
agent to hold instates based on incomplete or ambiguous evidence. I
will refer to Bayesians who continue to adhere to the classical theory
of sharp credences for rational agents as \qnull{Laplaceans} (e.g.\
Adam Elga and Roger White). I will refer to Bayesians who do not
believe that a rational agent's credences are sharp as
\qnull{Booleans} (e.g.\ Peter Walley and James Joyce).\fcut{1}

There is some terminological confusion around the adjectives
\qnull{imprecise,} \qnull{indeterminate,} and \qnull{mushy} credences.
In the following, I will exclusively refer to indeterminate credences
or credal states (abbreviated \qnull{instates}) and mean by them a set
of sharp credence functions (which some Booleans require to be convex)
which it may be rational for an agent to hold within an otherwise
orthodox Bayesian framework.\bcut{1}

There is a sense in which, by linking knowledge of chances to its
reflection in credences, Booleans seek to reconcile traditional
knowledge epistemology concerned with full belief and formal
epistemology concerned with partial belief. There are other more
recent reconciliation projects (see Spohn, 2012; and Moss, 2013). If
my paper is correct then the Boolean approach will not contribute to
this reconciliation because it mixes full belief and partial belief
metaphors in ways that are problematic.\fcut{2}\bcut{2}

Instates represent in one credence both degree of belief and
properties of the evidence. Instates thus incorporate both {\doxnotep}
and evidential features of the credal state. Representing multiple
features of a state is not per se a bad thing when we fix the terms of
a theory, in this case the terms of our theory of partial beliefs. In
colour theory, the term \qnull{red} represents both a phenomenological
quality and a neighbourhood on the visible light spectrum. When we say
one thing is more red than another thing, we effectively describe a
relation based on both phenomenological and physical properties.

My examples and conceptual arguments show that instates fail to give
us a coherent terminology in our theory of partial beliefs. It turns
out that we want to separate the {\doxnotep} and evidential
components, just as the scientific mineralogist wants to separate
jadeite and nephrite instead of lumping them together under the single
concept of \qnull{jade.} Contrary to how it appears at first, it
is the sharp credence which allows for greater latitude as to which
possibilities are still being considered and assigned positive
probability, compared to the instate. The main argument, however, adds
to the conceptual comparison that what is most compelling about
instates must be yielded by Booleans as concessions to a hands-on
problem facing instates.

When we first hear of the advantages of instates, two of them sound
particularly persuasive.

\begin{itemize}
\item \textsc{range} Instates represent the possibility range for objective
  chances.
\item \textsc{incomp} Instates represent incompleteness or ambiguity of the
  evidence.\bcut{3}
\end{itemize}

Let a \textit{coin} be a Bernoulli generator that produces successes
and failures with probability $p$ for success, labeled $H$, and $1-p$
for failure, labeled $T$. Physical coins may serve as examples, if we
are willing to set aside that most of them are approximately fair.

\addtocounter{expls}{1}

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Range.} Bob
  has two Bernoulli Generators in his lab, \textit{coin}$_{a}$ and
  \textit{coin}$_{b}$. Bob has a database of \textit{coin}$_{a}$
  results and concludes on excellent evidence that \textit{coin}$_{a}$
  is fair. Bob has no evidence about the bias of \textit{coin}$_{b}$.
  As a Boolean, Bob assumes a sharp credence of $\{0.5\}$ for success
  on the next toss of \textit{coin}$_{a}$ and an indeterminate credal
  state of $[0,1]$ for success on the next toss of
  \textit{coin}$_{b}$. He feels bad for Larry, his Laplacean
  colleague, who cannot distinguish between the two cases and who must
  assign a sharp credence of $\{0.5\}$ for success on the next toss of
  both \textit{coin}$_{a}$ and \textit{coin}$_{b}$.
\end{quotex}

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Incomp.} Bob
  has another Bernoulli Generator, \textit{coin}$_{c}$, in his lab.
  His graduate student has submitted \textit{coin}$_{c}$ to countless
  experiments and emails Bob the resulting bias, but fails to include
  whether the bias of $2/3$ is in favour of $H$ or in favour of $T$.
  As a Boolean, Bob assumes an indeterminate credal state of
  $[1/3,2/3]$ (or $\{1/3,2/3\}$) for success on the next toss of
  \textit{coin}$_{c}$. He feels bad for Larry who must assign a sharp
  credence of $\{0.5\}$ for success on the next toss of
  \textit{coin}$_{c}$ when Larry concurrently knows that his credence
  gets the bias wrong.
\end{quotex}

Against the force of \textsc{range} and \textsc{incomp}, I maintain
that the Laplacean approach of assigning subjective probabilities to
partitions of the event space (e.g.\ objective chances) and then
aggregating them by David Lewis' summation formula into a single
precise credence function is conceptually tidy and shares many of the
formal virtues of Boolean theories. To put it provocatively, this
paper defends a $0.5$ sharp credence in heads in all three cases: for
a coin of whose bias we are completely ignorant; for a coin whose
fairness is supported by a lot of evidence; and even for a coin about
whose bias we know that it is either 1/3 or 2/3 for heads. 

The following reasons incline Booleans to permit instates for rational
agents:

\begin{enumerate}[(A)]
\item The greatest emphasis motivating indeterminacy rests on
  \textsc{range} and \textsc{incomp}.
\item The preference structure of a rational agent may be incomplete
  so that representation theorems do not yield single probability
  measures to represent such incomplete structures.
\item There are more technical and paper-specific reasons, such as
  Thomas Augustin's attempt to mediate between the minimax pessimism
  of objectivists and the Bayesian optimism of subjectivists using
  interval probability (see \scite{8}{augustin03}{35f}); Alan
  H{\'a}jek and Michael Smithson's belief that there may be
  objectively indeterminate chances in the physical world (see
  \scite{8}{hajeksmithson12}{33}); and Jake Chandler's claim that
  \qeins{the sharp model is at odds with a trio of plausible
    propositions regarding agnosticism} \scite{2}{chandler14}{4}.
\end{enumerate}

This paper mostly addresses (A), while taking (B) seriously as well
and pointing towards solutions for it. I am leaving (C) to more
specific responses to the issues presented in the cited articles.

\section{Augustin's Concessions}
\label{AugustinsConcessions}

Here is a problem for Booleans:

\begin{itemize}
\item \textsc{dilation} Instates are vulnerable to dilation.
\end{itemize}

\textsc{dilation} is best explained by example.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Dilation.}
  You have two Bernoulli Generators, \textit{coin}$_{d}$ and
  \textit{coin}$_{e}$. You have excellent evidence that
  \textit{coin}$_{d}$ is fair and no evidence about the bias of
  \textit{coin}$_{e}$. Furthermore, the two generators are not
  necessarily independent. Their results could be 100\% correlated or
  anticorrelated, or the correlation could be anywhere between the two
  extremes, including independence. You toss \textit{coin}$_{d}$.
  Without looking at the result, your credence in $H_{d}$
  (\textit{coin}$_{d}$ coming up heads) is a sharp $\{0.5\}$, even if
  you are a Boolean, because you have excellent evidence for the
  fairness of \textit{coin}$_{d}$. Then you toss \textit{coin}$_{e}$.
  This time you look at the result and the moment you learn it, your
  credence in success for the previous and unknown toss of
  \textit{coin}$_{d}$ dilates from a sharp $\{0.5\}$ to the vacuous
  credal state covering the whole interval $[0,1]$ (provided that this
  was your credence in success for the toss of \textit{coin}$_{e}$, as
  stipulated). Even though you have just received information (the
  result of \textit{coin}$_{e}$'s toss), your credence in success for
  the toss of \textit{coin}$_{d}$ dilates.
\end{quotex}

This does not sound like a knock-down argument against Booleans (it
was investigated in detail in \scite{7}{seidenfeldwasserman93}{}), but
Roger White was able to use it to derive implications from instates
which are worrisome.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} White
    Chocolates.} Four out of five chocolates in the box have cherry
  fillings, while the rest have caramel. Picking one at random, what
  should my credence be that it is cherry-filled? Everyone, including
  the staunchest [Booleans], seems to agree on the answer $4/5$. Now
  of course the chocolate I've chosen has many other features, for
  example this one is circular with a swirl on top. Noticing such
  features could hardly make a difference to my reasonable credence
  that it is cherry filled (unless of course I have some information
  regarding the relation between chocolate shapes and fillings). Often
  chocolate fillings do correlate with their shapes, but I haven't the
  faintest clue how they do in this case or any reason to suppose they
  correlate one way rather than another {\ldots} the further result is
  that while my credence that the chosen chocolate is cherry-filled
  should be $4/5$ prior to viewing it, once I see its shape (whatever
  shape it happens to be) my credence that it is cherry-filled should
  dilate to become [indeterminate]. But this is just not the way we
  think about such matters. (Quoted verbatim from
  \scite{8}{white10}{183}.)
\end{quotex}

Joyce, an authoritative Boolean voice, has defended instates against
\textsc{dilation}, making Augustin's concessions (AC1) and (AC2). I
named them after Thomas Augustin, who has some priority over Joyce in
the matter, and the name James Joyce does not lend itself to literary
double entendre.

\begin{description}
\item[{\bf (AC1)}] Credences do not adequately represent evidence (the
  same instate can reflect different evidential states).
\item[{\bf (AC2)}] Instates do not reflect knowledge claims about
  objective chances (White's \emph{Chance Grounding Thesis} is not an
  appropriate characterization of the Boolean position).
\end{description}

I agree with Joyce that (AC1) and (AC2) are both necessary and
sufficient to resolve \textsc{dilation} for instates. I will address
this in more detail in a moment. I disagree with Joyce what this means
for an overall recommendation to accept the Boolean rather than the
Laplacean position. I will show that (AC1) and (AC2) neutralize both
\textsc{range} and \textsc{incomp}, the two major impulses for
rejecting the Laplacean position. Laplaceans, more modestly, consider
a credence to represent the {\doxnotep} features of the credal state
while filtering out some evidential features, which need to be
independently represented. Overall, a sharp credence reflects the
credal state and does not represent it (cashing out the difference in
the sense that a credence which reflects the credal state is not
sufficient for inference, updating, and decision making; whereas a
credence which represents the credal state would be sufficient). If
instates could successfully integrate all evidential features of the
credal state, including its {\doxnotep} features, they would represent
it. \textsc{dilation} combined with (AC1) and (AC2) show that they
cannot.\bcut{4}\bcut{5}

Indeterminacy imposes a double task on credences (representing both
uncertainty and available evidence) that they cannot coherently
fulfill. I will present several examples where this double task
stretches instates to the limits of plausibility. Joyce's idea that
credences can represent balance, weight, and specificity of the
evidence (in \scite{7}{joyce05}{}) is inconsistent with the use of
indeterminacy. Joyce himself, in response to \textsc{dilation}, gives
the argument why this is the case (see
\scite{8}{joyce10}{13ff}).\bcut{12} Let us look at reasons for (AC1)
and (AC2) more closely.

\subsection{Augustin's Concession (AC1)}
\label{jj1}

(AC1) says that credences do not adequately represent evidence. The
same instate can reflect different evidential states.

Augustin recognizes the problem of inadequate representation before
Joyce, with specific reference to instates: \qeins{The imprecise
  posterior does no longer contain all the relevant information to
  produce optimal decisions. Inference and decision do not coincide
  any more} \scite{2}{augustin03}{41} (see also an example for
inadequate representation of evidence by instates in
\scite{8}{bradleysteele13}{16}). Joyce rejects the notion that
identical instates encode identical beliefs by giving a simple
example:

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Three-Sided
    Die.} Let $\mathcal{C}'$ and $\mathcal{C}''$ be sets of credence
  functions defined on a partition $\{X,Y,Z\}$ corresponding to the
  result of a roll of a three sided-die. $\mathcal{C}'$ contains all
  credence functions $\mathbf{c}$ for which $\mathbf{c}(Z)\geq{}1/2$.
  $\mathcal{C}''$ contains all credence functions $\mathbf{c}$ for
  which $\mathbf{c}(X)=\mathbf{c}(Y)$ (see \scite{8}{joyce10}{12}).
\end{quotex}

$\mathcal{C}'$ and $\mathcal{C}''$ generate the same instates, but
they surely differ in the beliefs that they encode. The belief
corresponding to $\mathcal{C}'$ regards $X$ and $Y$ as equiprobable,
the belief corresponding to $\mathcal{C}''$ does not. To say that
\textsc{dilation} is a problem for the Boolean position presupposes
that instates encode beliefs, since if they do not it becomes clear
why the correlation between the two coin tosses is evidentially
relevant to success for \textit{coin}$_{a}$ in Example TBA\tbd{}. If
instates encoded the evidential basis for a belief, however, there
could be no weights attached to the various credence functions
represented by the instate based on the evidence. All \qnull{committee
  members,} as Joyce calls them in illustrating how instates work by
committee rather than one single credence function, would be equally
enfranchised, which would inhibit learning and either introduce
regress problems on the non-trivial margins of the indeterminate
intervals or render all instates vacuous.

On the one hand (the Laplacean approach), you can have partial beliefs
about how a parameter is distributed and then use Lewis' summation
formula (see \scite{8}{lewis81}{266f}) to integrate over them and
condense them to a sharp credence. Walley comments on this
\qeins{reduction} in his section on Bayesian second order
probabilities (see \scite{8}{walley91}{258f}), but he mistakenly
represents the Laplacean approach as a second order approach, as if
the probability distributions that are summarized by Lewis' formula
are of the same kind as the resulting credences. They are not. They
refer to partitions of the event space, sometimes corresponding to
objective chances, and represent the subjective probabilities that are
associated with them. The credence, by contrast, is a quantity
reflecting partial belief and assisting in the making of decisions and
inferences. It is the Boolean approach which has elements of a second
order approach and thus makes itself vulnerable to regress problems by
adding another dimension of uncertainty to a parameter (the credence)
which already represents uncertainty.\bcut{11}

\subsection{Augustin's Concession (AC2)}
\label{jj2}

(AC2) says that instates do not reflect knowledge claims about
objective chances. White's \emph{Chance Grounding Thesis} is not an
appropriate characterization of the Boolean position:

\begin{quotex}
  \textbf{Chance Grounding Thesis:} Only on the basis of known chances
  can one legitimately have sharp credences. Otherwise one's spread of
  credence should cover the range of possible chance hypotheses left
  open by your evidence. \scite{2}{white10}{174}\bcut{13}
\end{quotex}

Usually, we would expect more information to sharpen our credal states
(see Walley's \qeins{the more information the more precision}
principle and his response to this problem in
1991,\fixref{8}{walley91}{207 and 299} 207 and 299).\tbd{Expand.}
Joyce rejects the CGT on the grounds that it would make learning
impossible (see \scite{8}{joyce10}{7f}).\tbd{Expand.}

White's claim is also that \textsc{dilation} contradicts Bas van
Fraassen's reflection principle (see van Fraassen,
1984\fixref{7}{vanfraassen84}{}). If you know that soon you will take
a dilated doxastic attitude towards a proposition without loss of
information and no surprising information coming in, you can just as
well assume the dilated doxastic attitude now, which is
counter-intuitive (see \scite{8}{white10}{178}).

Joyce underlines how \qnull{committee members} can be discriminately
enfranchised by a \qeins{directionality of the spread} (see
\scite{8}{joyce10}{318}), which clarifies that instates, as little as
sharp credences, adequately represent the evidence supporting the
partial belief. Joyce gives a nice formal description of this, but I
want to show by example how dilation is unproblematic (and therefore
agree with Joyce that instates cannot encode beliefs).\fcut{11}

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Dilating
    Urns.} You draw one ball from an urn with 200 balls (100 red, 100
  black) and receive the information that the urn actually had two
  chambers, one with 99 red balls and 1 black ball, the other with 1
  red ball and 99 black balls.
\end{quotex}

Dilation from a sharp credence of $\{0.5\}$ to an instate of
$\{0.01,0.99\}$ or $[0.01,0.99]$ (depending on whether convexity is
required) is unproblematic, although the example already prefigures
that there is something odd about the Boolean conceptual approach. The
example licences a 99:1 bet for one of the colours (if the instate is
interpreted as upper and lower previsions), but this is a problem that
arises out of the Boolean position without dilation, which we will
address again in Example TBA\tbd{}.

\textsc{dilation} is in principle not any more surprising than a piece
of information that increases the Shannon entropy of a sharp credence
(see Example TBA\tbd{}). It is true for both sharp and indeterminate credences
that information can make us less certain about things, and it is true
for both sharp and indeterminate credences that they do not encode the
evidence.

If one were to be committed to the principle of regularity, that all
states of the world considered possible have positive probability (for
a defence see \scite{7}{edwardsetal63}{}); and to the solution of
Henry Kyburg's lottery paradox, that what is rationally accepted
should have probability 1 (for a defence of this principle see
\scite{7}{douvenwilliamson06}{}); and the CGT, that one's spread of
credence should cover the range of possible chance hypotheses left
open by the evidence (implied by much of Boolean literature); then
one's instate would always be vacuous. Booleans must deny at least one
of the premises to avoid the conclusion (Joyce denies the CGT).

\section{The Double Task}
\label{TheDoubleTask}

Sharp credences have one task: to represent epistemic uncertainty and
serve as a tool for updating, inference, and decision making. They
cannot fulfill this task without continued reference to the evidence
which operates in the background. To use an analogy, credences are not
sufficient statistics with respect to updating, inference, and
decision making. What is remarkable about Joyce's response to
\textsc{dilation} is that Joyce recognizes that instates are not
sufficient statistics either. But this means that they fail at the
double task which has been imposed on them: to represent both
epistemic uncertainty and the evidence.

In the following, I will provide a few examples where it becomes clear
that instates have difficulty representing uncertainty because they
are tangled in a double task which they cannot fulfill.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Aggregating
    Expert Opinion.} You have no information whether it will rain
  tomorrow ($R$) or not except the predictions of two weather
  forecasters. One of them forecasts 0.3 on channel GPY, the other 0.6
  on channel QCT. You consider the QCT forecaster to be significantly
  more reliable, based on past experience.
\end{quotex}

An instate corresponding to this situation may be $[0.3,0.6]$ (see
\scite{8}{walley91}{214}), but it will have a difficult time
representing the difference in reliability of the experts. We could
try $[0.2,0.8]$ (since the greater reliability of QCT suggests that
the chance of rain tomorrow is higher rather than lower) or
$[0.1,0.7]$ (since the greater reliability of QCT suggests that its
estimate is more precise), but it remains obscure what the criteria
might be.

A sharp credence of $P(R)=0.53$, for example, does the right thing.
Such a credence says nothing about any beliefs that the objective
chance is restricted to a subset of the unit interval, but it
accurately reflects the degree of uncertainty that the rational agent
has over the various possibilities. Beliefs about objective chances
make little sense in many situations where we have credences, since it
is doubtful even in the case of rain tomorrow that there is an urn of
nature from which balls are drawn. What is really at play is a complex
interaction between epistemic states (for example, experts evaluating
meteorological data) and the evidence which influences them.

A sharp credence is often associated with probability distributions
over chances, while an instate puts chances in sets where they all
have an equal voice. This may also be at the bottom of Susanna
Rinard's objection (see \scite{8}{white10}{184}) that Joyce's
committee members are all equally enfranchised and so it is not clear
how extremists among them could not always be replaced by even greater
extremists even after updating on evidence which should serve to
consolidate indeterminacy. Joyce has a satisfactory response to this
objection (see \scite{8}{joyce10}{291}), but I do not see how the
response addresses the problem of aggregating expert opinion without
the kind of summation that Laplaceans find unobjectionable, even
though information is lost and can only be recouped by going back to
the evidence. More generally, the two levels for sharp credences,
representation of uncertainty and distributions over partitions,
tidily differentiate between the {\doxnotep} and the evidential
dimension; instates, on the other hand, just add another level of
uncertainty on top of the uncertainty that is already expressed in the
partial belief and thus do not make the appropriate conceptual
distinctions.

As we will see in the next example, it is an advantage of sharp
credences that they do not exclude objective chances, even extreme
ones, because they are fully committed to partial belief and do not
suggest, as indeterminate credences do, that there is full belief
knowledge that the objective chance is a member of a proper subset of
the possibilities.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Precise
    Credences.} Your sharp credence for rain tomorrow, based on the
  expert opinion of channel GPY and channel QCT (you have no other
  information) is $0.53$. Is it reasonable, considering how little
  evidence you have, to reject the belief that the chance of rain
  tomorrow is $0.52$ or $0.54$; or to prefer a $52.9$ cent bet on rain
  to a $47.1$ cent bet on no rain?
\end{quotex}

The first question in example TBA\tbd{} is confused, but in
instructive ways (a display of this confusion is found in
\scite{8}{hajeksmithson12}{38f}, and their doctor and their time of
the day analogy). A sharp credence rejects no hypothesis about
objective chances (unlike an instate, unless (AC2) is firmly in place).
It often has a subjective probability distribution operating in the
background, over which it integrates to yield the sharp credence (it
would do likewise in H{\'a}jek and Smithson's example for the
prognosis of the doctor or the time of the day, without any problems).
This subjective probability distribution may look like this:

\begin{tabular}{|lcr|}
  \hline
  $P(\pi(R)=0.00)$ & = & $0.0001$ \\ \hline
  $P(\pi(R)=0.01)$ & = & $0.0003$ \\ \hline
  $P(\pi(R)=0.02)$ & = & $0.0007$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.30)$ & = & $0.0015$ \\ \hline
  $P(\pi(R)=0.31)$ & = & $0.0016$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.52)$ & = & $0.031$ \\ \hline
  $P(\pi(R)=0.53)$ & = & $0.032$ \\ \hline
  $P(\pi(R)=0.54)$ & = & $0.030$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
\end{tabular}

It is condensed by Lewis' summation formula to a sharp credence,
without being reduced to it:

\begin{equation}
  \label{eq:s2}
  C(R)=\int_{0}^{1}\zeta{}P(\pi(R)=\zeta)\,d\zeta\mbox{ }
\end{equation}

Lewis' 1981 paper \qeins{A Subjectivist's Guide to Objective Chance}
addresses the question what the relationship between $\pi$, $P$, and
$C$ is. The point is that we have properly separated the conceptual
dimensions and that the Laplacean approach is not a second order
probability approach. The partial belief epistemology deals with sharp
credences and how they represent uncertainty and serve as a tool in
inference, updating, and decision making; while Lewis' Humean
speculations and his interpretation of the principal principle cover
the relationship between subjective probabilities and objective
chance.

A sharp credence constrains partial beliefs in objective chances by
Lewis' summation formula (which we will provide in the next section).
No objective chance is excluded by it (principle of regularity) and
any updating will merely change the partial beliefs, but no full
beliefs. Instates, on the other hand, by giving ranges of acceptable
objective chances suggest that there is a full belief that the
objective chance does not lie outside what is indicated by the
instate. A Boolean can avoid this situation by accepting (AC2).

Here is a brief example to illustrate the difference between the
Laplacean theory of partial beliefs based on the principle of
regularity and the Boolean position which introduces an obscure grey
zone between partial beliefs and full belief, update and revision,
traditional epistemology and formal epistemology.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Bavarian
    King.} Matthias Perth, an Austrian civil servant, observes the
  Bavarian king at the Congress of Vienna in 1815 and writes in his
  diary that the king \qeins{appears to be a man between 45 and 47
    years old} (see \texttt{http://www.das-perth-projekt.at}).
\end{quotex}

If Perth learns that the king was 49 years old, he must revise, not
just update, his earlier judgment. The appropriate formal instrument
is belief revision, not probability update, requiring a substantial
reconciliation project between formal and traditional epistemology
operating in the background. I do not see this project articulated in
the Boolean literature (for an example of such a project see
\scite{7}{spohn12}{}, especially chapter 10). Sarah Moss also
undertakes it and assumes the Boolean approach (see
\scite{7}{moss13}{}), but I fail to see how the Boolean approach is
essential to her reconciliation or how her reconciliation gives
independent arguments for the Boolean approach. If Perth had wanted to
express a sharp credence, he would have said, \qeins{my best guess is
  that the king is 46 years old,} and the information that the king
was 49 would have triggered the appropriate update, without any
revision of full beliefs.

The burden for the Boolean is to show what kind of coherence there is
in defending indeterminacy when it neither fulfills the promise of
adequately representing evidence nor the promise of reconciling
traditional full belief \qnull{knowledge} epistemology and Bayesian
partial belief epistemology as outlined in the CGT, but only adds
another hierarchical layer of uncertainty to a numerical quantity (a
sharp credence) whose job it already is to represent
uncertainty.\bcut{14}

It is important not to confuse the claim that it is reasonable to hold
both $X$ and $Y$ with the claim that it is reasonable to hold either
$X$ (without $Y$) or $Y$ (without $X$). It is the reasonableness of
holding $X$ and $Y$ concurrently that is controversial, not the
reasonableness of holding $Y$ (without holding $X$) when it is
reasonable to hold $X$. It is a fallacy to think that $R_{S}(X)$ and
$R_{S}(Y)$ imply $R_{S}(X\wedge{}Y)$, when $R_{S}(Z)$ means \qeins{it
  is rational for $S$ to believe $Z$.} Consider the following
counter-example:

\begin{displaymath}
  \begin{array}{rl}
    R_{S}(X) & \mbox{It is rational for me to believe that} \\
        & \mbox{the tomato in front of me is orange.} \\
    R_{S}(Y) & \mbox{It is rational for me to believe that} \\
        & \mbox{the tomato in front of me is red.} \\
    \urcorner{}R_{S}(X\wedge{}Y) & \mbox{It is not rational for me to believe that} \\
        & \mbox{the tomato in front of me is red and orange.} \\
  \end{array}
\end{displaymath}

In a moment, I will talk about anti-luminosity, the fact that a
rational agent may not be able to distinguish psychologically between
a $54.9$ cent bet on an event and a $45.1$ bet on its negation, when
her sharp credence is $0.55$. She must reject one of them not to incur
sure loss, so proponents of indeterminacy suggest that she choose one
of them freely without being constrained by her credal state or reject
both of them. I claim that a sharp credence will make a recommendation
between the two so that only one of the bets is rational given her
particular credence, but that does not mean that another sharp
credence which would give a different recommendation may not also be
rational for her to have.

Instates, by contrast, mix evidential and doxastic features of a
credal state so that in the end we get a muddle where a superficial
reading of indeterminacy suddenly follows a converse principal
principle of sorts, namely that objective chances are constrained by
the factivity of a rational agent's credence when this credence is
knowledge (Lewis actually talks about such a converse, but in
completely different and epistemologically more intelligible terms,
see \scite{8}{lewis81}{289}). Sharp credences are more, not less,
permissive with respect to objective chances operating externally
(compared to the internal belief state of the agent, which the
credence reflects). By the principle of regularity and in keeping with
statistical practice, all objective chances as possible states of the
world are given positive subjective probabilities, even though they
may be very small. Instates, on the other hand, mix partial belief
epistemology with full belief epistemology and presumably exclude
objective chances which lie outside the credal state from
consideration because they are fully known not to hold (see
\scite{8}{levi81}{540}, \qeins{inference derives credal probability
  from knowledge of the chances of possible outcomes}).

The second question in example TBA\tbd{} is also instructive: why
would we prefer a $52.9$ cent bet on rain to a $47.1$ cent bet on no
rain, given that we do not possess the power of descrimination between
these two bets? The answer to this question ties in with the issue of
incomplete preference structure referred to above as motiviation (B)
for instates.

\begin{quotex}
  It hardly seems a requirement of rationality that belief be precise
  (and preferences complete); surely imprecise belief (and
  corresponding incomplete preferences) are at least rationally
  permissible. \scite{3}{bradleysteele13}{2}
\end{quotex}

The development of representation theorems beginning with Frank Ramsey
(followed by increasingly more compelling representation theorems in
\scite{7}{savage54}{}; and \scite{7}{jeffrey65}{}; and numerous other
variants in contemporary literature) puts the horse before the cart
and bases probability and utility functions of an agent on her
preferences, not the other way around. Once completeness as an axiom
for the preferences of an agent is jettisoned, indeterminacy follows
automatically. Indeterminacy may thus be a natural consequence of the
proper way to think about credences in terms of the preferences that
they represent.

In response, preferences may very well logically and psychologically
precede an agent's probability and utility functions, but that does
not mean that we cannot inform the axioms we use for a rational
agent's preferences by undesirable consequences downstream.
Completeness may sound like an unreasonable imposition at the outset,
but if incompleteness has unwelcome consequences for credences
downstream, it is not illegitimate to revisit the issue. Timothy
Williamson goes through this exercise with vague concepts, showing
that all upstream logical solutions to the problem fail and that it
has to be solved downstream with an epistemic solution (see
\scite{7}{williamson96}{}). Vague concepts, like sharp credences, are
sharply bounded, but not in a way that is luminous to the agent (for
anti-luminosity see chapter 4 in \scite{7}{williamson00}{}).
Anti-luminosity answers the original question: the rational agent
prefers the $52.9$ cent bet on rain to a $47.1$ cent bet on no rain
based on her sharp credence without being in a position to have this
preference necessarily or have it based on physical or psychological
ability (for the analogous claim about knowledge see
\scite{8}{williamson00}{95}).

In a way, advocates of indeterminacy have solved this problem for us.
There is strong agreement among most of them that the issue of
determinacy for credences is not an issue of elicitation (sometimes
the term \qnull{indeterminacy} is used instead of \qnull{imprecision}
to underline this difference; see \scite{8}{levi85}{395}). The appeal
of preferences is that we can elicit them more easily than assessments
of probability and utility functions. The indeterminacy issue has been
raised to the probability level (or moved downstream) by indeterminacy
advocates themselves who feel justifiably uncomfortable with an
interpretation of their theory in behaviourist terms. So it shall be
solved there, and this paper makes an appeal to reject indeterminacy
on this level. The solution then has to be carried upstream (or
lowered to the logically more basic level of preferences), where we
recognize that completeness for preferences is after all a desirable
axiom for rationality. Isaac Levi agrees with me on this point: when
he talks about indeterminacy, it proceeds from the level of
probability judgment to preferences, not the other way around (see
\scite{8}{levi81}{533}).

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1}
    Monkey-Filled Urns.} Let urn $A$ contain 4 balls, two red and two
  black. A monkey randomly fills urn $B$ from urn $A$ with two balls.
  We draw from urn $B$ (a precursor to this example is in
  \scite{8}{jaynesbretthorst03}{160}).
\end{quotex}

The sharp credence of drawing a red ball is $0.5$, following Lewis'
summation formula for the different combinations of balls in urn $B$.
This solution is more intuitive in terms of further inference,
decision making, and betting behaviour than a credal state of
$\{0,1/2,1\}$ or $[0,1]$ (depending on the convexity requirement),
since this instate would licence an exorbitant bet in favour of one
colour, for example one that costs \$9,999 and pays \$10,000 if red is
drawn and nothing if black is drawn.

To make this example more vivid consider a Hand Urn, where you draw by
hand from an urn with 100 balls, 50 red balls and 50 black balls. When
your hand retreats from the urn, does it not contain either a red ball
or a black ball and so serve itself as an urn, from which in a sense
you draw a ball? Your hand contains one ball, either red or black, and
the indeterminate credal state that it is one or the other should be
$[0,1]$. This contradicts our intuition that our credence should be a
sharp $0.5$. As is the case in Example TBA\tbd{white chocolate},
instates appear to be highly contingent on a problem's mode of
representation, more so than intuition allows.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Three
    Prisoners.} Prisoner $X_{1}$ knows that two out of three prisoners
  ($X_{1},X_{2},X_{3}$) will be executed and one of them pardoned. He
  asks the warden of the prison to tell him the name of another
  prisoner who will be executed, hoping to gain knowledge about his
  own fate. When the warden tells him that $X_{3}$ will be executed,
  $X_{1}$ erroneously updates his probability of pardon from $1/3$ to
  $1/2$, since either $X_{1}$ or $X_{2}$ will be spared.
\end{quotex}

Walley maintains that for the Monty Hall problem and the Three
Prisoners problem, the probabilities of a rational agent should dilate
rather than settle on the commonly accepted solutions. For the Three
Prisoners problem, there is a compelling case for standard
conditioning and the result that the credence for prisoner $X_{1}$ to
have been pardoned ought to be unchanged after the update (see
\scite{8}{lukits14}{1421f}). Walley's dilated solution would give
prisoner $X_{1}$ hope on the doubtful possibility (and unfounded
assumption) that the warden might prefer to provide $X_{3}$'s (rather
than $X_{2}$'s) name in case prisoner $X_{1}$ was pardoned.

This example brings an interesting issue to the forefront. Sharp
credences often reflect independence of variables where such
independence is unwarranted. Booleans (more specifically, detractors
of the principle of indifference or the principle of maximum entropy,
principles which are used to generate sharp credences for rational
agents) tend to point this out gleefully. They prefer to dilate over
the possible dependence relationships (independence included).
\textsc{dilation} is an instance of this. The fallacy in the argument
for instates, illustrated by the Three Prisoners problem, is that the
probabilistic independence of sharp credences does not imply
independence of variables. Only the converse is correct.

In the Three Prisoners problem, there is no evidence about the degree
or the direction of the dependence, and so prisoner $X_{1}$ should
take no comfort in the information that she receives. The prisoner's
probabilities will reflect probabilistic independence, but make no
claims about causal independence. Walley has unkind things to say
about sharp credences and their ability to respond to evidence (for
example that their \qeins{inferences rarely conform to evidence}, see
\scite{8}{walley91}{396}), but in this case it appears to me that they
outperform the Boolean approach.

\begin{quotex}
  \textbf{Example \arabic{expls}: \addtocounter{expls}{1} Wagner's
    Linguist.} A linguist hears the utterance of a native and
  concludes that the native cannot be part of certain population
  groups, depending on what the utterance means. The linguist is
  uncertain between some options about the meaning of the utterance.
  (For full details see \scite{8}{wagner92}{252}; and
  \scite{8}{spohn12}{197}.)
\end{quotex}

The mathematician Carl Wagner proposes a natural generalization of
Jeffrey Conditioning for his Linguist example (see
\scite{7}{wagner92}{}). Since the principle of maximum entropy is
already a generalization of Jeffrey Conditioning, the question
naturally arises whether the two generalizations agree. Wagner makes
the case that they do not agree and deduces that the principle of
maximum entropy is sometimes an inappropriate updating mechanism, in
line with many earlier criticisms of the principle of maximum entropy
(see van Fraassen,\fixref{7}{fraassen81}{} 1981;
\scite{7}{shimony85}{}; \scite{7}{skyrms87updating}{}; and, later on,
\scite{7}{grovehalpern97}{}). What is interesting about this case is
that Wagner uses instates for his deduction, so that even if you agree
with his natural generalization of Jeffrey Conditioning (which I find
plausible), the inconsistency with the principle of maximum entropy
can only be inferred assuming instates. Wagner is unaware of this, and
it can be shown that on the assumption of sharp credences Wagner's
generalization of Jeffrey conditioning accords with the principle of
maximum entropy (see \scite{7}{lukits15}{}).

This will not convince Booleans, since they are already unlikely to
believe in the general applicability of the principle of maximum
entropy (just as Wagner's argument is unlikely to convince a proponent
of the principle of maximum entropy, since they have a tendency to
reject instates). The battle lines are clearly drawn. Wagner's
argument, instead of undermining the principle of maximum entropy,
shows that instates are as wedded to rejecting the claims of the
principle of maximum entropy as the principle of maximum entropy is
wedded to sharp credences (these marriages are only unilaterally
monogamous, however, as it is perfectly coherent to reject both the
principle of maximum entropy and the Boolean position; or to reject
both the Laplacean position and instates).

Endorsement of instates, however, implies that there are situations of
probability update in which the posterior probability distribution is
more informative than it might be in terms of information theory.
Indeterminate credences violate the relatively natural intuition that
we should not gain information from evidence when a less informative
updated probability will do the job of responding to the evidence.
This is not a strong argument in favour of sharp credences. I consider
it to be much easier to convince someone to reject instates on
independent conceptual grounds than to convince them to reconsider the
principle of maximum entropy after its extensive criticism.

\section{Evidence Differentials and Cushioning Credences}
\label{WalleysWorldCupWoes}

I want to proceed to the intriguing issue of who does better in
betting situations: instates or sharp credences. I have given away the
answer already in the introduction: instates do better. It is
surprising that, except for a rudimentary allusion to this in Walley's
book, no Boolean has caught on to this yet. After I found out that
agents with instates do better betting on soccer games, I let Betsy
and Linda play a more basic betting game. An $n$-sided die is rolled
(by the computer). The die is fair, unbeknownst to the players. Their
bets are randomly and uniformly drawn from the simplex for which the
probabilities attributed to the $n$ results add up to 1. Betsy also
surrounds her credences with an imprecision uniformly drawn from the
interval $(0,y)$. I used Walley's pay off scheme (see
\scite{8}{walley91}{632}) to settle the bets.

Here is an example: let $n=2$, so the die is a fair \textit{coin}.
Betsy's and Linda's bets are randomly and uniformly drawn from the
line segment from $(0,1)$ to $(1,0)$ (these are two-dimensional
Cartesian coordinates), the two-dimensional simplex (for higher $n$,
the simplex is a pentatope generalized for $n$ dimensions with side
length $2^{1/2}$). The previsions (limits at which bets are accepted)
may be $(0.21,0.79)$ for Linda and $(0.35\pm{}0.11,0.65\pm{}0.11)$ for
Betsy, where the indeterminacy $\pm{}0.11$ is also randomly and
uniformly drawn from the imprecision interval $(0,y)\subseteq(0,1)$.
The first bet is on $H$, and Linda is willing to pay $22.5$ cents for
it, while Betsy is willing to pay $77.5$ cents against it. The second
bet is on $T$ (if $n>2$, there will not be the same symmetry as in the
\textit{coin} case between the two bets), for which Betsy is willing
to pay $77.5$ cents, and against which Linda is willing to pay $22.5$
cents. Each bet pays \$1 if successful. Often, Linda's credal state
will overlap with Betsy's sharp credence so that there will not be a
bet.\fcut{7}

The computer simulation clearly shows that Linda does better than
Betsy in the long run. A defence of sharp credences for rational
agents needs to have an explanation for this. We will call it partial
belief cushioning, which is based on an evidence differential between
the bettors.

In many decision-making contexts, we do not have the luxury of calling
off the bet. We have to decide one way or another. This is a problem
for instates, as Booleans have to find a way to decide without
receiving instructions from the credal state. Booleans have addressed
this point extensively (see for example \scite{8}{joyce10}{311ff}; for
an opponent's view of this see \scite{8}{elga10}{6ff}). The problem
for sharp credences arises when bets are noncompulsory, for then the
data above suggest that agents holding instates systematically do
better. Often, decision making happens as betting vis-{\`a}-vis
uninformed nature or opponents which are at least as uninformed as the
rational agent. Sometimes, however, bets are offered by better
informed or potentially better informed bookies. In this case, even an
agent with sharp credences must cushion her credences and is better
off by rejecting bets that look attractive in terms of her partial
beliefs.

If an agent does not cushion her partial beliefs (whether they are
sharp or indeterminate), she will incur a loss in the long run. Since
cushioning is permitted in Walley's experimental setup (the bets are
noncompulsory), Laplacean agents should also have access to it and
then no longer do worse than Boolean agents. One may ask what sharp
credences do if they just end up being cushioned anyway and do not
provide sufficient information to decide on rational bets. The answer
is that sharp credences are sufficient where betting (or decision
making more generally) is compulsory; the cushioning only supplies the
information from the evidence inasmuch as betting is noncompulsory and
so again properly distinguishes semantic categories. This task is much
harder for Booleans, although I do not claim that it is
insurmountable: instates can provide a coherent approach to compulsory
betting. What they cannot do, once cushioning is introduced, is
outperform sharp credences in noncompulsory betting situations.

Here are a few examples: even if I have little evidence on which to
base my opinion, someone may force me to either buy Coca Cola shares
or short them, and so I have to have a share price $p$ in mind that I
consider fair. I will buy Coca Cola shares for less than $p$, and
short them for more than $p$, if forced to do one or the other. This
does not mean that it is now reasonable for me to go (not forced by
anyone) and buy Coca Cola shares for $p$. It may not even be
reasonable to go (not forced by anyone) and buy Coca Cola share for
$p-\delta$ with $\delta{}>0$.

It may in fact be quite unreasonable, since there are many players who
have much better evidence than I do and will exploit my ignorance. I
suspect that most lay investors in the stock market make this mistake:
even though they buy and sell stock at prices that seem reasonable to
them, professional investors are much better and faster at exploiting
arbitrage opportunities and more subtle regularities. If indices rise,
lay investors will make a little less than their professional
counterparts; and when they fall, lay investors lose a lot more. In
sum, unless there is sustained growth and everybody wins, lay
investors lose in the long term.

A case in point is the U.S. Commodity Futures Trading Commission's
crackdown on the online prediction market Intrade. Intrade offered
fair bets for or against events of public significance, such as
election results or other events which had clear yes-or-no outcomes.
Even though the bets were all fair and Intrade only received a small
commission on all bets, and even though Intrade's predictions were
remarkably accurate, the potential for professional arbitrageurs was
too great and the CFTC shut Intrade down (see
\texttt{https://www.intrade.com}).

Cushioning does not stand in the way of holding a sharp credence, even
if the evidence is dim. The evidence determines for a rational agent
the partial beliefs over possible states of the world operating in the
background. The better the evidence, the more pointed the
distributions of these partial beliefs will be and the more willing
the rational agent will be to enter a bet, if betting is
noncompulsory. The mathematical decision rule will be based on the
underlying distribution of the partial beliefs, not only on the sharp
credence. As we have stated before, a sharp credence is not a
sufficient statistic for decision making, inference, or betting
behaviour; and neither is an instate.

The rational agent with a sharp credence has resources at her disposal
to use just as much differentiation with respect to accepting and
rejecting bets as the agent with instates. Often (if she is able to
and especially if the bets are offered to her by a better-informed
agent), she will reject both of two complementary bets, even when they
are fair. On the one hand, any advantage that the agent with an
instate has over her can be counteracted based on her distribution
over partial beliefs that she has with respect to all possibilities.
On the other hand, the agent with instates suffers under both
conceptual and practical problems that put her at a real disadvantage
in terms of understanding the sources and consequences of her
knowledge and her uncertainties.

\bibliographystyle{ChicagoReedweb} 
\bibliography{bib-7293}

\end{document} 
