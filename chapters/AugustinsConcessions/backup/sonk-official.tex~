% TBD: 

% (1) What exactly is player $X$'s evidence differential compared to
% player $Y$ -- the analytic expression may help.

% (2) Unfortunately, there are now corrections all over the files in
% 01-sonk-apa that need to be incorporated here. Many of the cuts would
% be beneficial as well. Spend some time to get this sorted out. You
% also need to run a diff between the introduction and synopsis.tex.

\documentclass[11pt]{article}
\usepackage{october}
% For BJPS
% \hyphenpenalty=10000
% \hbadness=10000

\begin{document}
% For BJPS
% \raggedright
% \doublespacing

\title{Semantics of Not Knowing}
\author{Stefan Lukits}
\date{}
\maketitle
% \doublespacing

% \begin{abstract} 
%   {\noindent}
% \end{abstract}

\section{Introduction}
\label{Introduction}

Traditional Bayesian epistemology used to include the
requirement for a rational agent to hold a sharp
credence function. It has recently become popular to
drop this requirement. There are now Bayesian theories
which permit a rational agent to hold indeterminate
credal states based on incomplete or ambiguous
evidence. I will refer to Bayesians who continue to
adhere to the classical theory of sharp credences for
rational agents as \qnull{Laplaceans} (e.g.\ Adam Elga
and Roger White). I will refer to Bayesians who do not
believe in the requirement for a rational agent to hold
sharp credences as \qnull{Booleans} (e.g.\ Peter Walley
and James Joyce; see Boole, 1854, chapters 16--21, for
alternative methods to the ones suggested by Laplace
which result in imprecise epistemic probabilities).

There is some terminological confusion around the
adjectives \qnull{imprecise,} \qnull{indeterminate,}
and \qnull{mushy} credences. In the following, I will
exclusively refer to indeterminate credences or credal
states and mean by them a credal state (a set of
credence functions, which some proponents of
indeterminacy require to be convex) which it may be
rational for an agent to hold within an otherwise
orthodox Bayesian framework. I will refer to Bayesians
who continue to adhere to the classical theory of sharp
credences for rational agents as \qnull{Laplaceans}
(e.g.\ Adam Elga and Roger White), while I will call
Bayesians who do not believe in the requirement for a
rational agent to hold sharp credences \qnull{Booleans}
(e.g.\ Peter Walley and James Joyce; see
\scite{7}{boole54}{}, chapters 16--21, for alternative
methods to the ones suggested by Laplace which resulted
in imprecise epistemic probabilities).

% This paper will examine two objections to
% indeterminacy, one by Adam Elga and one by Roger
% White, the former claiming that rational agents who
% use indeterminate credal states make themselves
% vulnerable to sure loss, and the latter that
% indeterminate credal states lead to unacceptable
% doxastic scenarios involving dilation. I will show
% how both of these objections fail (most of the work
% towards this end has already been done by Joyce, see
% \scite{7}{joyce10}{}; White's work, even though I
% think the objections fail as they stand, has a strong
% influence on my own objections).

After describing the appeal of indeterminacy and
showing how contemporary Laplacean objections fail, I
will point to more serious failings of indeterminacy in
semantic terms and show how a proper semantics of not
knowing, which we could also call a semantics of
partial belief, solves the problems for sharp credences
that Booleans address by introducing indeterminate
credal states. There is a sense in which, by linking
knowledge of chances to its reflection in credences,
Booleans seek to reconcile traditional knowledge
epistemology concerned with full belief and formal
epistemology concerned with partial belief. There are
other more recent reconciliation projects (see Spohn,
2012; and Moss, 2013), but if my paper is correct then
the Boolean approach will not contribute to this
reconciliation because it mixes full belief and partial
belief metaphors in ways that are semantically
problematic.

The underlying idea of my criticism is that sharp
credences run into a genuine conceptual crisis when
confronted with intuitions about betting behaviour,
completeness for preferences, and how reasonable it is
to demand precision from agents, even if they are
rational. Indeterminacy appears to provide an elegant
solution to overcome this crisis as well as a powerful
formal theory to continue what many find so compelling
about the Bayesian legacy. In the face of these
virtues, I maintain that indeterminacy adds an
unnecessary layer to the semantics of partial belief
which has in its wake counter-intuitive consequences
and solves nothing that cannot be solved by a carefully
articulated version of the classical Bayesian
commitment to sharp credences.

A sharp credence, as much as the term suggests
precision and a measure of certainty, is a
representation of an epistemic state chracterized by
uncertainty and lack of information. Importantly, it
does not represent the evidence which informs the
epistemic state, and it makes no claim of such a
representation. Indeterminate credal states are often
lauded as doing much better representing uncertainty
together with the evidence that constrains it, but they
can no more give an adequate representation of evidence
than sharp credences. This paper is concerned with the
semantic legitimacy of having a $0.5$ sharp credence in
heads for a coin of whose bias we are completely
ignorant; for a coin whose fairness is supported by a
lot of evidence; and even for a coin about whose bias
we know to be either 1/3 or 2/3 for heads.

One potential Boolean claim is that agents who use
indeterminate credal states do better than Laplaceans
when they bet on the truth of events for which they
have varying degrees of evidence. Peter Walley gives an
example where a Laplacean does much worse at predicting
Soccer World Cup games than Boolean peers who use upper
and lower previsions. Upper and lower previsions are
indeterminate credal states for which bets may either
be rejected or accepted if they fall within the margin
of indeterminacy. First, I will show on a much more
general level how Walley's claims are justified in
practice (bettors using upper and lower previsions do
better than bettors using linear previsions, i.e.\
sharp credences). Then I will explain why this is the
case, how a Laplacean can protect herself against this
disadvantage by drawing proper distinctions between
credence and evidence, and how indeterminacy emerges as
the loser when the contest is about clarity in one's
semantics. Again, the problem will be mixed metaphors:
the advocate of indeterminacy mixes semantic levels
that ought for good reasons to remain separate.
Indeterminacy imposes a double task on credences
(representing both uncertainty and available evidence)
that they cannot coherently fulfill.

I will present several examples where this double task
stretches indeterminate credal states to the limits of
plausibility, for example when they need to aggregate
expert opinion or account for dilation. Joyce's idea
that credences can represent balance, weight, and
specificity of the evidence is inconsistent with the
use of indeterminacy (and Joyce himself, in response to
the dilation problem, gives the argument why this is
the case). The implicit Boolean claim that certain
properties of the evidence (its ambiguity, its
completeness, conflicts within it) can be recovered
from indeterminate credal states is inconsistent with
an effective Boolean answer to the dilation problem.

The Laplacean approach of assigning subjective
probabilities to partitions of the event space (e.g.\
objective chances) and then aggregating them by David
Lewis' summation formula into a single precise
credence function is semantically tidy and shares many
of the formal virtues of Boolean theories. If the bad
taste about numerical precision in our fuzzy, nebulous
world lingers, I can point to philosophical projects in
other domains where the concepts we use are sharply
bounded, even though our ability to conceive of those
sharp boundaries or know them is limited, for example
Timothy Williamson's work on vagueness and knowledge as
a mental state.

\section{Motivation for Indeterminate Credal States}
\label{MotivationForIndeterminateCredal States}

We want to motivate indeterminacy for the credences of
a rational agent, independent of how they are elicited,
as forcefully as possible so that the reader will see
(a) the appeal of such indeterminacy, (b) the
insufficiency of the critical response, and (c) the
need for careful articulation of the Laplacean approach
that mandates a rational agent to hold sharp credences
together with an explanation of how this careful
articulation addresses the concerns which motivate some
to resort to indeterminacy.

When textual criticism compares variant readings of
ancient texts in order to recover the most probable
reading of the original, it follows a well-accepted
rule not to accept the easiest reading, i.e.\ the one
that flows most naturally with the surrounding text,
but the (often more difficult) reading which best
explains the variants in the manuscripts. A similar
dynamic is at work here: motivating indeterminacy will
make clear that acceptance of indeterminacy is the
easiest reading and on the surface best responds to
intuitions we have about the credences of a rational
agent. We will address, however, the ways in which
indeterminacy itself violates intuitions, especially
those for semantic clarity and simplicity (the latter
viewed in terms of reducing hierarchical nesting of
uncertainty versus tidily separating the evidential and
epistemic dimension of partial beliefs). The Laplacean
approach, which does not permit indeterminacy, explains
why this is the case and, despite being the more
difficult reading, ultimately yields a more integrated
package that accords better with our intuitions and
requirements for a coherent formal and semantic theory.

Our conclusion is that a rational agent is best off in
terms of her own goals when she entertains sharp
credences with respect to propositions about events
that come her way. Whether this is advisable for human
or machine intelligence is a different kettle of fish.
My topic is the logic of partial beliefs, and I readily
admit that such a logic may be computationally
intractable or, given finite resources, be an
irrational way of keeping track of beliefs.

% TBD: Condense Ellsberg for APA
Despite this disclaimer, we begin with an example that
motivates indeterminate credal states based on human
betting behaviour. It is nonetheless forceful. For the
Ellsberg paradox (see \scite{8}{ellsberg61}{650ff}),
you have two urns, both containing 100 red and black
balls. Urn I contains an unknown ratio of the two
colours, whereas the ratio for Urn II is 50:50. In
experiments, subjects usually prefer to bet on
Red$_{II}$ rather than Red$_{I}$ and Black$_{II}$
rather than Black$_{I}$. If these preferences stem from
sharp subjective probabilities, then

\begin{equation}
  \label{eq:s1}
  1=P(R_{II})+P(B_{II})>P(R_{I})+P(B_{I})=1
\end{equation}

leads to a violation of probability axioms by reductio.
A slight variation shows that such preferences also
violate L.J. Savage's Sure Thing principle, without the
possibly doubtful numerical mapping from preferences to
subjective probabilities (see
\scite{8}{ellsberg61}{653f}). The intuition behind the
Ellsberg paradox remains a strong motivation for
indeterminate credal states, often expressed in terms
of biased coins.

Let a \textsc{coin} be a Bernoulli generator that
produces successes and failures with probability $p$
for success, labeled $H$, and $1-p$ for failure,
labeled $T$. Physical coins may serve as examples if we
are willing to set aside that most of them are
approximately fair. Imagine three \textsc{coin}s for
which we have evidence that \textsc{coin}$_{I}$ is
fair, \textsc{coin}$_{II}$ has an unknown bias, and
\textsc{coin}$_{III}$ has as bias either $p=1/3$ or
$p=2/3$. The Laplacean approach permits a sharp $0.5$
credence in $H$ for a rational agent in all three
cases. A Boolean approach wants to see the difference
in the evidential situation reflected in a rational
agent's credal state and for example at least permit,
as credence in $H$, $\{x|x=0.5\}$ for
\textsc{coin}$_{I}$, $\{x|0\leq{}x\leq{}1\}$ for
\textsc{coin}$_{II}$, and $\{x|1/3\leq{}x\leq{}2/3\}$
or $\{1/3,2/3\}$ for \textsc{coin}$_{III}$. Here is a
list of reasons for the Boolean position.

Here are a few concise statements by Booleans:

\begin{quotex}
  [A] refusal to make a determinate probability
  judgment does not derive from a lack of clarity about
  one's credal state. To the contrary, it may derive
  from a very clear and cool judgment that on the basis
  of the available evidence, making a numerically
  determinate judgment would be unwarranted and
  arbitrary. \scite{3}{levi85}{395}
\end{quotex}

\begin{quotex}
  If there is little evidence concerning [a claim,]
  then beliefs about [that claim] should be
  indeterminate, and probability models imprecise, to
  reflect the lack of information. We regard this as
  the most important source of imprecision.
  \scite{3}{walley91}{212--213}
\end{quotex}

\begin{quotex}
  Imprecise probabilities and related concepts
  [{\ldots}] provide a powerful language which is able
  to reflect the partial nature of the knowledge
  suitably and to express the amount of ambiguity
  adequately. \scite{3}{augustin03}{34}
\end{quotex}

\begin{quotex}
  As sophisticated Bayesians like Isaac Levi (1980),
  Richard Jeffrey (1983), Mark Kaplan (1996), have long
  recognized, the proper response to symmetrically
  ambiguous or incomplete evidence is not to assign
  probabilities symmetrically, but to refrain from
  assigning precise probabilities at all.
  Indefiniteness in the evidence is reflected not in
  the values of any single credence function, but in
  the spread of values across the family of all
  credence functions that the evidence does not
  exclude. This is why modern Bayesians represent
  credal states using sets of credence functions. It is
  not just that sharp degrees of belief are
  psychologically unrealistic (though they are).
  Imprecise credences have a clear epistemological
  motivation: they are the proper response to
  unspecific evidence. \scite{3}{joyce05}{170f}
\end{quotex}

\begin{quotex}
  Precise degrees of belief are the wrong response to
  the sorts of evidence that we typically receive
  [{\ldots}] since the data we receive is often
  incomplete, imprecise or equivocal, the epistemically
  right response is often to have opinions that are
  similarly incomplete, imprecise or equivocal.
  \scite{3}{joyce10}{283}
\end{quotex}

In summary, here is a list of reasons why credal states
for ideally rational agents do not need to be
representable by single probability measures relative
to the appropriate corpora of knowledge, as Rudolf
Carnap and E.T. Jaynes require (see
\scite{8}{levi81}{533}).

\begin{enumerate}[(A)]
\item The greatest emphasis motivating indeterminacy
  rests on lack of evidence or conflicting evidence and
  the assumption that single probability measures
  (sharp credences) do not represent such evidence as
  well as credal states composed by sets of probability
  measures (indeterminate credal states).
\item The preference structure of a rational agent may
  be incomplete so that representation theorems do not
  yield single probability measures to represent such
  incomplete structures.
\item There are more technical and paper-specific
  reasons, such as Thomas Augustin's attempt to mediate
  between the minimax pessimism of objectivists and the
  Bayesian optimism of subjectivists using interval
  probability (see \scite{8}{augustin03}{35f}); Alan
  H{\'a}jek and Michael Smithson's belief that there
  may be objectively indeterminate chances in the
  physical world (see \scite{8}{hajeksmithson12}{33});
  and Jake Chandler's claim that \qeins{the sharp model
    is at odds with a trio of plausible propositions
    regarding agnosticism} \scite{2}{chandler14}{4}.
\end{enumerate}

This paper mostly addresses (A), while taking (B)
seriously as well and pointing towards solutions for
it. I am leaving (C) to more specific responses to the
issues presented in the cited articles, and for the
remainder of this section I am adding a reason (D) that
is poorly documented in the literature.

One motivation for permitting a rational agent to have
a range of probability measures rather than mandating
her to hold a single one as her credence is that she
would do better making decisions and accepting
advantageous bets. Even though advocates of
indeterminate credal states seldom raise this issue, I
find it worth pursuing. Before we do this, it is
necessary to make brief reference to the variety of
versions which accommodate indeterminacy as we have
sketched it: upper and lower probabilities, choquet
capacities, belief and possibility functions, coherent
lower previsions, sets of probability measures, partial
preference orderings, and sets of desirable gambles
(the list is from \scite{8}{walley00}{126}). The
proliferation of versions, however, is neither a
problem in principle as the debate is vigorous and
useful which of them best captures requirements for
rationality, nor in practice because the versions agree
on large parts of the terrain (see
\scite{8}{levi85}{390}; and \scite{8}{walley91}{50f}).

For our purposes here, we accept Peter Walley's theory
of upper and lower previsions, which is motivated by
coherence on the one hand and avoidance of sure losses
on the other hand (see Walley's 1991 book
\emph{Statistical Reasoning with Imprecise
  Probabilities}). Upper and lower previsions have a
behavioural interpretation as maximum buying prices and
minimum selling prices for gambles where two bets can
both be rejected if they offer a reward of \$1 for a
price of $x$ in case of $H$ and a reward of \$1 for a
price of $1-x$ in case of $T$ as long as $x$ falls
between the upper and lower prevision.

In the \textsc{coin}$_{II}$ example, if the agent's
lower prevision is $1/3$ and the upper prevision $2/3$,
she would accept a bet paying \$1 if $H$ (or $T$) for
thirty cents and reject such a bet for seventy cents,
but if the price of the bet is between one and two
thirds of a dollar it would be rational for her to
either accept or reject the bet. Walley conducted an
experiment with 17 participants, who had various levels
of understanding Bayesian theory, asking them for upper
and lower probabilities entering into bets about the
games played in the Soccer World Cup 1982 in Spain. One
of the participants, a \qeins{dogmatic Bayesian
  lecturer} (see \scite{8}{walley91}{633}), only used
single sharp subjective probabilities, while the others
used intervals. The dogmatic Bayesian lecturer finished
a distant last when the bets were evaluated. Walley
admits that this result may have been due to the
lecturer's eccentric assessments (for the game between
the Soviet Union and Brazil, for example, his
distribution between a Win, a Draw, and a Loss was
10-80-10).

I was curious what a more rigorous treatment of the
comparison between linear previsions (when upper and
lower previsions coincide) and interval previsions
would yield. I equipped two computer players with some
rudimentary artificial intelligence and made them
specify previsions for games played in the Soccer World
Cup 2014 in Brazil, ordering player $X$ to specify
linear previsions and player $Y$ to specify upper and
lower previsions (acknowledgements to open source
software making this possible and making it
inexpensive, especially emacs lisp, perl, R statistics,
and octave). I used the Poisson distribution (which is
an excellent predictor for the outcome of soccer
matches) and the FIFA ranking to simulate millions of
counterfactual World Cup results and their associated
bets, using Walley's evaluation method.

Player $Y$ had a slight but systematic advantage. Her
expected gain for a whole tournament was approximately
\$2 (very little compared to the stakes, as one can see
by considering the standard deviation of approximately
\$46 for this expected gain, i.e. 67\% of player $Y$'s
overall gain from a tournament was between -\$44 and
+\$48). The surprising fact that she did consistently
better than player $X$ remains in need of explanation.
In section \ref{WalleysWorldCupWoes}, I will provide an
explanation and show how it can support rejecting
indeterminate credal states for rational agents,
counter-intuitive as that may sound.

\section{Arbitrage Opportunities and Dilation}
\label{ArbitrageOpportunitiesAndDilation}

From a collection of arguments against indeterminacy I
draw on two that sound particularly compelling and that
in the final analysis fail. One by Adam Elga (see
\scite{7}{elga10}{}) charges indeterminacy with making
a rational agent vulnerable to sure loss and ends in
the statement: \qeins{Perfectly rational agents always
  have perfectly sharp probabilities}
\scite{2}{elga10}{1}.

The other by Roger White (see \scite{7}{white10}{}) is
initially more semantically minded with an analysis of
the Chance Grounding Thesis (CGT), of which I will also
make use in my criticism of indeterminacy. For the
remainder of White's paper, however, the focus moves to
dilation, which according to White saddles the
indeterminacy approach with unacceptable
counter-intuitive results. Joyce has reponded in favour
of indeterminacy both to Elga and to White and in my
view has successfully defended his position.

For Elga, the issue is that while it is rational for an
agent with an upper and lower provision to reject both
an $x$ bet for $H$ (shorthand for \qnull{receiving \$1
  if $H$ is true for the price of $x$}) and a $1-x$ bet
against $H$ (or, equivalently, for $T$), if $x$ is
between the two previsions; it should also be rational
to accept both bets if they are an $x+\delta$ bet for
$H$ and a $1-x+\delta$ bet for $T$, where $\delta$ is
chosen small enough to keep the prices of the bets
within the previsions. These bets will lead to a sure
loss and an arbitrage opportunity for bookies against
our supposedly rational agent.

There is no reason to reinvent the wheel here: both
Jake Chandler and Joyce address Elga's objection, and
while Chandler's defence of indeterminacy against Elga
does not persuade me (see \scite{8}{chandler14}{10}),
Joyce's defence does (see \scite{8}{joyce10}{314}).
Similarly, for White's objection, I am satisfied with
Joyce's response. Joyce deals with White's objection in
detail in his 2010 paper (for a concise summary see
\scite{8}{bradleysteele13}{13}). As opposed to Elga's
objection, White's objection has far-reaching semantic
implications. I will look at it more closely since my
criticism is largely semantic in nature and draws on
Joyce's semantic response to White.

You have two Bernoulli Generators, \textsc{coin}$_{a}$
and \textsc{coin}$_{b}$. You have good evidence that
\textsc{coin}$_{a}$ is fair and no evidence about the
bias of \textsc{coin}$_{b}$. Furthermore, the two
generators are not necessarily independent. Their
results could be 100\% correlated or anticorrelated,
they may be independent or the correlation could be
anywhere between the two extremes. You toss
\textsc{coin}$_{a}$. Without looking at the result,
your credence in $H$ is a sharp $0.5$, even if you are
open to indeterminate credal states, because you have
good evidence for the fairness of \textsc{coin}$_{a}$.
Then you toss \textsc{coin}$_{b}$. This time you look
at the result and the moment you learn it, your
credence in $H$ for \textsc{coin}$_{a}$ dilates from a
sharp $0.5$ to the vacuous credal state covering the
whole interval $[0,1]$ (provided that this was your
credence in $H$ for \textsc{coin}$_{b}$, as
stipulated). Even though you have just received
information (the result of \textsc{coin}$_{b}$'s toss),
your credence in $H$ for \textsc{coin}$_{a}$ dilates.
Usually, we would expect more information to sharpen
our credal states (see Walley's \qeins{the more
  information the more precision} principle and his
response to this problem in \scite{8}{walley91}{207 and
  299}).

White did not discover the phenomenon of dilation
(besides Walley's comments cited in previous the
paragraph see also the detailed study in
\scite{7}{seidenfeldwasserman93}{}), but he was able to
find examples where the consequences appear grotesque,
especially in his bonbon case (see
\scite{8}{white10}{183}).

\begin{quotex}
  Having noodled about this puzzle on and off for some
  time, I discovered that the general phenomenon of
  dilation is old news. Some statisticians and
  philosophers have studied how the phenomenon arises
  in other cases and appear to have taken it in their
  stride. This is not a reductio but a result, they
  might say. I want to suggest that the present case
  brings out particularly forcefully how bizarre this
  phenomenon is, at least in the present case where we
  are assuming evidential symmetry between $p$ and
  not-$p$. \scite{3}{white10}{177}
\end{quotex}

White's claim is also that dilation contradicts Bas van
Fraassen's reflection principle (see
\scite{7}{vanfraassen84}{}). 

Joyce's response uses two lines of defence: the results
are not counter-intuitive upon closer inspection and
Lewis' indadmissibility criterion as well as two
significant semantic concessions to White show why the
indeterminate credal states give us the right result.
This response is intriguing in several ways. It
articulates just the right response to White: yes,
dilation is what you would expect (1) if credences do
not represent evidence (the same indeterminate credal
state can reflect different evidential situations); and
(2) if the CGT is not a necessary consequence of the
indeterminacy approach.

Based on Joyce's amendments to the Boolean approach
(and his own version of it in \scite{7}{joyce05}{}), I
agree with Joyce in White's own words that White's
dilation problem \qeins{is not a reductio but a result}
\scite{3}{white10}{177}. The possible dependence
between \textsc{coin}$_{a}$ and \textsc{coin}$_{b}$ and
the unknown bias of \textsc{coin}$_{b}$ dilate our
credences in the result of tossing \textsc{coin}$_{a}$.

\addtocounter{expls}{1}

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} Dilating Urns} You draw
  from an urn with 200 balls (100 red, 100 black) and
  receive the information that the urn actually had two
  chambers, one with 99 red balls and 1 black ball, the
  other with 1 red ball and 99 black balls.
\end{quotex}

Your credence would dilate, given this additional piece
of information, from a sharp $0.5$ to an indeterminate
$[0.01,0.99]$ without much mystery (the indeterminate
credence would licence an unreasonable 99:1 bet, but
that is part of the semantic criticism below).

The problem with dilation is a problem that proponents
of indeterminacy have created for themselves, but they
also have the resources to extract themselves from it,
albeit only at the cost of opening up semantic issues
which turn the case against them. 

A sharp credence, on the one hand, constrains partial
beliefs in objective chances by Lewis' summation
formula (which we will provide in the next section). No
objective chance is excluded by it and any updating
will merely change the partial beliefs, but no full
beliefs. Indeterminate credal states, on the other
hand, by giving ranges of acceptable objective chances
suggest that there is a full belief that the objective
chance does not lie outside what is indicated by the
indeterminate credal state.

If one were to be committed to the principle of
regularity, that all states of the world considered
possible have positive probability (for a defence see
\scite{7}{edwardsetal63}{}); and to the solution of
Henry Kyburg's lottery paradox, that what is rationally
accepted should have probability 1 (for a defence of
this principle see \scite{7}{douvenwilliamson06}{});
and the CGT, that one's spread of credence should cover
the range of possible chance hypotheses left open by
evidence; then one's indeterminate credal state must
always be vacuous. Booleans must deny at least one of
the premises to avoid the conclusion. Joyce denies the
CGT, but then he continues to make implicit use of it
when he repeatedly complains that sharp credences
\qeins{ignore a vast number of possibilities that are
  consistent with [the] evidence} (for example in
\scite{2}{joyce05}{170}).

When updating dilates the credal state, it appears that
the prior credal state was in some sense incorrect and
did not properly reflect the state of the world, even
though it properly reflected the epistemic state of the
agent. Such a divergence between the proper reflections
of epistemic state and state of the world undermines
the subjective interpretation of probabilities at the
heart of Bayesian epistemology. Credences are not
knowledge claims about the world, but represent
uncertainty in the agent's epistemic state. Yet an
indeterminate credal state blurs the line between the
two (for two rigorous attempts to reconcile traditional
full belief epistemology and formal partial belief
epistemology (for semantically more intelligible
attempts at reconciliation between the two see
\scite{7}{moss13}{}, although Moss is committed to the
Boolean approach, which may weaken her case; and
\scite{7}{spohn12}{}, especially chapter 10).

Matthias Perth, an Austrian civil servant, observes the
Bavarian king at the Congress of Vienna and writes in
his diary that the king \qeins{appears to be a man
  between 45 and 47 years old} (see
\texttt{http://www.das-perth-projekt.at}). If Perth
then learns that the king was 49 years old, he must
revise, not just update, his earlier judgment. The
appropriate formal instrument is belief revision, not
probability update, and whoever wants to use it leaves
what Levi calls the ample bosom of Mother Bayes (see
\scite{8}{levi85}{392}), unless there is a substantial
reconciliation project between formal and traditional
epistemology operating in the background, which I do
not see in the literature defending indeterminacy. If
Perth had wanted to express a sharp credence, he would
have said, \qeins{my best guess is that the king is 46
  years old,} and the information that the king was 49
would have triggered the appropriate update, without
any revision of full beliefs.

White's objection fails because dilation for
indeterminate credences is in principle not any more
surprising than a piece of information that increases
the Shannon entropy of a sharp credence. It is true for
both sharp and indeterminate credences that information
can make us less certain about things. Once Booleans
have brought their house in order to accommodate
White's objection, however, they open wide the door on
semantic problems. We finally get to inquire what kind
of coherence there is in defending indeterminacy when
it neither fulfills the promise of representing
evidence nor the promise of reconciling traditional
full belief \qnull{knowledge} epistemology and Bayesian
partial belief epistemology as outlined in the CGT, but
only adds another hierarchical layer of uncertainty to
a numerical quantity (a sharp credence) whose job it
already is to represent uncertainty, thus unnecessarily
introducing regress problems. We will turn to these
semantic considerations now, show how they display the
virtues of sharp credences in responding to the
forceful motivations for indeterminate credal states
while making those indeterminate credal states look
semantically otiose. Then we will show in the last
section how sharp credences have an elegant solution
for being outperformed by indeterminate credal states
in betting scenarios, and there we will rest our case.

\section{Semantics of Partial Belief}
\label{SemanticsOfPartialBelief}

At the heart of my project is a proper semantic
distinction between evidence, information, and partial
belief. Both sharp credences and indeterminate credal
states, within a Bayesian framework, try to represent
the uncertainty of an agent with respect to the truth
of a proposition. Indeterminate credal states have a
greater ambition: they also claim to represent
properties of the evidence, such as its weight,
conflict between its constituents, or its ambiguity.

Indeterminate credal states are suggestive of a
measurement that wants to represent numerically the
mass of an object and then also make claims about its
density. With sharp credences, the semantic roles of
evidence, information, and uncertainty are
appropriately differentiated. Rational decision-making,
inference, and betting behaviour are based on sharp
credences together with the evidence that is at its
foundation. Information represents evidence, and sharp
credences represent uncertainty. Measurement is in any
case a misleading analogy for credences. Measurements
are always imprecise. Epistemic credences, however, are
not measurements, especially not of objective chances.
They represent uncertainty. They are more like logical
truth values than they are like measurements.
\scite{8}{levi85}{407}, makes this category mistake,
whereas \scite{8}{walley91}{249} is clear on the
difference.

It is a slippery affair to determine what evidence is,
which I will leave to others. My claim is that a
rational agent is someone who can distill information
from evidence which places numerically precise
constraints on relatively prior probability
distributions, which then can be updated to form
posterior probability distributions and the credences
associated with them. Note that relatively prior
probability distributions are not ignorance priors or
non-informative priors, which I would call absolutely
prior probability distributions. I have no answers
where absolutely prior probability distributions come
from, how they are justified, or in what sense they are
objective. I am not concerned whether all rational
agents, if they have the same evidence, should arrive
at the same credal states; or even if they should all
update a given relatively prior credal state to the
same posterior credal state, if they have the same
evidence. Sometimes there may be different ways to
translate or interpret evidence into information.

It is important not to confuse the claim that it is
reasonable to hold both $X$ and $Y$ with the claim that
it is reasonable to hold either $X$ (without $Y$) or
$Y$ (without $X$). It is the reasonableness of holding
$X$ and $Y$ concurrently that is controversial, not the
reasonableness of holding $Y$ (without holding $X$)
when it is reasonable to hold $X$. We will later talk
about anti-luminosity, the fact that a rational agent
may not be able to distinguish psychologically between
a 54.9 cent bet on an event and a 45.1 bet on its
negation. She must reject one of them not to incur sure
loss, so proponents of indeterminacy suggest that she
choose one of them freely without being constrained by
her credal state or reject both of them. I claim that a
sharp credence will make a recommendation between the
two so that only one of the bets is rational given her
particular credence, but that does not mean that
another sharp credence which would give a different
recommendation may not also be rational for her to
have.

I am sympathetic to the viewpoint that once a rational
agent has a relatively prior credal state and has
formalized her evidence in terms of information, then
the probability distributions forming her posterior
credal state should be unique. Joyce, with his
\qnull{committee member} approach, shows how this kind
of updating can be done for indeterminate credal states
(see \scite{8}{joyce10}{288}; also
\scite{8}{bradleysteele13}{6}).

If you are willing to follow me so far (assuming the
Bayesian core commitments of credal states as
representing the epistemic state of the agent in terms
of subjective probabilities, which are updated using
standard conditioning where it can be applied), there
are two approaches you can take towards the
indeterminacy question, both of them involving two
levels. On the one hand, you can have partial beliefs
about how a parameter is distributed and then use
Lewis' summation formula (see \scite{8}{lewis81}{266f})
to integrate over them and condense them to a sharp
credence. Walley comments on this \qeins{reduction} in
his section on Bayesian second order probabilities (see
\scite{8}{walley91}{258f}), but he mistakenly
represents the Laplacean approach as a second order
approach, as if the probability distributions that are
summarized by Lewis' formula are of the same kind as
the resulting credences. They are not. They are
objective chances or other partitions of the event
space and the subjective probabilities that are
associated with them. It is the Boolean approach which
has elements of a second order approach and thus makes
itself vulnerable to regress problems by adding another
dimension of uncertainty to a parameter (the credence)
which already represents uncertainty.

On the other hand, you can try to represent your
uncertainty about the distribution of the parameter by
an indeterminate credal state. I want to show that the
first approach can be aligned with the forceful
motivations we listed in the previous section to
introduce indeterminate credal states, as long as we do
not require that a sharp credence represent the
evidence as well as the epistemic state of uncertainty
in the agent. We have learned that this requirement can
be reduced ad absurdum even for indeterminate credal
states.

One of Joyce's complaints is that a sharp credence of
$0.5$ for a \textsc{coin} contains too much information
if there is little or no evidence that the
\textsc{coin} is fair. This complaint, of course, is
only effective if we make a credence say something
about the evidence. Joyce himself, however, admits that
indeterminate credal states cannot represent the
evidence without violating the reflection principle due
to White's dilation problem. He is quite clear that the
same indeterminate credal state can represent different
evidential scenarios (see, for example,
\scite{8}{joyce10}{302}).

In any case, Walley's and Joyce's claim that
indeterminate credal states are less informative than
sharp credences has no foundation in information theory
(see \scite{8}{walley91}{34}; and
\scite{8}{joyce10}{311} for examples, but this attitude
is passim). To compare indeterminate credal states and
sharp credences informationally, we would need a
non-additive set function obeying Shannon's axioms for
information. This is a non-trivial task. I have not
succeeded solving it, but I am not at all convinced
that it will result in an information measure which
assigns more information to a sharp credence such as
$\{0.5\}$ than to an indeterminate credal state such as
$\{x|1/3\leq{}x\leq{}2/3\}$ for a binomial random
variable.

Augustin recognizes the problem of inadequate
representation long before Joyce, with specific
reference to indeterminate credal states: \qeins{The
  imprecise posterior does no longer contain all the
  relevant information to produce optimal decisions.
  Inference and decision do not coincide any more}
\scite{2}{augustin03}{41} (see also an example for
inadequate representation of evidence by indeterminate
credal states in \scite{8}{bradleysteele13}{16}).
Indeterminate credal states fare no better than sharp
credences, except perhaps for the problem that they
unhelpfully mimic saying something about the evidence
that is much better said elsewhere.

Not only can we align sharp credences with the
motivations to introduce indeterminate credal states,
we can also show that indeterminate credal states
perform worse semantically because they mix evidential
and epistemic metaphors in deleterious ways. Sharp
credences have one task: to represent epistemic
uncertainty and serve as a tool for updating,
inference, and decision-making. They cannot fulfill
this task without continued reference to the evidence
which operates in the background. To use an analogy,
credences are not sufficient statistics with respect to
updating, inference, and decision-making. What is
remarkable about Joyce's response to White's dilation
problem is that Joyce recognizes that indeterminate
credal states are not sufficient statistics either. But
this means that they fail at the double task which has
been imposed on them: to represent both epistemic
uncertainty and the evidence.

In the following, I will provide a few examples where
it becomes clear that indeterminate credal states have
difficulty representing uncertainty because they are
tangled in a double task which they cannot fulfill.

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} Aggregating Expert Opinion}
  You have no information whether it will rain tomorrow
  ($R$) or not except the predictions of two weather
  forecasters. One of them forecasts 0.3 on channel
  GPY, the other 0.6 on channel QCT. You consider the
  QCT forecaster to be significantly more reliable,
  based on past experience.
\end{quotex}

An indeterminate credal state corresponding to this
situation may be $[0.3,0.6]$ (see
\scite{8}{walley91}{214}), but it will have a difficult
time representing the difference in reliability of the
experts. A sharp credence of $P(R)=0.55$, for example,
does the right thing. Such a credence says nothing
about any beliefs that the objective chance of $R$ is
$x\in{}I$ or restricted to $X\subseteq{}I$ (where $I$
is the unit interval), but it accurately reflects the
degree of uncertainty that the rational agent has over
the various possibilities. Beliefs about objective
chances make little sense in many situations where we
have credences, since it is doubtful even in the case
of rain tomorrow that there is an urn of nature from
which balls are drawn. What is really at play is a
complex interaction between epistemic states (for
example, experts evaluating meteorological data) and
the evidence which influences them.

A sharp credence is usually associated with
distributions over chances, while an indeterminate
credal state puts chances in sets where they all have
an equal voice. This may also be at the bottom of
Susanna Rinard's objection (see
\scite{8}{white10}{184}) that Joyce's committee members
are all equally enfranchised and so it is not clear how
extremists among them could not always be replaced by
even greater extremists even after updating on evidence
which should serve to consolidate indeterminacy. Joyce
has a satisfactory response to this objection (see
\scite{8}{joyce10}{291}), but I do not see how the
response addresses the problem of aggregating expert
opinion without the kind of summation that Laplaceans
find unobjectionable, even though information is lost
and can only be recouped by going back to the evidence.
More generally, the two levels for sharp credences,
representation of uncertainty and distributions over
partitions, tidily differentiate between the epistemic
and the evidential dimension; indeterminate credal
states, on the other hand, just add another level of
uncertainty on top of the uncertainty that is already
expressed in the partial belief and thus do not make
the appropriate semantic distinctions.

As we will see in the next example, it is an advantage
of sharp credences that they do not exclude objective
chances, even extreme ones, because they are fully
committed to partial belief and do not suggest, as
indeterminate credences do, that there is full belief
knowledge that the objective chance is a member of a
proper subset of the possibilities.

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} How Precise Can a Rational
    Agent Reasonably Be} Your sharp credence for rain
  tomorrow, based on the expert opinion of channel GPY
  and channel QCT (you have no other information) is
  $0.55$. Is it reasonable, considering how little
  evidence you have, to reject the belief that the
  chance of rain tomorrow is $0.54$ or $0.56$; or to
  prefer a 54.9 cent bet on rain to a 45.1 cent bet on
  no rain?
\end{quotex}

The first question, of course, is confused, but in
instructive ways (a display of this confusion is found
in \scite{8}{hajeksmithson12}{38f}, and their doctor
and time of the day analogy). A sharp credence rejects
no hypothesis about objective chances (unlike an
indeterminate credal state). It often has a subjective
probability distribution operating in the background,
over which it integrates to yield the sharp credence
(it would do likewise in H{\'a}jek and Smithson's
example for the prognosis of the doctor or the time of
the day, without any problems). This subjective
probability distribution may look like this:

\begin{tabular}{|lcr|}
  \hline
  $P(\pi(R)=0.00)$ & = & $0.0001$ \\ \hline
  $P(\pi(R)=0.01)$ & = & $0.0003$ \\ \hline
  $P(\pi(R)=0.02)$ & = & $0.0007$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.30)$ & = & $0.0015$ \\ \hline
  $P(\pi(R)=0.31)$ & = & $0.0016$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
  $P(\pi(R)=0.54)$ & = & $0.031$ \\ \hline
  $P(\pi(R)=0.55)$ & = & $0.032$ \\ \hline
  $P(\pi(R)=0.56)$ & = & $0.054$ \\ \hline
  $\ldots$ & & $\ldots$ \\ \hline
\end{tabular}

It is condensed by Lewis' summation formula to a sharp
credence, without being reduced to it:

\begin{equation}
  \label{eq:s2}
  P(R)=\int_{0}^{1}\zeta{}P(\pi(R)=\zeta)\,d\zeta
\end{equation}

There are more semantic questions here: what is
$\pi(R)$, the objective chance that it rains tomorrow,
and how do we get to use $P(\pi(R)=\zeta)$ in our
calculation of $P(R)$ without begging the question.
Lewis' 1981 paper \qeins{A Subjectivist's Guide to
  Objective Chance} remains the gold standard in
addressing these questions, and I will no longer pursue
them here. The point is that we have properly separated
the semantic dimensions and that the Laplacean approach
is not a second order probability approach. The partial
belief epistemology deals with sharp credences and how
they represent uncertainty and serve as a tool in
inference, updating, and decision making; while Lewis'
Humean speculations and his interpretation of the
principal principle cover the relationship between
subjective probabilities and objective chance.

Indeterminate credal states, by contrast, mix these
semantic dimensions so that in the end we get a muddle
where a superficial reading of indeterminacy suddenly
follows a converse principal principle of sorts, namely
that objective chances are constrained by the factivity
of a rational agent's credence when this credence is
knowledge (Lewis actually talks about such a converse,
but in completely different and epistemologically more
intelligible terms, see \scite{8}{lewis81}{289}). Sharp
credences are more, not less, permissive with respect
to objective chances operating externally (compared to
the internal epistemic state of the agent, which the
credence reflects). By the principle of regularity and
in keeping with statistical practice, all objective
chances as possible states of the world are given
positive subjective probabilities, even though they may
be very small. Indeterminate credal states, on the
other hand, mix partial belief epistemology with full
belief epistemology and presumably exclude objective
chances which lie outside the credal state from
consideration because they are fully known not to hold
(see \scite{8}{levi81}{540}, \qeins{inference derives
  credal probability from knowledge of the chances of
  possible outcomes}).

The second question is also instructive: why would we
prefer a 54.9 cent bet on rain to a 45.1 cent bet on no
rain, given that we do not possess the power of
descrimination between these two bets? The answer to
this question ties in with the issue of incomplete
preference structure referenced above as motiviation
(B) for indeterminate credal states.

\begin{quotex}
  It hardly seems a requirement of rationality that
  belief be precise (and preferences complete); surely
  imprecise belief (and corresponding incomplete
  preferences) are at least rationally permissible.
  \scite{3}{bradleysteele13}{2}
\end{quotex}

In personal communication, Yang Liu at Columbia
University posed this problem to me more forcefully:
the development of representation theorems beginning
with Frank Ramsey (followed by increasingly more
compelling representation theorems in
\scite{7}{savage54}{}; and \scite{7}{jeffrey65}{}; and
numerous other variants in contemporary literature)
puts the horse before the cart and bases probability
and utility functions of an agent on her preferences,
not the other way around. Once completeness as an axiom
for the preferences of an agent is jettisoned,
indeterminacy follows automatically. Indeterminacy may
thus be a natural consequence of the proper way to
think about credences in terms of the preferences that
underlie them.

In response, preferences may very well logically and
psychologically precede an agent's probability and
utility functions, but that does not mean that we
cannot inform the axioms we use for a rational agent's
preferences by undesirable consequences downstream.
Completeness may sound like an unreasonable imposition
at the outset, but if incompleteness has unwelcome
semantic consequences for credences, it is not
illegitimate to revisit the issue. Timothy Williamson
goes through this exercise with vague concepts, showing
that all upstream logical solutions to the problem fail
and that it has to be solved downstream with an
epistemic solution (see \scite{7}{williamson96}{}).
Vague concepts, like sharp credences, are sharply
bounded, but not in a way that is luminous to the agent
(for anti-luminosity see chapter 4 in
\scite{7}{williamson00}{}). Anti-luminosity answers the
original question: the rational agent prefers the 54.9
cent bet on rain to a 45.1 cent bet on no rain based on
her sharp credence without being in a position to have
this preference necessarily or have it based on
physical or psychological ability (for the analogous
claim about knowledge see \scite{8}{williamson00}{95}).

In a way, advocates of indeterminacy have solved this
problem for us. There is strong agreement among most of
them that the issue of determinacy for credences is not
an issue of elicitation (sometimes the term
\qnull{indeterminacy} is used instead of
\qnull{imprecision} to underline this difference; see
\scite{8}{levi85}{395}, but also Walley and Joyce
passim, even though Walley prefers to use the term
\qnull{imprecision,} strongly in the sense, however,
that they are not an elicitation issue). 

The appeal of preferences is 
that we can elicit them more easily than assessments of
probability and utility functions. The indeterminacy
issue has been raised to the probability level (or
moved downstream) by indeterminacy advocates themselves
who feel justifiably uncomfortable with an
interpretation of their theory in behaviourist terms.
So it shall be solved there, and this paper makes an
appeal to reject indeterminacy on this level. The
solution then has to be carried upstream (or lowered to
the logically more basic level of preferences), where
we recognize that completeness for preferences is after
all a desirable axiom for rationality. Ironically,
Isaac Levi seems to agree with me on this point: when
he talks about indeterminacy, it proceeds from the
level of probability judgment to preferences, not the
other way around (see \scite{8}{levi81}{533}).

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} Jaynes' Monkeys} E.T.
  Jaynes describes an experiment with monkeys filling
  an urn randomly with balls from another urn, for
  which sampling provides no information and so makes
  updating vacuous (see
  \scite{8}{jaynesbretthorst03}{160}). Here is a
  variant of this experiment for which a sharp credence
  provides a more compelling result than the associated
  indeterminate credal state: Let urn $A$ contain 4
  balls, two red and two black. A monkey randomly fills
  urn $B$ from urn $A$ with two balls. We draw from urn
  $B$.
\end{quotex}

The sharp credence of drawing a red ball is $0.5$,
following Lewis' summation formula for the different
combinations of balls in urn $B$. I find this solution
more intuitive in terms of further inference, decision
making, and betting behaviour than a credal state of
$\{0,1/2,1\}$, since this indeterminate credal state
would licence an exorbitant bet in favour of one
colour, for example one that costs \$9,999 and pays
\$10,000 if red is drawn and nothing if black is drawn.

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} Three Prisoners} Prisoner
  $X_{1}$ knows that two out of three prisoners
  ($X_{1},X_{2},X_{3}$) will be executed and one of
  them pardoned. He asks the warden of the prison to
  tell him the name of another prisoner who will be
  executed, hoping to gain knowledge about his own
  fate. When the warden tells him that $X_{3}$ will be
  executed, $X_{1}$ erroneously updates his probability
  of pardon from $1/3$ to $1/2$, since either $X_{1}$
  or $X_{2}$ will be spared.
\end{quotex}

Peter Walley maintains that for the Monty Hall problem
and the Three Prisoners problem, the probabilities of a
rational agent should dilate rather than settle on the
commonly accepted solutions. Consider the three
prisoners problem. There is a compelling case for
standard conditioning and the result that the chances
of pardon for prisoner $X_{1}$ are unchanged after the
update (see \scite{8}{lukits14}{1421f}). Walley's
dilated solution would give prisoner $X_{1}$ hope on
the doubtful possibility (and unfounded assumption)
that the warden might prefer to provide $X_{3}$'s name
in case prisoner $X_{1}$ was pardoned.

This example brings an interesting issue to the
forefront. Sharp credences often reflect independence
of variables where such independence is unwarranted.
Booleans (more specifically, detractors of the
principle of indifference or the principle of maximum
entropy, principles which are used to generate sharp
credences for rational agents) tend to point this out
gleefully. They prefer to dilate over the possible
dependence relationships (independence included).
White's dilation problem is an instance of this. The
fallacy in the argument for indeterminate credal
states, illustrated by the three prisoners problem, is
that the probabilistic independence of sharp credences
does not imply independence of variables (the converse
is correct), but only that it is unknown whether there
is dependence, and if yes, whether it is correlation or
inverse correlation.

The fallacy is that it is illegitimate to conclude from
probabilistic independence to causal independence, even
though the converse conclusion is legitimate. In the
Three Prisoners problem, there is no evidence about the
degree or the direction of the dependence, and so
prisoner $X_{1}$ should take no comfort in the
information that he receives. The prisoner's
probabilities will reflect probabilistic independence,
but make no claims about causal independence. Walley
has terribly unkind things to say about sharp credences
and their ability to respond to evidence (for example
that their \qeins{inferences rarely conform to
  evidence}, see \scite{8}{walley91}{396}), but in this
case it appears to me that they outperform the
indeterminate approach.

\begin{quotex}
  \textbf{Example \arabic{expls}:
    \addtocounter{expls}{1} Wagner's Linguist} A
  linguist hears the utterance of a native and
  concludes that the native cannot be part of certain
  population groups, depending on what the utterance
  means. The linguist is uncertain between some options
  about the meaning of the utterance. (For full details
  see \scite{8}{wagner92}{252}; and
  \scite{8}{spohn12}{197}.)
\end{quotex}

The mathematician Carl Wagner proposed a natural
generalization of Jeffrey Conditioning for his Linguist
example (see \scite{7}{wagner92}{}). Since the
principle of maximum entropy is already a
generalization of Jeffrey Conditioning, the question
naturally arises whether the two generalizations agree.
Wagner makes the case that they do not agree and
deduces that the principle of maximum entropy is
sometimes an inappropriate updating mechanism, in line
with many earlier criticisms of the principle of
maximum entropy (see \scite{7}{fraassen81}{};
\scite{7}{shimony85}{}; \scite{7}{skyrms87updating}{};
and, later on, \scite{7}{grovehalpern97}{}). What is
interesting about this case is that Wagner uses
indeterminate credal states for his deduction, so that
even if you agree with his natural generalization of
Jeffrey Conditioning (which I find plausible), the
inconsistency with the principle of maximum entropy can
only be inferred assuming indeterminate credal states.
Wagner is unaware of this, and I am showing in another
paper (in process) how on the assumption of sharp
credences Wagner's generalization of Jeffrey
conditioning perfectly accords with the principle of
maximum entropy.

This will not convince a proponent of indeterminate
credences, since they are already unlikely to believe
in the general applicability of the principle of
maximum entropy (just as Wagner's argument is unlikely
to convince a proponent of the principle of maximum
entropy, since they are more likely to reject
indeterminate credal states). The battle lines are
clearly drawn. Wagner's argument, instead of
undermining the principle of maximum entropy, just
shows that indeterminate credal states are as wedded to
rejecting the claims of the principle of maximum
entropy as the principle of maximum entropy is wedded
to sharp credences.

Endorsement of indeterminate credal states, however,
implies that there are situations of probability update
in which the posterior probability distribution is more
informative than it might be in terms of informative
theory. Indeterminate credences violate the relatively
natural intuition that we should not gain information
from evidence when a less informative updated
probability will do the job of responding to the
evidence. This is not a strong argument in favour of
sharp credences. The principle of maximum of entropy
has received a thorough bashing in the last thirty
years. I consider it to be much easier to convince
someone to reject indeterminate credal states on
independent (semantic) grounds than to convince them to
give the principle of maximum entropy a second chance.
But the section on semantics comes to an end here, and
we want to proceed to the intriguing issue of who does
better in betting situations: indeterminate credal
states or sharp credences.

\section{Evidence Differentials and Cushioning
  Credences}
\label{WalleysWorldCupWoes}

I have given away the answer already in the
introduction: indeterminate credal states do better. It
is surprising that, except for a rudimentary allusion
to this in Walley's book, no Boolean has caught on to
this yet. After I found out that agents with
indeterminate credal states do better betting on soccer
games, I let player $X$ (who uses sharp credences) and
player $Y$ (who uses indeterminate credal states) play
a more basic betting game. An $n$-sided die is rolled
(by the computer). The die is fair, unbeknownst to the
players. Their bets are randomly and uniformly drawn
from the simplex for which the probabilities attributed
to the $n$ results add up to 1. Player $Y$ also
surrounds her credences with an imprecision uniformly
drawn from the interval $(0,y)$. I used Walley's pay
off scheme (see \scite{8}{walley91}{632}) to settle the
bets.

Here is an example: let $n=2$, so the die is a fair
\textsc{coin}. $X$'s and $Y$'s bets are randomly and
uniformly drawn from the line segment from $(0,1)$ to
$(1,0)$ (these are two-dimensional Cartesian
coordinates), the two-dimensional simplex (for higher
$n$, the simplex is a pentatope generalized for $n$
dimensions with side length $2^{1/2}$). The bets may be
$(0.21,0.79)$ for player $X$ and
$(0.35\pm{}0.11,0.65\pm{}0.11)$ for player $Y$, where
the indeterminacy $\pm{}0.11$ is also randomly and
uniformly drawn from the imprecision interval
$(0,y)\subseteq(0,1)$. The first bet is on $H$, and
player $Y$ is willing to pay $22.5$ cents for it, while
$X$ is willing to pay $77.5$ cents against it. The
second bet is on $T$ (if $n>2$, there will not be the
same symmetry as in the \textsc{coin} case between the
two bets), for which player $X$ is willing to pay
$77.5$ cents, and against which player $Y$ is willing
to pay $22.5$ cents. Each bet pays \$1 if successful.
Often, $Y$'s credal state will overlap with $X$'s sharp
credence so that there will not be a bet.

Here is a table of the results. Each result is based on
100,000 die rolls. The second column shows the mean
gain for player $X$, the third column shows the
standard deviation, the fourth column shows the
percentage of bets which are called off. The table is
for $y=1$.

\begin{tabular}{|l|r|r|r|}
  \hline
  $n=2$ & 0.14 & 18.8 & 25.2 \\ \hline
  $n=3$ & -1.67 & 13.7 & 39.1 \\ \hline
  $n=4$ & -1.73 & 10.4 & 48.1 \\ \hline
  $n=5$ & -1.39 & 8.2 & 54.5 \\ \hline
  $n=6$ & -1.22 & 6.6 & 59.1 \\ \hline
  $n=7$ & -1.01 & 5.5 & 62.8 \\ \hline
\end{tabular}

Here are the results for a player $Y$ who is not as
generous with indeterminacy, $y=0.3$ (note that fewer
bets are called off).

\begin{tabular}{|l|r|r|r|}
  \hline
  $n=2$ & 5.82 & 28.0 & 0.0 \\ \hline
  $n=3$ & -0.55 & 21.8 & 0.0 \\ \hline
  $n=4$ & -2.32 & 17.0 & 0.0 \\ \hline
  $n=5$ & -2.89 & 13.7 & 0.4 \\ \hline
  $n=6$ & -2.74 & 11.3 & 1.4 \\ \hline
  $n=7$ & -2.52 & 9.6 & 3.2 \\ \hline
\end{tabular}

We should get similar results if we do this
analytically instead of using computer simulation. I
will pursue this further for the final version of the
paper. The math is not complicated, but unwieldy. The
following expression yields the expected gain for
player $X$:

\begin{eqnarray}
  \label{eq:s3}
  EX =
  \frac{p_{x}}{n}\left(\sum_{j=0}^{n-1}\int_{0}^{1}\int_{0}^{x}\int_{0}^{x-y}\sum_{k=0}^{n-1}g(x,y,s,k,j)\,ds\,d\upsilon(y)\,d\xi(x)\right)+
  \notag \\
  \frac{p_{y}}{n}\left(\sum_{j=0}^{n-1}\int_{0}^{1}\int_{0}^{1}\int_{0}^{y-s}\sum_{k=0}^{n-1}g(x,y,s,k,j)\,d\xi(x)\,d\upsilon(y)\,ds\right)
\end{eqnarray}

where $p_{x}$ and $p_{y}$ are the respective
probabilities that $X$ and $Y$ win a bet and $g$ is
$X$'s gain given $X$'s credence $x$ and $Y$'s credal
state $y\pm{}s$ on roll $j$, given result $k$. $\xi(x)$
and $\upsilon(y)$ are the distributions of the
credences given our method of simplex point picking
(for these distributions, one must use the
Cayley-Menger Determinant to find out the volume of
generalized pentatopes involved). The computer
simulation clearly shows that except for $n=2$, the
\textsc{coin} toss, player $Y$ does better. A defence
of sharp credences for rational agents needs to have an
explanation for this. We will call it partial belief
cushioning, which is based on an evidence differential
between the bettors.

In many decision-making context, we do not have the
luxury of calling off the bet. We have to decide one
way or another. This is a problem for indeterminate
credal states, as Booleans have to find a way to decide
without receiving clear instructions from the credal
state. Booleans have addressed this point extensively
(see for example \scite{8}{joyce10}{311ff}; for an
opponent's view of this see \scite{8}{elga10}{6ff}).
The problem for sharp credences arises when bets are
noncompulsory, for then the data above suggest that
agents holding indeterminate credal states do better.
Often, decision-making happens as betting
vis-{\`a}-vis uninformed nature or opponents which are
at least as uninformed as the rational agent.
Sometimes, however, bets are offered by better informed
or potentially better informed bookies. In this case,
even an agent with sharp credences must cushion her
credences and is better off by rejecting bets that look
attractive in terms of her partial beliefs. If an agent
does not cushion her partial beliefs (whether they are
sharp or indeterminate), she will incur a loss in the
long run. Since cushioning is permitted in Walley's
experimental setup, Laplacean agents should also have
access to it and then no longer do worse than Boolean
agents.

Here are a few examples: even if I have little evidence
on which to base my opinion, someone may force me to
either buy Coca Cola shares or short them, and so I
have to have a share price $p$ in mind that I consider
fair. I will buy Coca Cola shares for less than $p$,
and short them for more than $p$, if forced to do one
or the other. This does not mean that it is now
reasonable for me to go (not forced by anyone) and buy
Coca Cola shares for $p$. It may not even be reasonable
to go (not forced by anyone) and buy Coca Cola share
for $p-\delta$ with $\delta{}>0$.

It may in fact be quite unreasonable, since there are
many players who have much better evidence than I do
and will exploit my ignorance. I suspect that most lay
investors in the stock market make this mistake: even
though they buy and sell stock at prices that seem
reasonable to them, professional investors are much
better and faster at exploiting arbitrage opportunities
and more subtle regularities. If indices rise, lay
investors will make a little less than their
professional counterparts; and when they fall, lay
investors lose a lot more. In sum, unless there is
sustained growth and everybody wins, lay investors lose
in the long term.

A case in point is the U.S. Commodity Futures Trading
Commission's crackdown on the online prediction market
Intrade. Intrade offered fair bets for or against
events of public significance, such as election results
or other political events which had clear yes-or-no
outcomes. Even though the bets were all fair and
Intrade only received a small commission on all bets,
and even though Intrade's predictions were remarkably
accurate, the potential for professional arbitrageurs
was too great and the CFTC shut Intrade down (see
\texttt{https://www.intrade.com}).

Cushioning does not stand in the way of holding a sharp
credence, even if the evidence is dim. The evidence
determines for a rational agent the partial beliefs
over possible states of the world operating in the
background. The better the evidence, the more pointed
the distributions of these partial beliefs will be and
the more willing the rational agent will be to enter a
bet. The mathematical decision rule will be based on
the underlying distribution of the partial beliefs, not
only on the sharp credence. As we have stated before,
the sharp credence is not a sufficient statistic for
decision-making, inference, or betting behaviour; and
neither is an indeterminate credal state. If a rational
agent perceives an evidence differential and lends some
belief to the proposition that the bet is offered by
someone who has more evidence about the outcome of an
event than she does, then it is likely that the
rational agent will update her sharp credence, as she
would do if she were informed of another source of
expert opinion. She will certainly not be willing to
enter a bet based on her outdated sharp credence.

The rational agent with a sharp credence has resources
at her disposal to use just as much differentiation
with respect to accepting and rejecting bets as the
agent with indeterminate credal states. Often (if she
is able to and especially if the bets are offered to
her by a better-informed agent), she will reject both
of two complementary bets, even when they are fair. On
the one hand, any advantage that the agent with an
indeterminate credal state has over her can be
counteracted based on her distribution over partial
beliefs that she has with respect to all possibilities.
On the other hand, the agent with indeterminate credal
states suffers from a semantic mixing of metaphors
between evidential and epistemic dimensions that puts
her at a real disadvantage in terms of understanding
the sources and consequences of her knowledge and her
uncertainties.

\section{References}
\label{References}

% \nocite{*} 
\bibliographystyle{ChicagoReedweb} 
\bibliography{bib-7293}

\end{document} 
