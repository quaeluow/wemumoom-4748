% This is the official version. Use it for the dissertation. For
% publication, however, consider the cuts made in sonk-bjps.tex.

\documentclass[11pt]{article}
\usepackage{october}
\usepackage{lineno}
% \newcommand{\plebeian}[0]{\textsc{anderson}}
% \newcommand{\aristocratic}[0]{\textsc{augustin}}
\newcommand{\anderson}[0]{\textit{Bool-A}}
\newcommand{\augustin}[0]{\textit{Bool-B}}
% For BJPS
% \hyphenpenalty=10000
% \hbadness=10000

\begin{document}
\setpagewiselinenumbers
\modulolinenumbers[5]
\linenumbers
% For BJPS
% \raggedright
% \doublespacing

\title{Augustin's Concessions: A Problem for Indeterminate Credal States}
\author{Stefan Lukits}
\date{}
\maketitle

\begin{abstract} 
  {\noindent}Many Bayesian epistemologists now accept that it is not
  necessary for a rational agent to hold sharp credences. There are
  various compelling formal theories how such a non-traditional view
  of credences can accommodate decision making and updating. They are
  motivated by a common complaint: that sharp credences can fail to
  represent incomplete evidence and exaggerate the information
  contained in it. Indeterminate credal states, the alternative to
  sharp credences, face challenges as well: they are vulnerable to
  dilation and under certain conditions do not permit learning. This
  paper focuses on two concessions that Thomas Augustin and James
  Joyce make to address these challenges. The concessions undermine
  the original case for indeterminate credal states. I use both
  conceptual arguments and hands-on examples to argue that rational
  agents always have sharp credences.
\end{abstract}

\section{Introduction}
\label{Introduction}

The claim defended in this paper is that rational agents are subject
to a norm requiring sharp credences. I defend this claim in spite of
the initially promising features of indeterminate credal states to
address problems which sharp credences have as they reflect a doxastic
state.
% \tbd{You may want to add arguments addressing Belot and
%   Weatherson's orgulity claims.}

Traditionally, Bayesians have maintained that a rational agent, when
holding a credence, holds a sharp credence. It has recently become
popular to drop the requirement for credence functions to be sharp.
There are now Bayesians who permit a rational agent to hold
indeterminate credal states based on incomplete or ambiguous evidence.
I will refer to Bayesians who continue to adhere to the classical
theory of sharp credences for rational agents as \qnull{Laplaceans}
(e.g.\ Adam Elga and Roger White). I will refer to Bayesians who do
not believe that a rational agent's credences need to be sharp as
\qnull{Booleans} (e.g.\ Richard Jeffrey, Peter Walley, Brian
Weatherson, and James Joyce).\fcut{1}

There is some terminological confusion around the adjectives
\qnull{imprecise,} \qnull{indeterminate,} and \qnull{mushy} credences.
In the following, I will exclusively refer to indeterminate credences
or credal states (abbreviated \qnull{instates}) and mean by them a set
of sharp credence functions (which some Booleans require to be convex)
which it may be rational for an agent to hold within an otherwise
orthodox Bayesian framework (see \scite{7}{jeffrey83}{}).\bcut{1} 

More formally speaking, let $\Omega$ be a set of state descriptions or
possible worlds and $\mathcal{X}$ a suitable algebra on $\Omega$. Then
$X\in\mathcal{X}$ is a proposition toward which an agent entertains a
credal state $C(X)$. $C$ is a function
$C:\mathcal{X}\rightarrow\mathcal{R}$, where $\mathcal{R}$ is an
algebra on $\mathbb{R}^{+}_{0}$, in some cases required to be convex.
The credal state is potentially different from an agent's doxastic
state, which could be characterized in more detail than the credal
state (examples will follow). Laplaceans require that
$\mathcal{R}\subseteq\{\{x\}|x\in\mathbb{R}^{+}_{0}\}$. Indeterminate
alternatives are that $\mathcal{R}$ is a set of Borel sets or a set of
convex Borel sets. Since both Laplaceans and Booleans are Bayesians,
the elements of $\mathcal{R}$ will not contain numbers greater than
one.

In this paper,\lcut{1} I will introduce a \emph{divide et impera}
argument in favour of the Laplacean position. I assume that the appeal
of the Boolean position is immediately obvious. Not only is it
psychologically implausible that agents who strive for rationality
should have all their credences worked out to crystal-clear precision;
it seems epistemically doubtful to assign exact credences to
propositions about which the agent has little or no information,
incomplete or ambiguous evidence (Joyce calls the requirement for
sharp credences \qeins{psychologically implausible and
  epistemologically calamitous,} see \scite{8}{joyce05}{156}). From
the perspective of information theory, it appears that an agent with
sharp credences pretends to be in possession of information that she
does not have.

The \emph{divide et impera} argument runs like this: I show that the
Boolean position is really divided into two mutually incompatible
camps, {\anderson} and {\augustin}. 
% {\anderson} is named after my high-school age son who defends this
% position despite repeated attempts to dissuade him; {\augustin} is
% named after the philosopher who together with Joyce makes Augustin's
% concessions.
{\anderson} has the advantage of owning all the assets of appeal
against the Laplacean position. The stock examples brought to bear
against sharp credences have simple and compelling instate solutions
given {\anderson}. {\anderson}, however, has deep conceptual problems
which I will describe in detail below.

{\augustin}'s refinement of {\anderson} is successful in so far as it
resolves the conceptual problems. Their success depends on what I call
Augustin's concessions, which undermine all the appeal that the
Boolean position as a whole has over the Laplacean position. With a
series of examples, I seek to demonstrate that in Simpson Paradox type
fashion the Laplacean position looks genuinely inferior to the
amalgamated Boolean position, but as soon as the mutually incompatible
strands of the Boolean position have been identified, the Laplacean
position is independently superior to both.

\section{Partial Beliefs}
\label{amalgamated}

Bayesians, whether Booleans or Laplaceans, agree that full belief
epistemology gives us an incomplete account of rationality and the
epistemic landscape of the human mind. Full belief epistemology is
concerned with the acceptance and the rejection of full beliefs,
whether an agent may be in possession of knowledge about their
contents and what may justify or constitute this knowledge. Bayesians
engage in a complementary project investigating partial beliefs. There
are belief contents toward which a rational agent has a belief-like
attitude characterized by degrees of confidence. These partial beliefs
are especially useful in decision theory (for example, betting
scenarios). Bayesians have developed a logic of partial beliefs, not
dissimilar to traditional logic, which justifies certain partial
beliefs in the light of other partial beliefs.\lcut{4}

Some epistemologists now seek to reconcile full and partial belief
epistemology (see \scite{7}{spohn12}{}; \scite{7}{weatherson12}{}; and
\scite{7}{moss13}{}). There is a sense in which, by linking knowledge
of chances to its representation in credences, Booleans also seek to
reconcile traditional knowledge epistemology concerned with full
belief and Bayesian epistemology concerned with partial belief. If my
paper is correct then the Boolean approach will not contribute to this
reconciliation because it mixes full belief and partial belief
metaphors in ways that are problematic.\fcut{2}\bcut{2}\mcut{1} The
primary task of Bayesians is to explain what partial beliefs are, how
they work, and what the norms of rationality are that govern them. The
problem for Booleans, as we will see, is that only {\anderson} has an
explanation at hand how partial beliefs model the epistemic state of
the agent
% (to speak in Brian Weatherson's terms, see \scite{8}{weatherson12}{19}) 
in tandem with the way full beliefs do their modeling: as we will see
by example, {\anderson} often looks at partial beliefs as full beliefs
about objective chances. {\augustin} debunks this approach, which
leaves the project of reconciliation unresolved.

For the remainder of this section, I want to give the reader a flavour
of how appealing the amalgamated version of Booleanism is (the view
that a rational agent is permitted to entertain credal states that
lack the precision of sharp credences) and then draw the distinction
between {\anderson} and {\augustin}. Many recently published papers
confess allegiance to allowing instates without much awareness of
Augustin's and Joyce's refinements in what I call {\augustin} (for
examples see \scite{7}{kaplan10}{}; \scite{7}{hajeksmithson12}{};
\scite{7}{moss13}{}; \scite{7}{chandler14}{}; and
\scite{7}{weisberg15}{}). The superiority of the Boolean approach over
the Laplacean approach is usually packaged as the superiority of the
amalgamated Boolean version, even when the advantages almost
exclusively belong to {\anderson}. Advocates of {\augustin}, when they
defend instates against the Laplacean position, often relapse into
{\anderson}-type argumentation, as we will see in examples in a
moment.

When\lcut{2} we first hear of the advantages of instates, three of
them sound particularly persuasive.

\begin{itemize}
\item \textsc{intern} Instates represent the possibility range for
  objective chances (objective chances internal to the instate are not
  believed not to hold, objective chances external to the instate are
  believed not to hold).
\item \textsc{incomp} Instates represent incompleteness or
  ambiguity of the evidence.\bcut{3}
\item \textsc{inform} Instates are responsive to the information
  content of evidence.\bcut{3}
\end{itemize}

Here are some examples and explanations. Let a
\textit{coin}$_{\mbox{\tiny{x}}}$ be a Bernoulli generator that
produces successes and failures with probability $p_{\mbox{\tiny{x}}}$
for success, labeled $H_{\mbox{\tiny{x}}}$, and
$1-p_{\mbox{\tiny{x}}}$ for failure, labeled $T_{\mbox{\tiny{x}}}$.
Physical coins may serve as Bernoulli generators, if we are willing to
set aside that most of them are approximately fair.

\begin{quotex}
  \beispiel{INTERN}\label{ex:range} Blake has two Bernoulli generators in
  her lab, \textit{coin}$_{\mbox{\tiny{i}}}$ and
  \textit{coin}$_{\mbox{\tiny{ii}}}$. Blake has a database of
  \textit{coin}$_{\mbox{\tiny{i}}}$ results and concludes on excellent
  evidence that \textit{coin}$_{\mbox{\tiny{i}}}$ is fair. Blake has no
  evidence about the bias of \textit{coin}$_{\mbox{\tiny{ii}}}$. As a
  Boolean, Blake assumes a sharp credence of $\{0.5\}$ for
  $H_{\mbox{\tiny{i}}}$ and an indeterminate credal state of $[0,1]$
  for $H_{\mbox{\tiny{ii}}}$. She feels bad for Logan, her Laplacean
  colleague, who cannot distinguish between the two cases and who must
  assign a sharp credence of $\{0.5\}$ to both $H_{\mbox{\tiny{i}}}$
  and $H_{\mbox{\tiny{ii}}}$.
\end{quotex}

\begin{quotex}
  \beispiel{INCOMP}\label{ex:incomp} Blake has another Bernoulli
  generator, \textit{coin}$_{\mbox{\tiny{iii}}}$, in her lab. Her
  graduate student has submitted \textit{coin}$_{\mbox{\tiny{iii}}}$
  to countless experiments and emails Blake the resulting bias, but
  fails to include whether the bias of $2/3$ is in favour of
  $H_{\mbox{\tiny{iii}}}$ or in favour of $T_{\mbox{\tiny{iii}}}$. As
  a Boolean, Blake assumes an indeterminate credal state of
  $[1/3,2/3]$ (or $\{1/3,2/3\}$, depending on the convexity
  requirement) for $H_{\mbox{\tiny{iii}}}$. She feels bad for Logan
  who must assign a sharp credence of $\{0.5\}$ for
  $H_{\mbox{\tiny{iii}}}$ when Logan concurrently knows that her
  credence gets the bias wrong.
\end{quotex}

Example \ref{ex:range} also serves as an example for \textsc{inform}:
one way in which Blake feels bad for Logan is that Logan's $\{0.5\}$
credence for $H_{\mbox{\tiny{ii}}}$ is based on very little
information, a fact not reflected in Logan's credence. Walley notes
that \qeins{the precision of probability models should match the
  amount of information on which they are based}
\scite{2}{walley91}{34}. Joyce explicitly criticizes the information
overload for sharp credences in examples such as example
\ref{ex:range}. He says about sharp credences of this kind that,
despite their maximal entropy compared to other sharp credences, they
are \qeins{very informative} and \qeins{adopting [them] amounts to
  pretending that you have lots and lots of information that you
  simply don't have} \scite{2}{joyce10}{284}.

Walley and Joyce appeal to intuition when they promote
\textsc{inform}. It just feels as if there were more information in a
sharp credence than in an instate. Neither of them ever makes this
claim more explicit. Joyce admits:

\begin{quotex}
  It is not clear how such an \qnull{imprecise minimum information
    requirement} might be formulated, but it seems clear that $C_{1}$
  encodes more information than $C_{2}$ whenever
  $C_{1}\subset{}C_{2}$, or when $C_{2}$ arises from $C_{1}$ by
  conditioning. \scite{3}{joyce10}{288}
\end{quotex}

Since for the rest of the paper the emphasis will be on
\textsc{intern} and \textsc{incomp}, I will advance my argument
against \textsc{inform} right away: not only is it not clear how
Joyce's imprecise minimum information requirement might be formulated,
I see no reason why it should give the results that Joyce envisions.
To compare instates and sharp credences informationally, we would need
a non-additive set function obeying Shannon's axioms for information
(see \scite{7}{shannon48}{}, section 6). This is a non-trivial task. I
have not succeeded in solving it (nor do I need to carry the Booleans'
water), but I am not convinced that it will result in an information
measure which assigns, for instance, less entropy to a sharp credence
such as $\{0.5\}$ than to an instate such as
$\{x|1/3\leq{}x\leq{}2/3\}$. The challenge is in the Booleans' court
to produce such a non-additive set function. I doubt that they will
succeed and hope to produce more formal constraints for it in the
future, if not an impossibility theorem.

Against the force of \textsc{intern}, \textsc{incomp}, and
\textsc{inform}, I maintain that the Laplacean approach of assigning
subjective probabilities to partitions of the event space (e.g.\
objective chances) and then aggregating them by David Lewis' summation
formula (see \scite{8}{lewis81}{266f}) into a single precise credence
function is conceptually tidy and shares many of the formal virtues of
Boolean theories. If the bad taste about numerical precision lingers,
I will point to philosophical projects in other domains where the
concepts we use are sharply bounded, even though our ability to
conceive of those sharp boundaries or know them is limited (in
particular Timothy Williamson's accounts of vagueness and knowledge).
To put it provocatively, this paper defends a $0.5$ sharp credence in
heads in all three cases: for a coin of whose bias we are completely
ignorant; for a coin whose fairness is supported by a lot of evidence;
and even for a coin about whose bias we know that it is either 1/3 or
2/3 for heads.

Statements by Levi and Joyce are representative of how the Boolean
position is most commonly motivated:

\begin{quotex}
  A refusal to make a determinate probability judgment does not derive
  from a lack of clarity about one's credal state. To the contrary, it
  may derive from a very clear and cool judgment that on the basis of
  the available evidence, making a numerically determinate judgment
  would be unwarranted and arbitrary. \scite{3}{levi85}{395}
\end{quotex}

\begin{quotex}
  As sophisticated Bayesians like Isaac Levi (1980), Richard Jeffrey
  (1983), Mark Kaplan (1996), have long recognized, the proper
  response to symmetrically ambiguous or incomplete evidence is not to
  assign probabilities symmetrically, but to refrain from assigning
  precise probabilities at all. Indefiniteness in the evidence is
  reflected not in the values of any single credence function, but in
  the spread of values across the family of all credence functions
  that the evidence does not exclude. This is why modern Bayesians
  represent credal states using sets of credence functions. It is not
  just that sharp degrees of belief are psychologically unrealistic
  (though they are). Imprecise credences have a clear epistemological
  motivation: they are the proper response to unspecific evidence.
  \scite{3}{joyce05}{170f}
\end{quotex}

Consider therefore the following reasons that incline Booleans to
permit instates for rational agents:

\begin{enumerate}[(A)]
\item The greatest emphasis motivating indeterminacy rests on
  \textsc{intern}, \textsc{incomp}, and \textsc{inform}.
\item The preference structure of a rational agent may be incomplete
  so that representation theorems do not yield single probability
  measures to represent such incomplete structures.
\item There are more technical and paper-specific reasons, such as
  Thomas Augustin's attempt to mediate between the minimax pessimism
  of objectivists and the Bayesian optimism of subjectivists using
  interval probability (see \scite{8}{augustin03}{35f}); Alan
  H{\'a}jek and Michael Smithson's belief that there may be
  objectively indeterminate chances in the physical world (see
  \scite{8}{hajeksmithson12}{33}, but also \scite{8}{hajek03}{278,
    307}); Jake Chandler's claim that \qeins{the sharp model is at
    odds with a trio of plausible propositions regarding agnosticism}
  \scite{2}{chandler14}{4}; and Brian Weatherson's claim that for the
  Boolean position, open-mindedness and modesty may be consistent when
  for the Laplacean they are not (see \scite{7}{weatherson15}{}, using
  a result by Gordon Belot, see \scite{7}{belot13}{}).
\end{enumerate}

This paper mostly addresses (A), while taking (B) seriously as well
and pointing towards solutions for it. I am leaving (C) for more
specific responses to the issues presented in the cited articles. I
will address in section \ref{TheDoubleTask} Weatherson's more general
claim that it is a distinctive and problematic feature of the
Laplacean position \qeins{that it doesn't really have a good way of
  representing a state of indecisiveness or open-mindedness}
\scite{2}{weatherson15}{9}, i.e.\ that sharp credences cannot fulfill
what I will call the double task. Weatherson's more
particular claim about open-mindedness and modesty is a different
story and shall be told elsewhere.

\section{Two Camps: {\anderson} and {\augustin}}
\label{PlebeiansAndAristocrats}

My \emph{divide et impera} argument rests on the distinction between
two Boolean positions. The difference is best captured by a simple
example to show how epistemologists advocate for {\anderson} or
relapse into it, even when they have just advocated the more refined
{\augustin}.

\begin{quotex}
  \beispiel{Skittles}\label{ex:skittles} Every skittles bag contains
  42 pieces of candy. It is filled by robots from a giant randomized
  pile of candies in a warehouse, where the ratio of five colours is
  8:8:8:9:9, orange being the last of the five colours. Logan picks
  one skittle from a bag and tries to guess what colour it is before
  she looks at it. She has a sharp credence of $9/42$ that the skittle
  is orange.
\end{quotex}

{\anderson} Booleans reject Logan's sharp credence on the basis
that she does not know that there are 9 orange skittles in her
particular bag. A $9/42$ credence suggests to them a knowledge claim
on Logan's part, based on very thin evidence, that her bag contains 9
orange skittles. Logan's doxastic state, however, is much more
complicated than her credal state. She knows about the robots and the
warehouse. Therefore, her credences that there are $k$ orange skittles
in the bag conform to the Bernoulli distribution:

\begin{equation}
  \label{eq:bern}
  C(k)=\binom{42}{k}\left(\frac{9}{42}\right)^{k}\left(\frac{33}{42}\right)^{42-k}
\end{equation}

For instance, her sharp credence that there are in fact $9$ orange
skittles in the bag is approximately 14.9\%. One of Augustin's
concessions, the refinements that {\augustin} makes to {\anderson},
clarifies that a coherent Boolean position must agree with the
Laplacean position that doxastic states are not fully captured by
credal states. We will see in the next section why this is the case.

It is a characteristic of {\anderson}, however, to require that
the credal state be sufficient for inference, updating, and decision
making. Susanna Rinard, for example, considers it the goal of instates
to provide \qeins{a complete characterization of one's doxastic
  attitude} \scite{2}{rinard15}{5} and reiterates a few pages later
that it is \qeins{a primary purpose of the set of functions model to
  represent the totality of the agent's actual doxastic state}
\scite{2}{rinard15}{12}.

I will give a few examples of {\anderson} in the literature, where the
authors usually consider themselves to be defending an amalgamated
Boolean position which is \emph{pro toto} superior to the Laplacean
position. Here is an illustration in H{\'a}jek and Smithson.

\begin{quotex}
  \beispiel{Lung Cancer}\label{ex:crude} Your doctor is your
  sole source of information about medical matters, and she assigns a
  credence of $[0.4,0.6]$ to your getting lung cancer.
\end{quotex}

H{\'a}jek and Smithson go on to say that 

\begin{quotex}
  it would be odd, and arguably irrational, for you to assign this
  proposition a sharper credence---say, $0.5381$. How would you defend
  that assignment? You could say, I don't have to defend it, it just
  happens to be my credence. But that seems about as unprincipled as
  looking at your sole source of information about the time, your
  digital clock, which tells that the time rounded off to the nearest
  minute is 4:03---and yet believing that the time is in fact 4:03 and
  36 seconds. Granted, you may just happen to believe that; the point
  is that you have no business doing so.
  \scite{3}{hajeksmithson12}{38f}
\end{quotex}

This is an argument against Laplaceans by {\anderson} because it
conflates partial belief and full belief. The precise credences in
H{\'a}jek and Smithson's example, on any reasonable Laplacean
interpretation, do not represent full beliefs that the objective
chance of getting lung cancer is $0.5381$ or that the time of the day
is 4:03:36. A sharp credence rejects no hypothesis about objective
chances (unlike an instate for {\anderson}). It often has a subjective
probability distribution operating in the background, over which it
integrates to yield the sharp credence (it would do likewise in
H{\'a}jek and Smithson's example for the prognosis of the doctor or
the time of the day).\bcut{22} The integration proceeds by Lewis'
summation formula (see \scite{8}{lewis81}{266f}):

\begin{equation}
  \label{eq:s2}
  C(R)=\int_{0}^{1}\zeta{}P\left(\pi(R)=\zeta\right)\,d\zeta{}.\bcut{21}
\end{equation}

{\noindent}If, for example, $R$ is the proposition that Logan's
randomly drawn skittle in example \ref{ex:skittles} is orange, then

\begin{equation}
  \label{eq:skit}
  C(R)=\sum_{k=0}^{42}\frac{k}{42}\binom{42}{k}\left(\frac{9}{42}\right)^{k}\left(\frac{33}{42}\right)^{42-k}=9/42
\end{equation}

No objective chance $\pi(R)$ needs to be excluded by it. Any updating
will merely change the partial beliefs, but no full beliefs. Instates,
on the other hand, by giving ranges of acceptable objective chances
suggest that there is a full belief that the objective chance does not
lie outside what is indicated by the instate (corresponding to
\textsc{intern}). When a {\anderson} advocate learns that an objective
chance lies outside her instate, she needs to resort to belief
revision rather than updating her partial beliefs. A {\augustin}
advocate can avoid this by accepting one of Augustin's concessions
that I will introduce in section \ref{AugustinsConcessions}.

Here is another quote revealing the position of {\anderson}, this
time by Kaplan. The example that Kaplan gives is in all relevant
respects like example \ref{ex:skittles}, except that he contrasts two
cases, one in which the composition of an urn is known and the other
where it is not (as the composition of Logan's skittles bag is not
known).

\begin{quotex}
  Consider the two cases we considered earlier, and how the difference
  between them bears on the question as to how confident you should be
  that (B) the ball drawn will be black. In the first case [where you
  know the composition of the urn], it is clear why you should have a
  degree of confidence equal to 0.5 that ball drawn from the urn will
  be black. Your evidence tells you that there is an objective
  probability of 0.5 that the ball will be black: it rules every other
  assignment out either as too low or as too high. In the second case,
  however, you do not know the objective probability that the ball
  will be black, because you don't know exactly how many of the balls
  in the urn are black. Your evidence---thus much inferior in quality
  to the evidence you have in the first case---doesn't rule out all
  the assignments your evidence in the first case does. It rules out,
  as less warranted than the rest, every assignment that gives B a
  value $<0.3$, and every assignment that gives B a value $>0.65$. But
  none of the remaining assignments can reasonably thought to be any
  more warranted, or less warranted, by your evidence than any other.
  But then it would seem, at least at first blush, an exercise in
  unwarranted precision to accede to the requirement, issued by
  Orthodox Bayesian Probabilism [the Laplacean position], that you
  choose one of those assignments to be your own.
  \scite{3}{kaplan10}{43f}
\end{quotex}

While most of these examples have been examples of presenting
{\anderson} as an amalgamated Boolean position, without heed to the
refinements of Augustin and Joyce, it is also the case that refined
Booleans belonging to {\augustin} relapse into {\anderson} patterns
when they argue against the Laplacean position. This is not
surprising, because, as we will see, the refined Boolean position
{\augustin} is more coherent than the more simple Boolean position
{\anderson}, but also left without resources to address the problems
that have made the Laplacean position vulnerable in the first place.

Joyce, for instance, refers to an example that is again in all
relevant respects like example \ref{ex:skittles} and states that Logan
is \qeins{committing herself to a definite view about the relative
  proportions of skittles in the bag} (see \scite{8}{joyce10}{287},
pronouns and example-specific nouns changed to fit example
\ref{ex:skittles}). Augustin defends the Boolean position with another
example of relapse:

\begin{quotex}
  Imprecise probabilities and related concepts {\ldots} provide a
  powerful language which is able to reflect the partial nature of the
  knowledge suitably and to express the amount of ambiguity
  adequately. \scite{3}{augustin03}{34}
\end{quotex}

Augustin himself (see section \ref{AugustinsConcessions} on Augustin's
concessions) details the demise of the idea that indeterminate credal
states can \qeins{express the amount of ambiguity adequately.} Before
I go into these details, however, I need to make the case that
Augustin's concessions are necessary in order to refine {\anderson}
and make it more coherent. It is two problems for instates that make
this case for us: dilation and the impossibility for learning. Note
that these problems are not sufficient to reject instates---they only
compel us to refine the more simple Boolean position via Augustin's
concessions. The final game is between {\augustin} and Laplaceans,
where I will argue that the {\augustin} position has lost the
intuitive appeal of the amalgamated Boolean position to present
solutions to prima facie problems facing the Laplacean position.

\section{Dilation and Learning}
\label{DilationLearningAndEntropy}

Here are two potential problems for Booleans:

\begin{itemize}
\item \textsc{dilation} Instates are vulnerable to dilation.
\item \textsc{obtuse} Instates do not permit learning.
\end{itemize}

Both of these can be resolved by making Augustin's concessions. I will
introduce these problems in the present section, then Augustin's
concessions in the next section, and the implications for the more
general disagreement between Booleans and Laplaceans in the final
section.

\subsection{Dilation}
\label{dilation}

Consider the following example for \textsc{dilation} (see
\scite{8}{white10}{175f} and \scite{8}{joyce10}{296f}).

\begin{quotex}
  \beispiel{Dilation}\label{ex:dilation} Logan has two Bernoulli
  generators, \textit{coin}$_{\mbox{\tiny{iv}}}$ and
  \textit{coin}$_{\mbox{\tiny{v}}}$. She has excellent evidence that
  \textit{coin}$_{\mbox{\tiny{iv}}}$ is fair and no evidence about the
  bias of \textit{coin}$_{\mbox{\tiny{v}}}$. Logan's graduate student
  independently tosses both \textit{coin}$_{\mbox{\tiny{iv}}}$ and
  \textit{coin}$_{\mbox{\tiny{v}}}$. Then she tells Logan whether the
  two tosses are correlated or not
  ($H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ or
  $H_{\mbox{\tiny{iv}}}\equiv{}T_{\mbox{\tiny{v}}}$, where
  $X\equiv{}Y$ means
  $(X\wedge{}Y)\vee(\urcorner{}X\wedge\urcorner{}Y)$). Logan, who has
  a sharp credence for $H_{\mbox{\tiny{v}}}$, takes this information
  in stride, but she feels bad for Blake, whose credence in
  $H_{\mbox{\tiny{iv}}}$ dilates to $[0,1]$ even though Blake shares
  Logan's excellent evidence that \textit{coin}$_{\mbox{\tiny{iv}}}$
  is fair.
\end{quotex}

Here is why Blake's credence in $H_{\mbox{\tiny{iv}}}$ must dilate. Her
credence in $H_{\mbox{\tiny{v}}}$ is $[0,1]$, by stipulation. Let
$c(X)$ be the set of sharp credences representing Blake's instate, for
example $c(H_{\mbox{\tiny{v}}})=[0,1]$. Then

\begin{equation}
  \label{eq:d1}
  c(H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})=c(H_{\mbox{\tiny{iv}}}\equiv{}T_{\mbox{\tiny{v}}})=\{0.5\}
\end{equation}

because the tosses are independent and
$c(H_{\mbox{\tiny{iv}}})=\{0.5\}$ by stipulation. Next,

\begin{equation}
  \label{eq:d2}
  c(H_{\mbox{\tiny{iv}}}|H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})=c(H_{\mbox{\tiny{v}}}|H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})
\end{equation}

where $c(X|Y)$ is the updated instate after finding out $Y$. Booleans
accept (\ref{eq:d2}) because they are Bayesians and update by standard
conditioning. Therefore,

\begin{align}
  \label{eq:d3}
  &c(H_{\mbox{\tiny{iv}}}|H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})=c(H_{\mbox{\tiny{v}}}|H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})=\frac{c(H_{\mbox{\tiny{iv}}})c(H_{\mbox{\tiny{v}}})}{c(H_{\mbox{\tiny{iv}}})c(H_{\mbox{\tiny{v}}})+c(T_{\mbox{\tiny{iv}}})c(T_{\mbox{\tiny{v}}})} \notag \\
  &=c(H_{\mbox{\tiny{v}}})=[0,1].
\end{align}

Blake's updated instate for $H_{\mbox{\tiny{iv}}}$ has dilated from
$\{0.5\}$ to $[0,1]$.

This does not sound like a knock-down argument against Booleans (it is
investigated in detail in \scite{7}{seidenfeldwasserman93}{}), but
Roger White uses it to derive implications from instates which are
worrisome.

\begin{quotex}
  \beispiel{Chocolates}\label{ex:chocolates} Four out of five
  chocolates in the box have cherry fillings, while the rest have
  caramel. Picking one at random, what should my credence be that it
  is cherry-filled? Everyone, including the staunchest [Booleans],
  seems to agree on the answer $4/5$. Now of course the chocolate I've
  chosen has many other features, for example this one is circular
  with a swirl on top. Noticing such features could hardly make a
  difference to my reasonable credence that it is cherry filled
  (unless of course I have some information regarding the relation
  between chocolate shapes and fillings). Often chocolate fillings do
  correlate with their shapes, but I haven't the faintest clue how
  they do in this case or any reason to suppose they correlate one way
  rather than another {\ldots} the further result is that while my
  credence that the chosen chocolate is cherry-filled should be $4/5$
  prior to viewing it, once I see its shape (whatever shape it happens
  to be) my credence that it is cherry-filled should dilate to become
  [indeterminate]. But this is just not the way we think about such
  matters. \scite{3}{white10}{183}
\end{quotex}

I will characterize the problems that dilation causes for the Boolean
position by three aspects (all of which originate in
\scite{7}{white10}{}):

\begin{itemize}
\item \textsc{retention} This is the problem in example
  \ref{ex:chocolates}. When we tie the outcome of a random process
  whose objective chance we know to the outcome of a random process
  whose chance we do not know, White maintains that we should be
  entitled to \emph{retain} the credence that is warranted by the
  known objective chance. One worry about the Boolean position in this
  context is that credences become excessively dependent on the mode
  of representation of a problem.
\item \textsc{repetition} Consider again example \ref{ex:dilation},
  although this time Blake runs the experiment 10,000 times. Each
  time, her graduate student tells her whether
  $H^{n}_{\mbox{\tiny{iv}}}\equiv{}H^{n}_{\mbox{\tiny{v}}}$ or
  $H^{n}_{\mbox{\tiny{iv}}}\equiv{}T^{n}_{\mbox{\tiny{v}}}$, $n$
  signifying the $n$-th experiment. After running the experiment that
  many times, approximately half of the outcomes of
  \textit{coin}$_{\mbox{\tiny{iv}}}$ are heads. Now Blake runs the
  experiment one more time. Again, the Boolean position mandates
  dilation, but should Blake not just on inductive grounds persist in
  a sharp credence of $0.5$ for $H_{\mbox{\tiny{iv}}}$, given that
  about half of the coin flips so far have come up heads? Attentive
  readers will notice a sleight of hand here: as many times as Blake
  performs the experiment, it must not have any evidential impact on
  the assumptions of example \ref{ex:dilation}, especially that the
  two coin flips remain independent and that the credal state for 
  \textit{coin}$_{\mbox{\tiny{v}}}$ is still, even after all these
  experiments, maximally indeterminate. 
\item \textsc{reflection} Consider again example \ref{ex:dilation}.
  Blake's graduate student will tell Blake either
  $H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ or
  $H_{\mbox{\tiny{iv}}}\equiv{}T_{\mbox{\tiny{v}}}$. No matter what
  the graduate student tells Blake, Blake's credence in
  $H_{\mbox{\tiny{iv}}}$ dilates to an instate of $[0,1]$. Blake
  therefore is subject to Bas van Fraassen's reflection principle
  stating that
  \begin{equation}
    \label{eq:reflection}
    P_{t}^{a}(A|p_{t+x}^{a}(A)=r)=r
  \end{equation}
  where $P_{t}^{a}$ is the agent $a$'s credence function at time $t$,
  $x$ is any non-negative number, and $p_{t+x}^{a}(A)=r$ is the
  proposition that at time $t+x$, the agent $a$ will bestow degree $r$
  of credence on the proposition $A$ (see van
  Fraassen, \scite{10}{vanfraassen84}{244}). Van Fraassen had sharp
  credences in mind, but it is not immediately obvious why the
  reflection principle should not also hold for instates.
\end{itemize}

To address the force of \textsc{retention}, \textsc{repetition}, and
\textsc{reflection}, Joyce hammers home what I have called Augustin's
concessions. According to Joyce, none of White's attacks succeed if a
refinement of {\anderson}'s position takes place and instates are not
required either to reflect knowledge of objective chances or doxastic
states. I will address this in detail in section
\ref{AugustinsConcessions}, concluding that Augustin's concessions are
only necessary based on \textsc{reflection}, whereas solutions for
\textsc{retention} and \textsc{repetition} have less far-reaching
consequences and do not impugn the Boolean position of {\anderson}.

\subsection{Learning}
\label{learning}

Here is an example for \textsc{obtuse} (see Rinard's objection cited
in \scite{8}{white10}{84} and addressed in \scite{8}{joyce10}{290f}).
It presumes Joyce's supervaluationist semantics of instates (see
\scite{7}{hajek03}{}; \scite{8}{joyce10}{288}; and
\scite{7}{rinard15}{}; for a problem with supervaluationist semantics
see \scite{7}{lewis93}{}; and an alternative which may solve the
problem see \scite{8}{weatherson15}{7}), for which Joyce uses the
helpful metaphor of committee members, each of whom holds a sharp
credence. The instate consists then of the set of sharp credences from
each committee member: for the purposes of updating, for example, each
committee member updates as if she were holding a sharp credence. The
aggregate of the committee members' updated sharp credences forms the
updated instate. Supervaluationist semantics also permits comparisons,
when for example a partial belief in $X$ is stronger than a partial
belief in $Y$ because all committee members have sharp credences in
$X$ which exceed all the sharp credences held by committee members
with respect to $Y$.

\begin{quotex}
  \beispiel{Learning}\label{ex:learning} Blake has a Bernoulli
  generator in her lab, \textit{coin}$_{\mbox{\tiny{vi}}}$, of whose
  bias she knows nothing and which she submits to experiments. At first,
  Blake's instate for $H_{\mbox{\tiny{vi}}}$ is $[0,1]$. After a few
  experiments, it looks like \textit{coin}$_{\mbox{\tiny{vi}}}$ is
  fair. However, as committee members crowd into the centre and update
  their sharp credences to something closer to $0.5$, they are
  replaced by extremists on the fringes. The instate remains at
  $[0,1]$. 
\end{quotex}

It is time now to examine refinements of the Boolean position to
address these problems.

\section{Augustin's Concessions}
\label{AugustinsConcessions}

Joyce has defended instates against \textsc{dilation} and
\textsc{obtuse}, making Augustin's concessions (AC1) and (AC2). I am
naming them after Thomas Augustin, who has some priority over Joyce in
the matter. Augustin's concessions distinguish {\anderson} and
{\augustin}, the former of which does not make the concessions and
identifies partial beliefs with full beliefs about objective chances.
A sophisticated view of partial beliefs recognizes that they are sui
generis, which necessitates a substantial reconciliation project
between full belief epistemology and partial belief epistemology. My
task at hand is to agree with the refined position of {\augustin} in
their argument against {\anderson} that this reconciliation project is
indeed substantial and that partial beliefs are not full beliefs about
objective chances; but also that {\augustin} fails to summon arguments
against the Laplacean position without relapsing into an unrefined
version of indeterminacy.

Here, then, are Augustin's concessions:

\begin{description}
\item[{\bf (AC1)}] Credal states do not adequately represent doxastic
  states. The same instate can reflect different doxastic states, even
  when the difference in the doxastic states matters for updating,
  inference, and decision making.
\item[{\bf (AC2)}] Instates do not represent full belief claims about
  objective chances. White's \emph{Chance Grounding Thesis} is not an
  appropriate characterization of the Boolean position.
\end{description}

I agree with Joyce that (AC1) and (AC2) are both necessary and
sufficient to resolve \textsc{dilation} and \textsc{obtuse} for
instates. I disagree with Joyce about what this means for an overall
recommendation to accept the Boolean rather than the Laplacean
position. After I have already cast doubt on \textsc{inform}, I will
show that (AC1) and (AC2) neutralize \textsc{intern} and
\textsc{incomp}, the major impulses for rejecting the Laplacean
position. 
% A sharp credence reflects the doxastic state and does not represent
% it. If instates could successfully integrate all relevant features of
% the doxastic state, they would represent it. (AC1) and (AC2) manifest
% that they cannot.\bcut{4}\bcut{5}

Indeterminacy imposes a double task on credences (representing both
uncertainty and available evidence) that they cannot coherently
fulfill. I will present several examples where this double task
stretches instates to the limits of plausibility. Joyce's idea that
credences can represent balance, weight, and specificity of the
evidence (in \scite{7}{joyce05}{}) is inconsistent with the use of
indeterminacy. Joyce himself, in response to \textsc{dilation} and
\textsc{obtuse}, gives the argument why this is the case (see
\scite{8}{joyce10}{290ff} for \textsc{obtuse}; and
\scite{8}{joyce10}{296ff} for \textsc{dilation}).\bcut{12} Let us
begin by looking more closely at how (AC1) and (AC2) protect
{\augustin} from \textsc{dilation} and \textsc{obtuse}.

\subsection{Augustin's Concession (AC1)}
\label{jj1}

(AC1) says that credences do not adequately represent a doxastic
state. The same instate can reflect different doxastic states, where
the difference is relevant to updating, inference, and decision
making.

Augustin recognizes the problem of inadequate representation before
Joyce, with specific reference to instates: \qeins{The imprecise
  posterior does no longer contain all the relevant information to
  produce optimal decisions. Inference and decision do not coincide
  any more} \scite{2}{augustin03}{41} (see also an example for
inadequate representation of evidence by instates in
\scite{8}{bradleysteele13}{16}). Joyce rejects the notion that
identical instates encode identical beliefs by giving two examples.
The first one is problematic. The second one, which is example
\ref{ex:dilation} given earlier, addresses the issue of
\textsc{dilation} more directly. Here is the first example.

\begin{quotex}
  \beispiel{Three-Sided Die}\label{ex:die} Suppose $\mathcal{C}'$ and
  $\mathcal{C}''$ are defined on a partition $\{X,Y,Z\}$ corresponding
  to the result of a roll of a three sided-die. Let $\mathcal{C}'$
  contain all credence functions defined on $\{X,Y,Z\}$ such that
  $c(Z)\geq1/2$, and let $\mathcal{C}''$ be the subset of
  $\mathcal{C}''$ whose members also satisfy $c(X)=c(Y)$ (see
  \scite{8}{joyce10}{294}).
\end{quotex}

Joyce then goes on to say,

\begin{quotex}
  It is easy to show that $\mathcal{C}'$ and $\mathcal{C}''$ generate
  the same range of probabilities for all Boolean combinations of
  $\{X,Y,Z\}$, and so LP and PSET deem them equivalent. But they are
  surely different: the $\mathcal{C}''$-person believes everything the
  $\mathcal{C}'$-person believes, but she also regards $X$ and $Y$ as
  equiprobable.
\end{quotex}

example \ref{ex:die} is problematic because $\mathcal{C}'$ and
$\mathcal{C}''$ do not generate the same range of probabilities: if,
as Joyce says, $c(Z)\geq1/2$, then $c(X)=c(Y)$ implies $c(X)\leq{}1/4$
for $\mathcal{C}''$, but not for $\mathcal{C}'$. What Joyce wants to
say is that the same instate can encode doxastic states which are
relevantly different when it comes to updating probabilities, and the
best example for this is example \ref{ex:dilation} itself.

To explain this in more detail, we need to review for a moment what
Lewis means by the Principal Principle and by inadmissibility. The
Principal Principle requires that my knowledge of objective chances is
reflected in my credence, unless there is inadmissible evidence.
Inadmissible evidence would for instance be knowledge of a coin toss
outcome, in which case of course I do not need to have a credence for
it corresponding to the bias of the coin. In example
\ref{ex:dilation}, I could use the Principal Principle in the spirit
of \textsc{retention} to derive a contradiction to the Boolean
formalism: (*) $H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ does
not give anything away about $H_{\mbox{\tiny{iv}}}$, therefore (**)
$c(H_{\mbox{\tiny{iv}}}|H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}})=c(H_{\mbox{\tiny{iv}}})$
by the Principal Principle and in contradiction to (\ref{eq:d3}). 

Joyce explains how (*) is false and blocks the conclusion (**), which
would undermine the Boolean position.
$H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ is clearly
inadmissible, even without (AC1), since it is information that not
only changes Blake's doxastic state, but also her credal state.\lcut{3}

We would usually expect more information to sharpen our credal states
(see Walley's anti-dilation principle and his response to this problem
in \scite{10}{walley91}{207 and 299}), an intuition violated by both
\textsc{dilation} and \textsc{obtuse}. As far as \textsc{dilation} is
concerned, however, the loss of precision is in principle not any more
surprising than information that increases the Shannon entropy of a
sharp credence.

\begin{quotex}
  \beispiel{Rumour}\label{ex:rumour} A rumour that the Canadian prime
  minister has been assassinated raises your initially very low
  probability that this event is taking place today to approximately
  50\%.
\end{quotex}

It is true for both sharp and indeterminate credences that information
can make us less certain about things. This is the simple solution for
\textsc{retention}. If one of Joyce's committee members has a sharp
credence of $1$ in $H_{\mbox{\tiny{v}}}$ and learns
$H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$, then her sharp
credence for $H_{\mbox{\tiny{iv}}}$ should obviously be $1$ as well;
ditto and mutatis mutandis for the committee member who has a sharp
credence of $0$ in $H_{\mbox{\tiny{v}}}$. (AC1) is unnecessary.

Here is how dilation is as unproblematic as a gain in entropy after
more information in example \ref{ex:rumour}:\fcut{11}

\begin{quotex}
  \beispiel{Dilating Urns}\label{ex:urns} You are about to draw a ball
  from an urn with 200 balls (100 red, 100 yellow). Just before you
  draw, you receive the information that the urn has two chambers
  which are obscured to you as you draw the ball, one with 99 red
  balls and 1 yellow ball, the other with 1 red ball and 99 yellow
  balls.
\end{quotex}

Dilation from a sharp credence of $\{0.5\}$ to an instate of
$[0.01,0.99]$ (or $\{0.01,0.99\}$, depending on whether convexity is
required) is unproblematic, although the example prefigures that there
is something odd about the Boolean conceptual approach. The example
licences a 99:1 bet for one of the colours (if the instate is
interpreted as upper and lower previsions), which inductively would be
a foolish move. This is a problem that arises out of the Boolean
position quite apart from \textsc{dilation} and in conjunction with
betting licences, which we will address in example \ref{ex:monkey}.

So far we have not found convincing reasons to accept (AC1). Neither
dilation as a phenomenon nor Lewis' inadmissibility criterion need to
compel a {\anderson} advocate to admit (AC1), despite Joyce's claims
in the abstract of his paper that reactions to dilation \qeins{are
  based on an overly narrow conception of imprecise belief states
  which assumes that we know everything there is to know about a
  person's doxastic attitudes once we have identified the spreads of
  values for her imprecise credences.} Not only does example
\ref{ex:die} not give us the desired results, we can also resolve
\textsc{retention} and \textsc{repetition} without recourse to (AC1).
It is, in the final analysis, \textsc{reflection} which will make the
case for (AC1).

It is odd that Joyce explicitly says that the argument
\textsc{repetition} \qeins{goes awry by assuming that credal states
  which assign the same range of credences for an event reflect the
  same opinions about that event} \scite{2}{joyce10}{304}, when in the
following he makes an air-tight case against the anti-Boolean force of
\textsc{repetition} without ever referring to (AC1). Joyce's case
against \textsc{repetition} is based on the sleight of hand to which I
made reference when I introduced \textsc{repetition}. There is no need
to repeat Joyce's argument here.

Let me add that despite my agreement with Joyce on how to handle
\textsc{repetition}, although we disagree that it has anything to do
with (AC1), a worry about the Boolean position with respect to
\textsc{repetition} lingers. Joyce requires that Blake, in so far as
Blake wants to be rational, has a maximally indeterminate credal state
for $H^{10000}_{\mbox{\tiny{iv}}}$ after hearing from her graduate
student. The oddity of this, when we have just had about $5000$ heads
and $5000$ tails, remains. Blake's maximally indeterminate credal
state rests on her stubborn conviction that her credal state must be
inclusive of the objective chance of
\textit{coin}$^{10000}_{\mbox{\tiny{iv}}}$ landing heads.

Logan, if she were to do this experiment, would relax, reason
inductively as well as based on her prior probability, and give
$H_{\mbox{\tiny{iv}}}$ a credence of $0.5$, since her credal state is
not in the same straight-jacket of underlying objective chances---just
as in example \ref{ex:skittles} Logan is able to have a sharp credence
of $9/42$ for picking an orange skittle, when her credence that there
are $9$ orange skittles in the bag is only 14.9\%. This worry supports
Augustin's second concession (AC2) that the relationship between
instates and objective chances is much looser than for {\anderson},
but more about this in the next subsection.

We are left with \textsc{reflection}, which takes up little room in
Joyce but bears most of the burden in his argument for (AC1). It is
indeed odd that a rational agent should have two strictly distinct
credal states $C_{1}$ and $C_{2}$, when $C_{2}$ follows upon $C_{1}$
from a piece of information that says either $X$ or
$\urcorner{}X$---but it does not matter which of the two. Why does the
rational agent not assume $C_{2}$ straight away? Joyce introduces an
important distinction for van Fraassen's reflection principle: It is
not the degree of credence that is decisive as in van Fraassen's
original formulation of the principle, but the doxastic state. $X$ and
$\urcorner{}X$ (in example \ref{ex:dilation}, they refer to
$H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ and
$H_{\mbox{\tiny{iv}}}\equiv{}T_{\mbox{\tiny{v}}}$) both lead from a
sharp credence of $0.5$ to an instate of $[0,1]$ for
$H_{\mbox{\tiny{iv}}}$, but this updated instate reflects completely
different doxastic states. In Joyce's words, \qeins{the beliefs about
  $H_{\mbox{\tiny{iv}}}$ you will come to have upon learning
  $H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ are complementary
  to the beliefs you will have upon learning
  $H_{\mbox{\tiny{iv}}}\equiv{}T_{\mbox{\tiny{v}}}$}
\scite{2}{joyce10}{304}. Committee members representing complementary
beliefs agree on the instate, but single committee members take
opposite views depending on the information, $X$ or $\urcorner{}X$.
Credal states keep track only of the committee's aggregate credal
state, whereas doxastic states keep track of each committee member's
individual sharp credences.

This resolves the anti-Boolean force of \textsc{reflection} by making
the concession (AC1). Ironically, of course, not being able to
represent a doxastic state, but only to reflect it inadequately, was
just the problem that Laplacean sharp credences had which Boolean
instates were supposed to fix. One way {\augustin} could respond is
like this:

\begin{quotex}
  \textbf{Riposte:} If you are going to make a difference between
  \emph{representing} a doxastic state and \emph{reflecting} a
  doxastic state, where the former poses an identity relationship
  between credal states and doxastic states and the latter a
  supervenience relationship, then all you have succeeded in making me
  concede is that both instates and sharp credences reflect doxastic
  states. Instates may still be more successful in reflecting doxastic
  states than sharp credences are and so solve the abductive task of
  explaining partial beliefs better.
\end{quotex}

There are several reasons why I doubt this line of argument can be
successful. The Laplacean position has formal advantages, for example
that it is able to cooperate with information theory, an ability which
{\augustin} lacks. There is no coherent theory of how relations
between instates can be evaluated on the basis of information and
entropy, which are powerful tools when it comes to justifying
fundamental Bayesian tenets (see \scite{7}{shorejohnson80}{};
\scite{7}{giffin08}{}; and \scite{7}{lukits15}{}). Furthermore, the
Laplacean position is conceptually tidy. It distinguishes between the
quantifiable aspects of a doxastic state, which it integrates to yield
the sharp credence, and other aspects of the evidence, such as
incompleteness or ambiguity. Instates dabble in what I will call the
double task: trying to reflect both aspects without convincing success
in either. 

\subsection{Augustin's Concession (AC2)}
\label{jj2}

(AC2) says that instates do not reflect knowledge claims about
objective chances. White's \emph{Chance Grounding Thesis} (which White
does not endorse, being a Laplacean) is not an appropriate
characterization of the Boolean position.

\begin{quotex}
  \textbf{Chance Grounding Thesis:} Only on the basis of known chances
  can one legitimately have sharp credences. Otherwise one's spread of
  credence should cover the range of possible chance hypotheses left
  open by your evidence. \scite{2}{white10}{174}\bcut{13}
\end{quotex}

Joyce considers (AC2) to be as necessary for a coherent Boolean view
of partial beliefs, blocking \textsc{obtuse}, as (AC1) is, blocking
\textsc{dilation} (see \scite{8}{joyce10}{289f}).\bcut{16} 

\textsc{obtuse} is related to \textsc{vacuity}, another problem for
Booleans:

\begin{itemize}
\item \textsc{vacuity} If one were to be committed to the principle of
  regularity, that all states of the world considered possible have
  positive probability (for a defence see
  \scite{8}{edwardsetal63}{211}); and to the solution of Henry
  Kyburg's lottery paradox, that what is rationally accepted should
  have probability 1 (for a defence of this principle see
  \scite{7}{douvenwilliamson06}{}); and the CGT, that one's spread of
  credence should cover the range of possible chance hypotheses left
  open by the evidence (implied by much of Boolean literature); then
  one's instate would always be vacuous.
\end{itemize}

Booleans must deny at least one of the premises to avoid the
conclusion. Joyce denies the CGT, giving us (AC2). It is by no means
necessary to sign on to regularity and to the above-mentioned solution
of Henry Kyburg's lottery paradox in order to see how (AC2) is a
necessary refinement of {\anderson}. The link between objective
chances and credal states expressed in the CGT is suspect for many
other reasons. I have referred to them passim, but will not go into
more detail here.

\section{The Double Task}
\label{TheDoubleTask}

Sharp credences have a single task: to reflect epistemic uncertainty
as a tool for updating, inference, and decision making. They cannot
fulfill this task without continued reference to the evidence which
operates in the background. To use an analogy, credences are not
sufficient statistics with respect to updating, inference, and
decision making. What is remarkable about Joyce's response to
\textsc{dilation} and \textsc{obtuse} is that Joyce recognizes that
instates are not sufficient statistics either. But this means that
they fail at the double task which has been imposed on them: to
represent both epistemic uncertainty and relevant features of the
evidence.

In the following, I will provide a few examples where it becomes clear
that instates have difficulty representing uncertainty because they
are tangled in a double task which they cannot fulfill.

\begin{quotex}
  \beispiel{Aggregating Expert Opinion}\label{ex:aggreg} Blake has no
  information whether it will rain tomorrow ($R$) or not except the
  predictions of two weather forecasters. One of them forecasts 0.3 on
  channel GPY, the other 0.6 on channel QCT. Blake considers the QCT
  forecaster to be significantly more reliable, based on past
  experience.
\end{quotex}

An instate corresponding to this situation may be $[0.3,0.6]$ (see
\scite{8}{walley91}{214}), but it will have a difficult time
representing the difference in reliability of the experts. We could
try $[0.2,0.8]$ (since the greater reliability of QCT suggests that
the chance of rain tomorrow is higher rather than lower) or
$[0.1,0.7]$ (since the greater reliability of QCT suggests that its
estimate is more precise), but it remains obscure what the criteria
might be.

A sharp credence of $P(R)=0.53$, for example, does the right thing.
Such a credence says nothing about any beliefs that the objective
chance is restricted to a subset of the unit interval, but it
accurately reflects the degree of uncertainty that the rational agent
has over the various possibilities. Beliefs about objective chances
make little sense in many situations where we have credences, since it
is doubtful even in the case of rain tomorrow that there is an urn of
nature from which balls are drawn. What is really at play is a complex
interaction between epistemic states (for example, experts evaluating
meteorological data) and the evidence which influences them.\bcut{17}

As we will see in the next example, it is an advantage of sharp
credences that they do not exclude objective chances, even extreme
ones, because they express partial belief and do not suggest, as
instates do for {\anderson}, that there is full belief knowledge
that the objective chance is a member of a proper subset of the
possibilities (for an example of a crude version of indeterminacy that
reduces partial beliefs to full beliefs see \scite{8}{levi81}{540},
\qeins{inference derives credal probability from knowledge of the
  chances of possible outcomes}; or \scite{8}{kaplan10}{45},
\qeins{you should rule out all and only the assignments the evidence
  warrants your regarding as too high or too low, and you should
  remain in suspense between those degree of confidence assignments
  that are left}).

\begin{quotex}
  \beispiel{Precise Credences}\label{ex:preccre} Logan's credence for
  rain tomorrow, based on the expert opinion of channel GPY and
  channel QCT (she has no other information) is $0.53$. Is it
  reasonable for Logan, considering how little evidence she has, to
  reject the belief that the chance of rain tomorrow is $0.52$ or
  $0.54$; or to prefer a $52.9$ cent bet on rain to a $47.1$ cent bet
  on no rain?
\end{quotex}

The first question in example \ref{ex:preccre} is as confused as the
{\anderson} confusion found in example \ref{ex:crude} discussed
earlier. As for the second question in example \ref{ex:preccre}: why
would we prefer a $52.9$ cent bet on rain to a $47.1$ cent bet on no
rain, given that we do not possess the power of discrimination between
these two bets? It is important not to confuse the claim that it is
reasonable to hold both $X$ and $Y$ with the claim that it is
reasonable to hold either $X$ (without $Y$) or $Y$ (without $X$). It
is the reasonableness of holding $X$ and $Y$ concurrently that is
controversial, not the reasonableness of holding $Y$ (without holding
$X$) when it is reasonable to hold $X$.

Let $R(S,Z,t)$ mean \qeins{it is rational for $S$ to believe $Z$ at
  time $t$.} Then $R$ is exportable (see \scite{8}{rinard15}{6}) if
and only if $R(S,X,t)$ and $R(S,Y,t)$ imply $R(S,X\wedge{}Y,t)$.
Beliefs somehow grounded in subjectivity, such as beliefs about
etiquette or colour perception are counter-examples for the
exportability of $R$. Vagueness also gives us cases of
non-exportability. Rinard considers the connection between vagueness
and indeterminacy to be an argument in favour of indeterminacy.

My argument is that non-exportability blunts an argument against the
Laplacean position. In a moment, I will talk about anti-luminosity,
the fact that a rational agent may not be able to distinguish
psychologically between a $54.9$ cent bet on an event and a $45.1$ bet
on its negation, when her sharp credence is $0.55$. She must reject
one of them not to incur sure loss, so proponents of indeterminacy
suggest that she choose one of them freely without being constrained
by her credal state or reject both of them. I claim that a sharp
credence will make a recommendation between the two so that only one
of the bets is rational given her particular credence, but that does
not mean that another sharp credence which would give a different
recommendation may not also be rational for her to have. Partial
beliefs are non-exportable.\bcut{19}

The answer to the second question in example \ref{ex:preccre} ties in
with the issue of incomplete preference structure referred to above as
motivation (B) for instates.

\begin{quotex}
  It hardly seems a requirement of rationality that belief be precise
  (and preferences complete); surely imprecise belief (and
  corresponding incomplete preferences) are at least rationally
  permissible. (\scite{8}{bradleysteele13}{2}, for a similar sentiment
  see \scite{8}{kaplan10}{44}.)
\end{quotex}

The development of representation theorems beginning with Frank Ramsey
(followed by increasingly more compelling representation theorems in
\scite{7}{savage54}{}; and \scite{7}{jeffrey65}{}; and numerous other
variants in contemporary literature) bases probability and utility
functions of an agent on her preferences, not the other way around.
Once completeness as an axiom for the preferences of an agent is
jettisoned, indeterminacy follows automatically. Indeterminacy may
thus be a natural consequence of the proper way to think about
credences in terms of the preferences that they represent.

In response, preferences may very well logically and psychologically
precede an agent's probability and utility functions, but that does
not mean that we cannot inform the axioms we use for a rational
agent's preferences by undesirable consequences downstream.
Completeness may sound like an unreasonable imposition at the outset,
but if incompleteness has unwelcome consequences for credences
downstream, it is not illegitimate to revisit the issue. Timothy
Williamson goes through this exercise with vague concepts, showing
that all upstream logical solutions to the problem fail and that it
has to be solved downstream with an epistemic solution (see
\scite{7}{williamson96}{}). Vague concepts, like sharp credences, are
sharply bounded, but not in a way that is luminous to the agent (for
anti-luminosity see chapter 4 in \scite{7}{williamson00}{}).
Anti-luminosity answers the second question in example
\ref{ex:preccre}: the rational agent prefers the $52.9$ cent bet on
rain to a $47.1$ cent bet on no rain based on her sharp credence
without being in a position to have this preference necessarily or
have it based on physical or psychological ability (for the analogous
claim about knowledge see \scite{8}{williamson00}{95}).

In a way, advocates of indeterminacy have solved this problem for us.
There is strong agreement among most of them that the issue of
determinacy for credences is not an issue of elicitation (sometimes
the term \qnull{indeterminacy} is used instead of \qnull{imprecision}
to underline this difference; see \scite{8}{levi85}{395}). The appeal
of preferences is that we can elicit them more easily than assessments
of probability and utility functions. The indeterminacy issue has been
raised to the probability level (or moved downstream) by indeterminacy
advocates themselves who feel justifiably uncomfortable with an
interpretation of their theory in behaviourist terms. So it shall be
solved there, and this paper makes an appeal to reject indeterminacy
on this level. The solution then has to be carried upstream (or
lowered to the logically more basic level of preferences), where we
recognize that completeness for preferences is after all a desirable
axiom for rationality and \qeins{perfectly rational agents always have
  perfectly sharp probabilities} \scite{2}{elga10}{1}. When Levi talks
about indeterminacy, it also proceeds from the level of probability
judgment to preferences, not the other way around (see
\scite{8}{levi81}{533}).

\begin{quotex}
  \beispiel{Monkey-Filled Urns}\label{ex:monkey} Let urn $A$ contain 4
  balls, two red and two yellow. A monkey randomly fills urn $B$ from
  urn $A$ with two balls. We draw from urn $B$ (a precursor to this
  example is in \scite{8}{jaynesbretthorst03}{160}).
\end{quotex}

The sharp credence of drawing a red ball is $0.5$, following Lewis'
summation formula for the different combinations of balls in urn $B$.
This solution is more intuitive in terms of further inference,
decision making, and betting behaviour than a credal state of
$\{0,1/2,1\}$ or $[0,1]$ (depending on the convexity requirement),
since this instate would licence an exorbitant bet in favour of one
colour, for example one that costs \$9,999 and pays \$10,000 if red is
drawn and nothing if yellow is drawn. 

How a bet is licenced is different on various Boolean accounts.
Rinard, for example, contrasts a moderate account with a liberal
account (see \scite{8}{rinard15}{7}). According to the liberal
account, the \$9,999 bet is licenced, whereas according to the
moderate account, it is only indeterminate whether the bet is
licenced. The moderate account does not take away from the force of
example \ref{ex:monkey}, where it should be determinate that a \$9,999
bet is not licenced.

To make example \ref{ex:monkey} more vivid consider a Hand Urn, where
you draw by hand from an urn with 100 balls, 50 red balls and 50
yellow balls. When your hand retreats from the urn, does it not
contain either a red ball or a yellow ball and so serve itself as an
urn, from which in a sense you draw a ball? Your hand contains one
ball, either red or yellow, and the indeterminate credal state that it
is one or the other should be $[0,1]$. This contradicts our intuition
that our credence should be a sharp $0.5$ and raises again the mode of
representation issue, as in \textsc{retention}. Sharp credences are
more resistent to partition variance when the partition is along lines
that appear irrelevant to the question (such as symbols on pieces of
chocolate as in example \ref{ex:chocolates} or how a ball is retrieved
from an urn as in example \ref{ex:monkey}).

\begin{quotex}
  \beispiel{Three Prisoners}\label{ex:threepris} Prisoner $X_{1}$
  knows that two out of three prisoners ($X_{1},X_{2},X_{3}$) will be
  executed and one of them pardoned. She asks the warden of the prison
  to tell her the name of another prisoner who will be executed,
  hoping to gain knowledge about her own fate. When the warden tells
  her that $X_{3}$ will be executed, $X_{1}$ erroneously updates her
  probability of pardon from $1/3$ to $1/2$, since either $X_{1}$ or
  $X_{2}$ will be spared.
\end{quotex}

Walley maintains that for the Monty Hall problem and the Three
Prisoners problem, the probabilities of a rational agent should dilate
rather than settle on the commonly accepted solutions. For the Three
Prisoners problem, there is a compelling case for standard
conditioning and the result that the credence for prisoner $X_{1}$ to
receive a pardon ought not to change after the update (see
\scite{8}{lukits14}{1421f}). Walley's dilated solution would give
prisoner $X_{1}$ hope on the doubtful possibility (and unfounded
assumption) that the warden might prefer to provide $X_{3}$'s (rather
than $X_{2}$'s) name in case prisoner $X_{1}$ was pardoned.

This example brings an interesting issue to the forefront. Sharp
credences often reflect independence of variables where such
independence is unwarranted. Booleans (more specifically, detractors
of the principle of indifference or the principle of maximum entropy,
principles which are used to generate sharp credences for rational
agents) tend to point this out gleefully. They prefer to dilate over
the possible dependence relationships, independence included. Dilation
in example \ref{ex:dilation} is an instance of this. The fallacy in
the argument for instates, illustrated by the Three Prisoners problem,
is that the probabilistic independence of sharp credences does not
imply independence of variables. Only the converse is correct.
Probabilistic independence may simply reflect an averaging process
over various dependence relationships, independence again included.

In the Three Prisoners problem, there is no evidence about the degree
or the direction of the dependence, and so prisoner $X_{1}$ should
take no comfort in the information that she receives. The rational
prisoner's probabilities will reflect probabilistic independence, but
make no claims about causal independence. Walley has unkind things to
say about sharp credences and their ability to respond to evidence
(for example that their \qeins{inferences rarely conform to evidence},
see \scite{8}{walley91}{396}), but in this case it appears to me that
they outperform the Boolean approach.\mcut{2}

Joyce also commits himself to dilation for the Three Prisoners problem
and would thus have to call the conventional solution defective
epistemology (see \scite{8}{joyce10}{292}), for in the comparable case
of example \ref{ex:dilation} he states that \qeins{behaving as if
  these two events are independent amounts to pulling a statistical
  correlation out of thin air!} \scite{3}{joyce10}{300} The two events
in question are $H_{\mbox{\tiny{iv}}}$ and
$H_{\mbox{\tiny{iv}}}\equiv{}H_{\mbox{\tiny{v}}}$ in example
\ref{ex:dilation}, but they could just as well be \qnull{$X_{1}$ will
  be executed} and \qnull{warden says $X_{3}$ will be executed} in
example \ref{ex:threepris}.

To conclude, a Boolean in the light of Joyce's two Augustinian
concessions has three alternatives, of which I favour the third: (a)
to find fault with Joyce's reasoning as he makes those concessions;
(b) to think (as Joyce presumably does) that the concessions are
compatible with the promises of Booleans, such as \textsc{intern},
\textsc{incomp}, and \textsc{inform}, to solve prima facie problems of
sharp credences; or (c) to abandon the Boolean position because (AC1),
(AC2), and an array of examples in which sharp credences are
conceptually and pragmatically more appealing show that the initial
promise of the Boolean position is not fulfilled.

% \nocite{*} 
\bibliographystyle{ChicagoReedweb} 
\bibliography{bib-7293}

\end{document} 
