\documentclass[xcolor=dvipsnames]{beamer}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{colortbl}
\definecolor{myblue}{rgb}{0.8,0.85,1}

\mode<presentation>
{
  \usetheme{Warsaw}
  \setbeamercovered{transparent}
}
% \usecolortheme[named=OliveGreen]{structure}
\setbeamertemplate{navigation symbols}{} 
\setbeamertemplate{blocks}[rounded][shadow=true] 

\title{Asymmetry and the Geometry of Reason}
\subtitle{Causal and Probabilistic Reasoning Conference, LMU M{\"u}nchen}

\author{Stefan Lukits}

\date{June 19, 2015}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Epistemic Utility Approach to Justification}
  \begin{figure}[h]
    \includegraphics[scale=.6]{./epvspr.eps}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Geometry of Reason vs. Information Theory I}
  \begin{itemize}
  \item \emph{Geometry of Reason:} topology of the probability space is
    metric. A symmetric distance measure is used (Euclidean).
  \end{itemize}
\begin{equation}
  \label{eq:e3}
  \|u-v\|=\sqrt{\sum_{i=1}^{n}\left(u_{i}-v_{i}\right)^{2}}.
\end{equation}
  \begin{itemize}
  \item \emph{Information Theory:} topology of the probability space is not a
    metric. An asymmetric divergence measure is used (Kullback-Leibler).
  \end{itemize}
\begin{equation}
  \label{eq:e7}
  D_{\mbox{\tiny KL}}(u,v)=\sum_{i=1}^{3}u_{i}\ln\frac{u_{i}}{v_{i}}
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{Geometry of Reason vs. Information Theory II}
  \begin{figure}[h]
    \includegraphics[scale=.6]{./contourslp.eps}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Geometry of Reason vs. Information Theory III}
  \begin{figure}[h]
    \includegraphics[scale=.6]{./crj.eps}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Weak Convexity and Symmetry}
Here are two axioms for inaccuracy measures which use the language of
the Geometry of Reason (Joyce):
\begin{description}
\item[Weak Convexity] Let $m=(0.5b'+0.5b'')$ be the midpoint of the line
  segment between $b'$ and $b''$. If $I(b',\omega)=I(b'',\omega)$,
  then it will always be the case that $I(b',\omega)\geq{}I(m,\omega)$
  with identity only if $b'=b''$.
\item[Symmetry] If $I(b',\omega)=I(b'',\omega)$, then for any
  $\lambda\in{}[0,1]$ one has\newline
  $I(\lambda{}b'+(1-\lambda)b'',\omega)=I((1-\lambda){}b'+\lambda{}b''),\omega)$.
\end{description}
\end{frame}

\begin{frame}
  \frametitle{Local and Global Inaccuracy}
\emph{Expected local inaccuracy} of degree of belief $x$ in proposition $A$
by the lights of belief function $b$ with respect to local
inaccuracy measure $I$ and over the set $E$ of epistemically
possible worlds:

\begin{equation}
  \label{eq:eli}
  \mbox{LExp}_{b}(I,A,E,x)=\sum_{w\in{}E}b(\{w\})I(A,w,x)=\sum_{w\in{}E}b(\{w\})\lambda\left(\chi_{A}(w)-x\right)^{2}.
\end{equation}

\emph{Expected global inaccuracy} of belief function $b'$ by the lights of
belief function $b$ with respect to global inaccuracy measure $G$
and over the set $E$ of epistemically possible worlds:

\begin{equation}
  \label{eq:egi}
  \mbox{GExp}_{b}(G,E,b')=\sum_{w\in{}E}b(\{w\})G(w,b')=\sum_{w\in{}E}b(\{w\})\mu\|w-b\|^{2}.
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{Standard Conditioning, Jeffrey and LP Conditioning}
  \begin{figure}[h]
    \includegraphics[scale=.5]{./sjlp}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Jeffrey Type Updating Scenario: Priors}
  \begin{figure}[h]
    \includegraphics[scale=.4]{./j1.jpg}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Jeffrey Type Updating Scenario: Jeffrey Posteriors}
  \begin{figure}[h]
    \includegraphics[scale=.4]{./j2.jpg}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Jeffrey Type Updating Scenario: LP Posteriors}
  \begin{figure}[h]
    \includegraphics[scale=.4]{./j3.jpg}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Euclid and Kullback-Leibler}
  \begin{figure}[h]
    \includegraphics[scale=.6]{./threepoints.eps}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Five Plausible Expectations for an Amujus}
\begin{itemize}
\item \textsc{continuity} An amujus ought to be continuous with
  standard conditioning as a limiting case.
\item \textsc{invariance} An amujus ought to be partition invariant.
\item \textsc{levinstein} An amujus ought not to give ``extremely
    unattractive'' results in a Levinstein scenario
\item \textsc{regularity} An amujus ought not to assign a posterior
  probability of $0$ to an event which has a positive prior
  probability and about which the intervening evidence says nothing
  except that a strictly weaker event has a positive posterior
  probability.
\item \textsc{asymmetry} An amujus ought to reflect epistemic
  asymmetries.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Continuity Violation I}
To illustrate a \textsc{continuity} violation, consider the case where
Sherlock Holmes reduces his credence that the culprit was male to
$\varepsilon_{n}=1/n$ for $n=4,5,\ldots$
\end{frame}

\begin{frame}
  \frametitle{Continuity Violation II}
Straightforward conditionalization on the evidence that ``the
  culprit is female'' gives us 

\begin{equation}
  \label{eq:sherlockcontsc}
  \begin{array}{rcl}
  P'_{\mbox{\tiny SC}}(E_{1})&=&0\\
  P'_{\mbox{\tiny SC}}(E_{2})&=&3/4\\
  P'_{\mbox{\tiny SC}}(E_{3})&=&1/4.
\end{array}
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{Continuity Violation III}
Letting $n\rightarrow\infty$ for Jeffrey conditioning yields

\begin{equation}
  \label{eq:sherlockcontjc}
  \begin{array}{rcccl}
  P'_{\mbox{\tiny JC}}(E_{1})&=&1/n&\rightarrow&0\\
  P'_{\mbox{\tiny JC}}(E_{2})&=&3(n-1)/4n&\rightarrow&3/4\\
  P'_{\mbox{\tiny JC}}(E_{3})&=&(n-1)/4n&\rightarrow&1/4,
\end{array}
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{Continuity Violation IV}
Letting $n\rightarrow\infty$ for LP conditioning yields

\begin{equation}
  \label{eq:sherlockcontlp}
  \begin{array}{rcccl}
  P'_{\mbox{\tiny LP}}(E_{1})&=&1/n&\rightarrow&0\\
  P'_{\mbox{\tiny LP}}(E_{2})&=&(4n-1)/6n&\rightarrow&2/3\\
  P'_{\mbox{\tiny LP}}(E_{3})&=&(2n-1)/6n&\rightarrow&1/3.
\end{array}
\end{equation}

LP conditioning violates \textsc{continuity}.
\end{frame}

\begin{frame}
  \frametitle{Invariance Violation I}
Consider the Sherlock Holmes scenario with the relatively prior
probabilities in (\ref{eq:priors}). Jane Marple is on the same case
and arrives at the same relatively prior probability distribution as
Sherlock Holmes (we will call Jane Marple's relatively prior
probability distribution $Q$ and her posterior probability
distribution $Q'$). Jane Marple, however, has a more fine-grained
probability assignment than Sherlock Holmes and distinguishes between
the case where Ms.\ S went to boarding school with her, of which she
has a vague memory, and the case where Ms.\ S did not and the vague
memory is only about a fleeting resemblance of Ms.\ S with another
boarding school mate.
\end{frame}

\begin{frame}
  \frametitle{End of Presentation}
Thank you for your attention.
\end{frame}

\end{document}