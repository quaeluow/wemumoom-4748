Given a set of probabilities on an event space and a new observation, it is common to form updated probabilities by using rules of conditioning. Some observations pose constraints that cannot be addressed by standard conditional probabilities or Jeffrey conditioning. The principle of maximum entropy (abbreviated maxent) claims that it is then appropriate to form an updated probability assessment by minimizing information gain consistent with the observation. Opposition to the maxent leans heavily on one counterexample: the Judy Benjamin problem. This article shows that an intuitively plausible approach that should support the opponents' case turns out to support the maxent. It becomes apparent that the opponents improperly apply independence assumptions to the problem.
