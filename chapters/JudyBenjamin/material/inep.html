<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
lang="en" xml:lang="en">
<head>
<title>inep</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2012-02-29 13:26:34 PST"/>
<meta name="author" content="U-VCC\stlukits"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">

<h1 class="title">inep</h1>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 current </a>
<ul>
<li><a href="#sec-1.1">1.1 quotes </a>
<ul>
<li><a href="#sec-1.1.1">1.1.1 Gr"unwald and Halpern: Updating Probabilities </a></li>
<li><a href="#sec-1.1.2">1.1.2 Recall that Bayes assumed a condition of complete </a></li>
<li><a href="#sec-1.1.3">1.1.3 The copy principle (Hume) </a></li>
</ul>
</li>
<li><a href="#sec-1.2">1.2 ideas </a>
<ul>
<li><a href="#sec-1.2.1">1.2.1 lottery </a></li>
<li><a href="#sec-1.2.2">1.2.2 lottery texted </a></li>
<li><a href="#sec-1.2.3">1.2.3 for Donat Berghuber, who </a></li>
<li><a href="#sec-1.2.4">1.2.4 probability kinematics and ethics </a></li>
<li><a href="#sec-1.2.5">1.2.5 ranking functions </a></li>
<li><a href="#sec-1.2.6">1.2.6 kickstart </a></li>
<li><a href="#sec-1.2.7">1.2.7 information, and only information, can </a></li>
</ul>
</li>
<li><a href="#sec-1.3">1.3 roadmap </a>
<ul>
<li><a href="#sec-1.3.1">1.3.1 read Giffin and Caticha's work </a></li>
<li><a href="#sec-1.3.2">1.3.2 read MaxEnt conference proceedings </a></li>
<li><a href="#sec-1.3.3">1.3.3 think about information and Carnap </a></li>
<li><a href="#sec-1.3.4">1.3.4 read information textbook (Raymond Yeung) </a></li>
<li><a href="#sec-1.3.5">1.3.5 read 1953_<sub>Bar</sub><sub>Hillel</sub><sub>Carnap</sub>_<sub>Semantic</sub><sub>Information</sub>.pdf </a></li>
<li><a href="#sec-1.3.6">1.3.6 find out whats been written on Information and Philosophy in the last five years </a></li>
</ul>
</li>
<li><a href="#sec-1.4">1.4 external comments </a>
<ul>
<li><a href="#sec-1.4.1">1.4.1 Paul Bartha </a></li>
<li><a href="#sec-1.4.2">1.4.2 Jan-Willem Romeijn </a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-2">2 before february 2012 </a>
<ul>
<li><a href="#sec-2.1">2.1 Zillner map </a></li>
<li><a href="#sec-2.2">2.2 quotes </a>
<ul>
<li><a href="#sec-2.2.1">2.2.1 Colin Howson and Allan Franklin </a></li>
<li><a href="#sec-2.2.2">2.2.2 Igor Douven and Jan-Willem Romeijn </a></li>
<li><a href="#sec-2.2.3">2.2.3 Jon Williamson </a></li>
<li><a href="#sec-2.2.4">2.2.4 Williams, Peter </a></li>
<li><a href="#sec-2.2.5">2.2.5 Uffink, Jos </a></li>
<li><a href="#sec-2.2.6">2.2.6 Diaconis and Zabell </a></li>
<li><a href="#sec-2.2.7">2.2.7 Fraassen, Hughes, Harman </a></li>
<li><a href="#sec-2.2.8">2.2.8 Seidenfeld, Teddy </a></li>
<li><a href="#sec-2.2.9">2.2.9 Aristotle </a></li>
<li><a href="#sec-2.2.10">2.2.10 Avenarius, Richard </a></li>
<li><a href="#sec-2.2.11">2.2.11 Bar-Hillel, Yehoshua, and Carnap, Rudolf </a></li>
<li><a href="#sec-2.2.12">2.2.12 Burgin, Mark </a></li>
<li><a href="#sec-2.2.13">2.2.13 Chalmers, David </a></li>
<li><a href="#sec-2.2.14">2.2.14 Halpern, Joseph </a></li>
<li><a href="#sec-2.2.15">2.2.15 Mach, Ernst </a></li>
<li><a href="#sec-2.2.16">2.2.16 Quine, WVO </a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-3">3 before fall 2010 </a>
<ul>
<li><a href="#sec-3.1">3.1 aufbau </a></li>
<li><a href="#sec-3.2">3.2 quotes </a>
<ul>
<li><a href="#sec-3.2.1">3.2.1 ingardenurbanik62 </a></li>
<li><a href="#sec-3.2.2">3.2.2 bernardo79 </a></li>
<li><a href="#sec-3.2.3">3.2.3 clarkebarron90 </a></li>
<li><a href="#sec-3.2.4">3.2.4 goguen97 </a></li>
<li><a href="#sec-3.2.5">3.2.5 guiasu77 </a></li>
<li><a href="#sec-3.2.6">3.2.6 hjorland07 </a></li>
<li><a href="#sec-3.2.7">3.2.7 jaynes57 </a></li>
<li><a href="#sec-3.2.8">3.2.8 khinchin57 </a></li>
<li><a href="#sec-3.2.9">3.2.9 kolmogorov68 </a></li>
<li><a href="#sec-3.2.10">3.2.10 kolmogorov68a </a></li>
<li><a href="#sec-3.2.11">3.2.11 loeve55 </a></li>
<li><a href="#sec-3.2.12">3.2.12 solomonov64 </a></li>
<li><a href="#sec-3.2.13">3.2.13 turing37 </a></li>
<li><a href="#sec-3.2.14">3.2.14 wallacedowe99 </a></li>
<li><a href="#sec-3.2.15">3.2.15 zhulu04 </a></li>
</ul>
</li>
<li><a href="#sec-3.3">3.3 links </a>
<ul>
<li><a href="#sec-3.3.1">3.3.1 information theory </a></li>
</ul>
</li>
<li><a href="#sec-3.4">3.4 ideas </a>
<ul>
<li><a href="#sec-3.4.1">3.4.1 information epistemology is an </a></li>
<li><a href="#sec-3.4.2">3.4.2 Kolmogorov's frustration with probability theory comes </a></li>
<li><a href="#sec-3.4.3">3.4.3 math results </a></li>
<li><a href="#sec-3.4.4">3.4.4 philsophical musings </a></li>
<li><a href="#sec-3.4.5">3.4.5 there is also a convergence between physics and epistemology </a></li>
<li><a href="#sec-3.4.6">3.4.6 is there a Dutch-book equivalent for </a></li>
<li><a href="#sec-3.4.7">3.4.7 experimental design </a></li>
<li><a href="#sec-3.4.8">3.4.8 perl zipping program </a></li>
<li><a href="#sec-3.4.9">3.4.9 Model-Fitting </a></li>
<li><a href="#sec-3.4.10">3.4.10 Minimum message length (MML) is a formal information theory </a></li>
<li><a href="#sec-3.4.11">3.4.11 The idea of Kullback–Leibler divergence as discrimination information </a></li>
<li><a href="#sec-3.4.12">3.4.12 Solomonoff, who focused on prediction using his invention of </a></li>
<li><a href="#sec-3.4.13">3.4.13 Incomputability of Kolmogorov complexity </a></li>
<li><a href="#sec-3.4.14">3.4.14 Chaitin's incompleteness theorem </a></li>
<li><a href="#sec-3.4.15">3.4.15 in algorithmic information theory, the invariance theorem, originally proved by </a></li>
<li><a href="#sec-3.4.16">3.4.16 Gettier cases </a></li>
<li><a href="#sec-3.4.17">3.4.17 Mutual information can be expressed as the average Kullback–Leibler divergence </a></li>
<li><a href="#sec-3.4.18">3.4.18 information density </a></li>
<li><a href="#sec-3.4.19">3.4.19 What matters is belief revision, not knowledge </a></li>
<li><a href="#sec-3.4.20">3.4.20 Quantitative Bayesian belief analysis is </a></li>
<li><a href="#sec-3.4.21">3.4.21 diachronische vernetztheit, eigenheit of the world, evidence.org </a></li>
<li><a href="#sec-3.4.22">3.4.22 rephrase Leibniz: Why is there something and not rather nothing? Why is </a></li>
<li><a href="#sec-3.4.23">3.4.23 defining the size of objects by their complexity </a></li>
<li><a href="#sec-3.4.24">3.4.24 Information is directly related to </a></li>
<li><a href="#sec-3.4.25">3.4.25 I dedicate this paper to X whose </a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> current </h2>
<div class="outline-text-2" id="text-1">


</div>

<div id="outline-container-1.1" class="outline-3">
<h3 id="sec-1.1"><span class="section-number-3">1.1</span> quotes </h3>
<div class="outline-text-3" id="text-1.1">


</div>

<div id="outline-container-1.1.1" class="outline-4">
<h4 id="sec-1.1.1"><span class="section-number-4">1.1.1</span> Gr"unwald and Halpern: Updating Probabilities </h4>
<div class="outline-text-4" id="text-1.1.1">

<ul>
<li id="sec-1.1.1.1">There exist some very simple setting in which <br/>
MRE essentially never gives the right results. (Gr"unwald and Halpern:
Updating Probabilities, 243)
</li>
<li id="sec-1.1.1.2">Example 1.3 provides some motivation for working in <br/>
the smaller, more naive space. Examples 1.1 and 1.2 show that this is
not always appropriate. Thus, an obvious question is when it is
appropriate. (Gr"unwald and Halpern: Updating Probabilities, 245)
</li>
<li id="sec-1.1.1.3">There are situations where applying MRE leads to <br/>
paradoxical, highly counter-intuitive results (Gr"unwald and Halpern:
Updating Probabilities, 245)
</li>
<li id="sec-1.1.1.4">Seidenfeld (1986), strengthening results of <br/>
Friedman and Shimony (1971), show that there is &lt;i&gt;no&lt;/i&gt;
sophisticated space in which conditioning will give the same answer as
MRE in this case. (See also (Dawid, 2001), for similar results along
these lines.) (Gr"unwald and Halpern: Updating Probabilities, 246)
</li>
<li id="sec-1.1.1.5">Working with the naive space, while an attractive <br/>
approach, is likely to give highly misleading answers. That is the
main message of this paper. (Gr"unwald and Halpern: Updating
Probabilities, 246)
</li>
<li id="sec-1.1.1.6">We show that Jeffrey conditioning in the naive space <br/>
gives the appropriate answers iff a generalized CAR condition holds.
We then show that, typically, applying MRE in the naive space does not
give the appropriate answer. (Gr"unwald and Halpern: Updating
Probabilities, 246)
</li>
<li id="sec-1.1.1.7">While in these cases the sophisticated space is still <br/>
relatively simple, this is no longer the case for the Judy Benjamin
puzzle. (Gr"unwald and Halpern: Updating Probabilities, 247)
</li>
<li id="sec-1.1.1.8">In some cases of interest, CAR is (roughly speaking) guaranteed <br/>
&lt;i&gt;not&lt;/i&gt; to hold except in ``degenerate'' situations. (Gr"unwald and
Halpern: Updating Probabilities, 251)
</li>
<li id="sec-1.1.1.9">Seidenfeld shows that, under very weak conditions, MRE cannot <br/>
coincide with sophisticated conditioning if the observations have the
form ``the conditional probability of $U$ given $V$ is $&alpha;$'' (as
is the case in the Judy Benjamin problem). (Gr"unwald and Halpern:
Updating Probabilities, 263)
</li>
<li id="sec-1.1.1.10">[Useful summary in table form] <br/>
(Gr"unwald and Halpern: Updating Probabilities, 264)
</li>
<li id="sec-1.1.1.11">We show that the CAR framework can be used as a general <br/>
tool to clarify many of the well-known paradoxes of conditional
probability; &hellip; no CAR-like condition can hold in general for cases
where only MRE (and not Jeffrey) updating can be applied &hellip; MRE
updating is not always so bad (Gr"unwald and Halpern: Updating
Probabilities, 264)
</li>
</ul>
</div>

</div>

<div id="outline-container-1.1.2" class="outline-4">
<h4 id="sec-1.1.2"><span class="section-number-4">1.1.2</span> Recall that Bayes assumed a condition of complete </h4>
<div class="outline-text-4" id="text-1.1.2">

<p>ignorance regarding the unknown event. If we ignore the potential
ambiguities in this notion, the point is that such a condition will be
realized only in never-never-land Bayesianism, where an agent begins
as a tabula rasa, chooses her priors, and forever after changes her
probabilities only by conditionalization. A more realistic Bayesianism
would recognize the local and episodic character of problem solving.
In Bayesian terms, we use different probability functions for
different problem-solving contexts, and within a context we may change
probabilities not by conditionalization but by some more radical
means. Thus, far from being a tabula rasa, the typical scientist comes
burdened with a wealth of information in trying to make what the
Bayesian would describe as decisions about prior probabilities. E.T.
Jaynes's modern version of the principle of indifference tries to take
into account some of this information, since it enjoins us to maximize
a quantity he calls ``entropy'' subject to known constraints that can
be expressed in terms of moments of the probability distribution. But
only a small part of information can be expressed in these terms.
(1992_<sub>John</sub><sub>Earman</sub>_<sub>Bayes</sub><sub>or</sub><sub>Bust</sub>, 139f)
</p></div>

</div>

<div id="outline-container-1.1.3" class="outline-4">
<h4 id="sec-1.1.3"><span class="section-number-4">1.1.3</span> The copy principle (Hume) </h4>
<div class="outline-text-4" id="text-1.1.3">

<p>Information. Numbers. Is information, and subsequently numbers, a
consequence of our excessive success in copying, or the origin? Names
are more like numbers than they are like words. They falsify
Nietzsche's claim in Truth and Lies that nothing is really identical
or the same, that all identity is fiction.
</p></div>
</div>

</div>

<div id="outline-container-1.2" class="outline-3">
<h3 id="sec-1.2"><span class="section-number-3">1.2</span> ideas </h3>
<div class="outline-text-3" id="text-1.2">


</div>

<div id="outline-container-1.2.1" class="outline-4">
<h4 id="sec-1.2.1"><span class="section-number-4">1.2.1</span> lottery </h4>
<div class="outline-text-4" id="text-1.2.1">

<p>scenario I: information is about Y's decreased odds
(* (/ 1 (+ 999 (/ 1 1000.0))) (/ 1 1000.0))
1.0009999989990002e-06
(* (/ 1 (+ 999 (/ 1 1000.0))))
0.001000999998999
</p>

<p>
scenario II: information is about X and Y's odds, but independent of Z's odds
(/ 2 1001.0)
0.001998001998001998
</p>
<p>
(/ 1 1999.0)
0.0005002501250625312
</p>

<p>
beta = minus &lambda;<sub>1</sub> = (/ (log 1000.0) -1001)
0.006900854424557579
</p>
<p>
&lambda;<sub>0</sub> = (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998))))
-5.906762718201527
</p>
<p>
P(&alpha;<sub>0</sub>) = (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (/ (log 1000.0) 1001)))
0.0010079246503368348
</p>
<p>
P(&alpha;<sub>1</sub>) = (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (* -1000 (/ (log 1000.0) 1001))))
1.007924650336835e-06
</p>
<p>
P(&alpha;<sub>n</sub>) for n=2..999 = (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1))
0.0010009930535320765
</p>
<p>
(+ (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (/ (log 1000.0) 1001))) (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (* -1000 (/ (log 1000.0) 1001)))) (* 998 (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1))))
0.9999999999999994
</p>
<p>
(/ (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (/ (log 1000.0) 1001))) (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (* -1000 (/ (log 1000.0) 1001)))))
999.9999999999999
</p>
<p>
(/ (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp
(* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (/ (log 1000.0) 1001))) (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1)))
1.006924720186918
</p>
<p>
(/ (- (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1 (/ (log 1000.0) 1001))) .001) (/ (- (exp (+ (+ 1 (* -1 (log (+ (exp (* -1 (/ (log 1000.0) -1001))) (exp (* 1000 (/ (log 1000.0) -1001))) 998)))) -1)) .001) 998))
7964.123565044741
</p>
<p>
(/ (- 0.0010079246503368348 .001) (- 0.0010009930535320765 .001))
7.980083732509759
</p>


<p>
A lottery with 1000 tickets, your ticket is #0, my ticket is #1. We
receive reliable information that your ticket is a thousand times more
likely to win than my ticket. Originally, the chance to win was 1
promille. Now it is, according to Jaynes,
</p>
<p>
P(&alpha;<sub>0</sub>)=1.007925 promille
P(&alpha;<sub>1</sub>)=0.001008 promille
P(&alpha;<sub>n</sub>)=1.000993 promille
</p>
<p>
Here is what's interesting: call A1's promille P &ndash; who gets P? A1 loses almost all of it, only gets 1/1000 of it. But A0 doesn't get much of it either, only 8/1000. The remaining 991/1000 are distributed among A2 to A999. In fact, despite the promising announcement ``You are 1000 times more likely to win than your neighbour'' your odds compared to another neighbour have improved only by 0.69 percent. If you had received (almost) all of P (a Douven Romeijn scenario), your chances would be almost double that of anybody else. As it is, A0 only gets 8 times more than the other neighbours off of P.
</p></div>

</div>

<div id="outline-container-1.2.2" class="outline-4">
<h4 id="sec-1.2.2"><span class="section-number-4">1.2.2</span> lottery texted </h4>
<div class="outline-text-4" id="text-1.2.2">

<p>Consider a 1000 ticket lottery to demonstrate the role of epistemic
entrenchment. There will be one winner. You receive the information
that ticket holder X's ticket is 1000 times more likely to win than
ticket holder Y's ticket. You consider this information completely
reliable, but you have no idea what the reasons behind it are. The
reasons may have nothing to do with X's increased odds, but only with
Y's decreased odds. Y's original 1/10th percent chance to win should
be evenly distributed amongst all others (leaving enough for Y to have
1/1000th of the chance to win as everybody else, including X).
Alternatively, X may have claim to all the spoils coming from Y's
1/10th percent: then everybody will stay at odds of 1/10th of a
percent except X, who will have almost 2/10ths, and Y, who will have
1/1000th of that. \textsc{maxent} sides largely with the first
scenario, approximately handing Y 1/1000th of the original 1/10th
percent that was Y's, X 8/1000th of Y's original 1/10th percent, and
everybody else 991/1000th of Y's original 1/10th percent. X gains
little compared to everyone else. This example lends support to Douven
and Romeijn's argument: \textsc{maxent} appears to commit itself to
something that is better left in the hands of an epistemic
entrenchment. On the other hand, however, maxent does give X eight
times more of the pie than everyone else.}
</p></div>

</div>

<div id="outline-container-1.2.3" class="outline-4">
<h4 id="sec-1.2.3"><span class="section-number-4">1.2.3</span> for Donat Berghuber, who </h4>
<div class="outline-text-4" id="text-1.2.3">

<p>taught me .975 of this stuff.
</p></div>

</div>

<div id="outline-container-1.2.4" class="outline-4">
<h4 id="sec-1.2.4"><span class="section-number-4">1.2.4</span> probability kinematics and ethics </h4>
<div class="outline-text-4" id="text-1.2.4">

<p>Probability kinematics resembles ethics in the sense that there are
all kinds of things we are able to say about the relations between our
intuitions and the prescriptions or rules we propose. We never cease
to be vulnerable, however, to the question why the states of affairs
we describe should entail that we have one set of probability
assignments and updating strategies and not another. That an
observation or a piece of evidence should change our assessment of
uncertainty with respect to relevant propositions and events in
particular ways cannot be a matter of logical consistency. Even a
Dutch Book argument rests on assumptions that are entangled with the
relations and intuitions we are supposed to explain. Our task in this
paper, then, is to show what were to flow from certain assumptions
being made and certain intuitions being accepted, and to articulate
them clearly and well so that we understand where they are reasonable,
arbitrary, or subject to criticism. In all this, we never lose a sense
of need for what ethicists in Rawl's tradition call a reflective
equilibrium, as it is not the intuitions about particular cases alone,
nor the general judgments they sometimes inspire, that carry away the
prize, but rather a balance between them. The principle of maximum
entropy is a poster child for this method: it is a principle with
great generality and scope, arguably outperforming all others, but it
also raises worries in particular cases. There is beauty in the fact
that, as sweeping as the principle is, it cannot accommodate
everything we think and feel about how conditionalization (another
term for probability update) should proceed. This paper cautions,
however, against undue enthusiasm about the full employment theorem,
the view that ultimately all rules and methods of conditionalization
are tools in the hand of a human inquirer, expressing that which one
to use must always be based on the intuitive and creative labour of
the user. Probability kinematics is not a sit-down dinner: various
approaches mingle, easily shift positions, and have access to the
buffet table from different angles. There is no throne even for the
view that, when all is said and done, a special place remains for the
art of human inquiry.
</p></div>

</div>

<div id="outline-container-1.2.5" class="outline-4">
<h4 id="sec-1.2.5"><span class="section-number-4">1.2.5</span> ranking functions </h4>
<div class="outline-text-4" id="text-1.2.5">

<p>Hi Stefan,
</p>
<p>
Lots to say here.
</p>
<p>
'Tis true &ndash; the relationship between ranking functions and information. One could say, I suppose, that if it takes n bits of information to make you believe P then the rank of P is n. In a lottery with 1024 tickets it would take 10 bits to identify the winner, so &rho;(P<sub>i</sub>)=10, if P<sub>i</sub> designates that the i-th ticket wins. You would have to change the disjunction rule to
</p>
<p>
(*) &rho;{A&cup; B}=-log<sub>2</sub>(2<sup>-I(A)</sup>+2<sup>-I(B)</sup>) for disjoint A and B
</p>
<p>
&ndash; a formula that has little to recommend it in terms of elegance, but it takes care of the lottery paradox: if A<sub>i</sub> is a disjoint cover of &Omega; then
</p>
<p>
&rho;(&Omega;)=-log<sub>2</sub>(&sum;<sub>i</sub>2<sup>-I(A<sub>i</sub>)</sup>)=0
</p>
<p>
A rigorous proof of this looks like an interesting challenge. I am only assuming this because it works for probabilities of the (1/k)<sup>m</sup> type, thus by ``mathematical analogy''
</p>
<p>
OK &ndash; part of the problem here is interpreting what claims about rank mean. According to the official rank theorists (Spohn, Huber): rank 0 is not "believes", but "does not disbelieve". So, rank 10 means disbelief that is 10 steps away from "does not disbelieve". But the entrenchment interpretation does not always seem to fit with this view about rank 0.
</p>
<p>
Your rule will violate the basic axioms of ranking theory: since &rho;(A &cup; ~A) = 0 = min(&rho;(A), &rho;(~A)), we must have at least one of &rho;(A)=0 or &rho;(~A)=0.
</p>
<p>
[beginning of rabbit trail] besides the examples you provided I was trying to think of cases of analogies in mathematics and couldn't come up with anything interesting, but then I read in my book on topology that I am reading for the Carnap seminar:
</p>
<p>
``This [a claim about manifolds] is a sensible claim because if v were a vector in \mathbold{R}<sup>m</sup> then to express v as a linear combination of the standard basis vector, to find the approximate coefficients we would take the scalar product of v with the standard basis vectors. To verify this claim we must show that &hellip;'' (David Gauld, Differential Topology, page 98)
</p>
<p>
In topology this analogy from n-dimensional Euclidean spaces to manifolds is quite common (and mathematically productive, as nobody can picture general manifolds very well, but we do OK with Euclidean spaces). Topology is to a large degree the discipline that provides theorems delineating when the analogies are valid and when they are not. [end of rabbit trail]
</p>
<p>
An m-manifold is locally like R<sup>m</sup>, for sure. I guess there is an analogical argument here in support of a conjecture about manifolds involving scalar products &ndash; that's pretty cool, since it is being put forward exactly the way I say things run: first the analogy (and with no big fuss about the degree of strength of the analogical argument), and then the need to follow up with a proof. In my chapter on analogies in mathematics, I have a section on "asymptotic analogies" &ndash; those involving limits.
</p>
<p>
As soon as ranking functions are defined by information as outlined above, they could immediately be reduced to probabilities (to the degree to which probabilities and information hang together) &hellip; not what the Baconian modal approach has in mind, I suppose, unless one could find a modal approach to information as well that makes it less of a one-to-one reflection of the corresponding probabilities. Now, I would be VERY interested in how that might work. Perhaps, instead of defining information by the corresponding probabilities, one could define information by ranking functions, as in I(A)=&rho;(A), where we know how A ranks (in terms of plausibility), but not what quantifiable probability it has. Unfortunately, with the disjunction rule (<b>) &rho;(A) would reduce to the Bayesian probability calculus (violating our Baconian intuitions), and without (</b>) (for example, your suggested disjunction rule) information wouldn't do anything for us that we didn't already know about ranking functions &ndash; for example that they don't deal very well with the lottery paradox, or, I suppose, with anything that quantifies nicely probabilistically. Modal plausibilities and Bayesian probabilities appear to live in different kingdoms, not unlike my IT-1 (information theory intimately connected with probability theory) and IT-2 (information theory as it relates to data compression).
</p>
<p>
Stefan
</p>
<p>
Good &ndash; I am wrestling with this too. I thought the idea of "modal information" or "Baconian information" might be interesting to you &ndash; an approach that doesn't mesh with probability, but is independently worthwhile. Spohn thinks that rank is exactly this (though I have not seen him make the connection with information, the 'entrenchment semantics' seems to me to do just that).
</p>
<p>
Ranks don't mesh with probabilities, unless you use the infinitesimal semantics. The theme of the talk was that there really are these two different notions. Yet I refuse to let things stand at that &ndash; there has to be some link. At present, the best I can do is an informal link, interpreting ranks as orders-of-magnitude of probability&hellip;
</p>
<p>
Paul
</p></div>

</div>

<div id="outline-container-1.2.6" class="outline-4">
<h4 id="sec-1.2.6"><span class="section-number-4">1.2.6</span> kickstart </h4>
<div class="outline-text-4" id="text-1.2.6">

<p>We want to (a) know things and (b) come to know things. According to
Bayesian epistemology, knowing things corresponds to being able to
partition epistemic space and evaluating it quantitatively.
This evaluation happens on the basis of evidence, or more basic, on
the basis of information. Use the example of physics:
<a href="http://www.philosophynow.org/issue82/Hawking_contra_Philosophy">http://www.philosophynow.org/issue82/Hawking_contra_Philosophy</a>. Debate
about multiverses. 
</p></div>

</div>

<div id="outline-container-1.2.7" class="outline-4">
<h4 id="sec-1.2.7"><span class="section-number-4">1.2.7</span> information, and only information, can </h4>
<div class="outline-text-4" id="text-1.2.7">

<p>be copied. <span class="timestamp-wrapper"> <span class="timestamp">2011-02-25 Fri</span></span>
</p></div>
</div>

</div>

<div id="outline-container-1.3" class="outline-3">
<h3 id="sec-1.3"><span class="section-number-3">1.3</span> roadmap </h3>
<div class="outline-text-3" id="text-1.3">


</div>

<div id="outline-container-1.3.1" class="outline-4">
<h4 id="sec-1.3.1"><span class="section-number-4">1.3.1</span> read Giffin and Caticha's work </h4>
<div class="outline-text-4" id="text-1.3.1">

</div>

</div>

<div id="outline-container-1.3.2" class="outline-4">
<h4 id="sec-1.3.2"><span class="section-number-4">1.3.2</span> read MaxEnt conference proceedings </h4>
<div class="outline-text-4" id="text-1.3.2">

</div>

</div>

<div id="outline-container-1.3.3" class="outline-4">
<h4 id="sec-1.3.3"><span class="section-number-4">1.3.3</span> think about information and Carnap </h4>
<div class="outline-text-4" id="text-1.3.3">

</div>

</div>

<div id="outline-container-1.3.4" class="outline-4">
<h4 id="sec-1.3.4"><span class="section-number-4">1.3.4</span> read information textbook (Raymond Yeung) </h4>
<div class="outline-text-4" id="text-1.3.4">

</div>

</div>

<div id="outline-container-1.3.5" class="outline-4">
<h4 id="sec-1.3.5"><span class="section-number-4">1.3.5</span> read 1953_<sub>Bar</sub><sub>Hillel</sub><sub>Carnap</sub>_<sub>Semantic</sub><sub>Information</sub>.pdf </h4>
<div class="outline-text-4" id="text-1.3.5">

</div>

</div>

<div id="outline-container-1.3.6" class="outline-4">
<h4 id="sec-1.3.6"><span class="section-number-4">1.3.6</span> find out whats been written on Information and Philosophy in the last five years </h4>
<div class="outline-text-4" id="text-1.3.6">

</div>
</div>

</div>

<div id="outline-container-1.4" class="outline-3">
<h3 id="sec-1.4"><span class="section-number-3">1.4</span> external comments </h3>
<div class="outline-text-3" id="text-1.4">


</div>

<div id="outline-container-1.4.1" class="outline-4">
<h4 id="sec-1.4.1"><span class="section-number-4">1.4.1</span> Paul Bartha </h4>
<div class="outline-text-4" id="text-1.4.1">

<p>Hi Stefan,
</p>
<p>
I think the paper is great!  You might want to submit it for the
upcoming PSA (= Philosophy of Science Association) meeting.  Papers are
due March 1.
</p>
<p>
A couple of suggestions.
</p>
<ol>
<li>
 When you state the intuitions T1 and T2, you should elaborate on
</li>
</ol>

<p>each to give a non-technical appreciation.  So for T2 you could say:
given ~A<sub>1</sub>, conditionalization would imply q<sub>3</sub> = 2/3.  The intuition is
that we should approach this value as we increase P(~A<sub>1</sub> / A<sub>1</sub> v A<sub>2</sub>).
</p>
<ol>
<li>
 Also:  these intuitions, and the discussion of Judy Benjamin, are
</li>
</ol>

<p>already on page 7!  Is there any way you can foreshadow with an informal
insertion of one paragraph in the Introduction, probably between your
current second and third paragraph?  Something like this:
</p>
<p>
"One argument has it that this information, which makes no mention of
Blue territory, does not change the probability that Judy is in Blue
territory.  There is, however, a rival argument.  Suppose the commanders
were to tell Judy that if she is in Red territory, then she is in Red
HQ.  This is the same as simply finding out that she is not in Red 2C,
and ordinary conditionalization tells us that Judy's new probability of
being in Blue territory should be 2/3.  Now &hellip; [etc.]"
</p>
<ol>
<li>
 Perhaps you can give a label to these two intuitions?

</li>
</ol>

<p>I will get to your other questions later, but I just wanted to send an
initial encouraging note.
</p>
<p>
Paul
</p></div>

</div>

<div id="outline-container-1.4.2" class="outline-4">
<h4 id="sec-1.4.2"><span class="section-number-4">1.4.2</span> Jan-Willem Romeijn </h4>
<div class="outline-text-4" id="text-1.4.2">

<p>Dear Stefan,
</p>
<p>
Thanks again for sending me your paper which I read with a lot of
pleasure.
</p>
<p>
I do have a few things to say about it:
</p>
<p>
The parallel you draw to the Carnapian continuum is not quite
correct: his is really not about inference rules. In fact Carnap's
logics are best understood as relying on conditionalisation; see
my paper in the Handbook for the Philosophy of Statistics. You
might argue that Carnap is also worried about epistemic
entrenchments, in which case you'd have to say more about the
parallel than you do now.
</p>
<p>
Igor Douven and I should perhaps have been less emphatic about the
intuitions that drive people's answers to the Judy puzzle. We are
not exactly wedded to the idea that P(Blue) is invariant. Our
point is rather that, whatever your intuitions on that, those
intuitions can be slotted into Jeffrey's rule. In other words, our
arguments do not really hinge on MaxEnt bringing out the wrong
intuition in Judy.
</p>
<p>
As I guess you realise, showing that the result of MaxEnt is
backed by another method does not yet show that MaxEnt is our best
candidate for a universal inference rule. (I would, for example,
not claim that it is "arguably outperforming all others".)
</p>
<p>
I had not seen the powerset approach before and I think it has its
own appeal. But of course there are issues with representing or
portraying MaxEnt as, or at least paralleling it with
conditionalisation, mostly to do with non-conglomerability. I also
urge you to look at Halpern and Grunwald's paper on CAR.
</p>
<p>
Quite apart from that, as you will be aware, the powerset approach
hinges on assuming a particular probability over the sets C that
realise the constraint. You should spend much more time motivating
this assumption, because it drives your result on E[X]. (There is
some irony in the fact that, to defend MaxEnt, you rely on a
method that seems to presuppose a uniform probability over the
C's.)
</p>
<p>
I hope these comments are of help to you and I wish you the best
of luck with the paper!
</p>
<p>
Kind regards,
</p>
<p>
Jan-Willem
</p></div>
</div>
</div>

</div>

<div id="outline-container-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> before february 2012 </h2>
<div class="outline-text-2" id="text-2">


</div>

<div id="outline-container-2.1" class="outline-3">
<h3 id="sec-2.1"><span class="section-number-3">2.1</span> Zillner map </h3>
<div class="outline-text-3" id="text-2.1">

<p>Introduction
Probability Update
The Judy Benjamin Problem
Two Intuitions
Skepticism about maxent
The Full Employment Theorem
Probability Kinematics and Ethics
</p>
<p>
The Judy Benjamin Problem and Its Solutions
Outlining the Problem (diagram already in judy.pdf)
T1 and T2
Jaynes (already done in inep-before-fredericton.tex)
Grove and Halpern
Fraassen, Hughes, and Harman 
FHH's five requirements and three strategies
</p>
<p>
Independence and the Judy Benjamin Problem
Scenarios
Diagrams for unif,maxent, mud, and mtp (see plotq-i1 and plotq-i2)
The Powerset Approach
</p>
<p>
Conclusion
Information processing deficiencies of other approaches, Seidenfeld's Calibration Fallacy
To be done: generalize the powerset approach
Address Shimony's, Uffink's, and Seidenfeld's concerns
Address van Fraassen's MUD
the monopoly argument 
</p></div>

</div>

<div id="outline-container-2.2" class="outline-3">
<h3 id="sec-2.2"><span class="section-number-3">2.2</span> quotes </h3>
<div class="outline-text-3" id="text-2.2">


</div>

<div id="outline-container-2.2.1" class="outline-4">
<h4 id="sec-2.2.1"><span class="section-number-4">2.2.1</span> Colin Howson and Allan Franklin </h4>
<div class="outline-text-4" id="text-2.2.1">

<ul>
<li id="sec-2.2.1.1">[soundness and completeness theorem <br/>
for the probability calculus] (Colin Howson and Allan Franklin,
Bayesian Conditionalization and Probability Kinematics, 451)
</li>
<li id="sec-2.2.1.2">[Jeffrey's innovation: evidence doesn't come to us in the form of <br/>
propositions of whose truth we are certain] Jeffrey inaugurated the
study of general probability kinematics (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 453)
</li>
<li id="sec-2.2.1.3">limitation on Jeffrey's rule: it cannot be <br/>
used to define a posterior probability P' when the E(i) are not
exclusive (Colin Howson and Allan Franklin, Bayesian
Conditionalization and Probability Kinematics, 454)
</li>
<li id="sec-2.2.1.4">Csiszar states that if any convex set C of constraints is <br/>
closed in the variational distance and some member of C has finite
information relative to P, then there is a unique P' such that P'
minimizes I(P',P). [affine constraints] (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 456)
</li>
<li id="sec-2.2.1.5">This gloss (the function P' minimizing I(P',P) is as like <br/>
P as it is possible to be given the constraints imposed by the data)
should be treated with great caution. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 456)
</li>
<li id="sec-2.2.1.6">The requirement that the posterior distribution should be that <br/>
which is in some sense or other the closest, subject to the stated
constraints, to the prior, is not only an extralogical constraint, but
it is also, in our view, one which it is very difficult if not
impossible to defend as a rationality constraint either. (Colin Howson
and Allan Franklin, Bayesian Conditionalization and Probability
Kinematics, 457)
</li>
<li id="sec-2.2.1.7">[critique of diachronic or dynamic Dutch Book arguments, based <br/>
on Hacking, see also Jon Williamson, Objective Bayesianism, Bayesian
Conditionalisation and Voluntarism, 14] (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 458)
</li>
<li id="sec-2.2.1.8">Bayesian conditionalization suffices to deal with most if not <br/>
all of the methodologically important cases of adjusting beliefs, even
where uncertain evidence is involved. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 461)
</li>
<li id="sec-2.2.1.9">There are several things wrong with [Hobson's example, where <br/>
probabilities are calculated with an expectation constraint and the
PME] the X(i) are not likely to be independent with respect to the
probability distribution P', for P' is by assumption an inductive
probability [see Seidenfeld's example in Jon Williamson, Objective
Bayesianism, Bayesian Conditionalisation and Voluntarism, 10f] (Colin
Howson and Allan Franklin, Bayesian Conditionalization and Probability
Kinematics, 464)
</li>
<li id="sec-2.2.1.10">not to use the rule of Bayesian conditionalization, but some <br/>
other rule, like the principle of minimum information with a uniform
prior and constraints in the form of expectation values, actually
entails inconsistency, i.e. incoherence. (Colin Howson and Allan
Franklin, Bayesian Conditionalization and Probability Kinematics, 465)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.2" class="outline-4">
<h4 id="sec-2.2.2"><span class="section-number-4">2.2.2</span> Igor Douven and Jan-Willem Romeijn </h4>
<div class="outline-text-4" id="text-2.2.2">

<ul>
<li id="sec-2.2.2.1">we argue that Jeffrey's rule can solve the <br/>
Judy Benjamin problem after all {\ldots} we extend the set of distance
functions to ones that take into account the varying degrees to which
propositions may be epistemically entrenched (Igor Douven and
Jan-Willem Romeijn, A New Resolution of the Judy Benjamin Problem, 1)
</li>
<li id="sec-2.2.2.2">[indicative conditional] <br/>
(Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 2)
</li>
<li id="sec-2.2.2.3">how one could beg any questions simply by registering one's <br/>
intuitive verdict that (1) contains no information relevant to whether
Judy is in Red rather than in Blue territory {\ldots}(Igor Douven and
Jan-Willem Romeijn, A New Resolution of the Judy Benjamin Problem, 4)
</li>
<li id="sec-2.2.2.4">How is one to update on an indicative conditional <br/>
{\ldots} is there a defensible update rule that agrees with how Judy
should respond to learning (3)? {\ldots} semantics of conditionals
[used to undermine T2 on page 8] (Igor Douven and Jan-Willem Romeijn,
A New Resolution of the Judy Benjamin Problem, 5)
</li>
<li id="sec-2.2.2.5">[Sarah's example: if it rains tomorrow, we cannot have <br/>
sundowners at the Westcliff. My comment: Sarah of course knows that
rain is independent of sundowners, there is no such certainty in the
JB case.] (Igor Douven and Jan-Willem Romeijn, A New Resolution of the
Judy Benjamin Problem, 7)
</li>
<li id="sec-2.2.2.6">intuitively, the learning of a conditional is or would be irrelevant <br/>
to one's degree of belief for the conditional's antecedent {\ldots}
the learning of the relevant conditional should intuitively leave the
probability of the antecedent unaltered (Igor Douven and Jan-Willem
Romeijn, A New Resolution of the Judy Benjamin Problem, 9)
</li>
<li id="sec-2.2.2.7">[Bradley's Adams conditioning] <br/>
(Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 9f)
</li>
<li id="sec-2.2.2.8">{\ldots} really just a Jeffrey update. To be more <br/>
exact, it is a Jeffrey update on the partition
\{urcorner{}A,A&and;B<sub>1</sub>,{\ldots},A&and;B<sub>n</sub>\}, with
constraints Pr<sub>1</sub>(\urcorner{}A)=Pr<sub>0</sub>(\urcorner{}A) and {\ldots} in
the case of Judy only part of that assignment is given. But this
objection overlooks the fact that the context of the Judy Benjamin
case provides us with the additional probabilistic information
{\ldots} a clear separation between probabilities that derive from
explicit information and those that derive from context does not seem
feasible (Igor Douven and Jan-Willem Romeijn, A New Resolution of the
Judy Benjamin Problem, 11)
</li>
<li id="sec-2.2.2.9">Adams conditioning, or, equivalently, Jeffrey conditioning with the <br/>
explicit constraint of keeping the antecedent's probability fixed in
the update, or, again equivalently, IRE minimization, covers most of
the cases of learning a conditional. Unfortunately, however, it would
be wrong to think that it covers all of them, as Example 2 (jeweller,
Kate and Henry) already shows. (Igor Douven and Jan-Willem Romeijn, A
New Resolution of the Judy Benjamin Problem, 12)
</li>
<li id="sec-2.2.2.10">where Sarah held onto her probability for the antecedent, Kate <br/>
wants to leave the probability of the consequent unaffected {\ldots}
bring to the table the epistemic entrenchments of the propositions
under scrutiny [my comment: translates into finding a Jeffrey
partition] (Igor Douven and Jan-Willem Romeijn, A New Resolution of
the Judy Benjamin Problem, 13)
</li>
<li id="sec-2.2.2.11">[epistemic entrenchments and <br/>
Hellinger distance function] allows us to regulate whether, and to
what extent, learning a conditional reflects back on the probability
fo the antecedent or rather influences the probability of the
consequent (Igor Douven and Jan-Willem Romeijn, A New Resolution of
the Judy Benjamin Problem, 14)
</li>
<li id="sec-2.2.2.12">As Bradley stresses, even Bayes' rule ``should not be thought of <br/>
as a universal and mechanical rule of updating, but as a technique to
be applied in the right circumstances, as a tool in what Jeffrey terms
\qnull{the art of judgment}.'' In the same way, determining and
adapting the weights EE supposes, or deciding when Adams conditioning
applies, may be an art, or a skill, rather than a matter of
calculation or derivation from more fundamental epistemic principles.
((Igor Douven and Jan-Willem Romeijn, A New Resolution of the Judy
Benjamin Problem, 16)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.3" class="outline-4">
<h4 id="sec-2.2.3"><span class="section-number-4">2.2.3</span> Jon Williamson </h4>
<div class="outline-text-4" id="text-2.2.3">

<ul>
<li id="sec-2.2.3.1">the difference between the two forms of updating [Bayes, maxent] <br/>
reflects negatively on Bayesian conditionalization rather than on
objective Bayesian updating. (Jon Williamson, Objective Bayesianism,
Bayesian Conditionalisation and Voluntarism, 1)
</li>
<li id="sec-2.2.3.2">[Probability, Calibration, Equivocation] <br/>
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 3)
</li>
<li id="sec-2.2.3.3">It is objective in the sense that the three principles <br/>
outlined above strongly constrain degrees of belief, leaving little
room for an agent to subjectively choose how strongly to believe a
proposition (Jon Williamson, Objective Bayesianism, Bayesian
Conditionalisation and Voluntarism, 4)
</li>
<li id="sec-2.2.3.4">[affine constraint, as in Csiszar] <br/>
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 5)
</li>
<li id="sec-2.2.3.5">conditionalisation requires being eternally true of prior beliefs <br/>
(Jon Williamson, Objective Bayesianism, Bayesian Conditionalisation
and Voluntarism, 11)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.4" class="outline-4">
<h4 id="sec-2.2.4"><span class="section-number-4">2.2.4</span> Williams, Peter </h4>
<div class="outline-text-4" id="text-2.2.4">

<ul>
<li id="sec-2.2.4.1">about reversibility of evidence <br/>
(136)
</li>
<li id="sec-2.2.4.2">In summary, the principle of minimum information yields a <br/>
unique prescription for all closed convex constraints satisfied by at
least one distribution having finite information relative to the given
prior. (139)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.5" class="outline-4">
<h4 id="sec-2.2.5"><span class="section-number-4">2.2.5</span> Uffink, Jos </h4>
<div class="outline-text-4" id="text-2.2.5">

<p>not yet excerpted
</p></div>

</div>

<div id="outline-container-2.2.6" class="outline-4">
<h4 id="sec-2.2.6"><span class="section-number-4">2.2.6</span> Diaconis and Zabell </h4>
<div class="outline-text-4" id="text-2.2.6">

<ul>
<li id="sec-2.2.6.1">retrospective conditioning <br/>
(basically what Grove and Halpern are doing) (822)
</li>
<li id="sec-2.2.6.2">Example 5.1 suggests that any claims to the effect <br/>
that maximum-entropy revision is the only correct route to probability
revision should be viewed with considerable caution because of its
strong dependence on the measure of closeness being used. (829)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.7" class="outline-4">
<h4 id="sec-2.2.7"><span class="section-number-4">2.2.7</span> Fraassen, Hughes, Harman </h4>
<div class="outline-text-4" id="text-2.2.7">

<ul>
<li id="sec-2.2.7.1">three classes of constraints <br/>
(454)
</li>
<li id="sec-2.2.7.2">five symmetry requirements <br/>
(455ff)
</li>
<li id="sec-2.2.7.3">the three rules <br/>
INF Infomin or PME
MTP Maximum Transition Probability
MUD the simplest rule fulfilling the five requirements
</li>
<li id="sec-2.2.7.4">It is surely significant, and disturbing, that <br/>
INFOMIN did not come out the winner in either test &hellip; the perceived
superiority of INFOMIN (462, with a handwritten note of objection)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.8" class="outline-4">
<h4 id="sec-2.2.8"><span class="section-number-4">2.2.8</span> Seidenfeld, Teddy </h4>
<div class="outline-text-4" id="text-2.2.8">

<ul>
<li id="sec-2.2.8.1">It is interesting to note, as reported <br/>
by Denzau et. al. (1984), the MAXENT solution (A1) is associated with
a LOGIT model by a simple reidentification of parameters (Entropy and
Uncertainty, 282)
</li>
<li id="sec-2.2.8.2">PME is excessively aprioristic &hellip; <br/>
[I think Seidenfeld is here the victim of the meteorologist's fallacy]
(Why I am not, 414)
</li>
<li id="sec-2.2.8.3">At one pole is subjectivism <br/>
(as defended by Savage and de Finetti) &hellip; At the other pole is
objectivism (as defended by Jeffreys and Jaynes) which argues for a
uniquely admissible probability function given a knowledge state K.
(Why I am not, 416)
</li>
<li id="sec-2.2.8.4">Seidenfeld's objection <br/>
Maximizing entropy is unsatisfactory because the `partial information'
it works with fails to capture the effect of uncertainty about related
nuisance factors &hellip; by conditionalizing on information about a
nuisance parameter one may move from a distribution of lower to higher
entropy, despite the obvious increase in information available (Why I
am not, 434)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.9" class="outline-4">
<h4 id="sec-2.2.9"><span class="section-number-4">2.2.9</span> Aristotle </h4>
<div class="outline-text-4" id="text-2.2.9">

<ul>
<li id="sec-2.2.9.1">Nicomachean Ethics <br/>
Here, as in all other cases, we must set down the appearances
(phainomena) and, first working through the puzzles (diaporesantas),
in this way go on to show, if possible, the truth of all the beliefs
we hold about these experiences; and, if this is not possible, the
truth of the greatest number and the most authoritative. For if the
difficulties are resolved and the beliefs are left in place, we will
have done enough showing. (NE VII, 1145b1ff)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.10" class="outline-4">
<h4 id="sec-2.2.10"><span class="section-number-4">2.2.10</span> Avenarius, Richard </h4>
<div class="outline-text-4" id="text-2.2.10">

<ul>
<li id="sec-2.2.10.1">die Gesamtheit des in der Erfahrung Gegebenen <br/>
mit dem geringsten Kraftaufwand zu denken (Richard Avenarius
inspirierte die Figur des Professor Avenarius im Roman Die
Unsterblichkeit von Milan Kundera.)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.11" class="outline-4">
<h4 id="sec-2.2.11"><span class="section-number-4">2.2.11</span> Bar-Hillel, Yehoshua, and Carnap, Rudolf </h4>
<div class="outline-text-4" id="text-2.2.11">

<p>see article Semantic Information in keep-2011
</p></div>

</div>

<div id="outline-container-2.2.12" class="outline-4">
<h4 id="sec-2.2.12"><span class="section-number-4">2.2.12</span> Burgin, Mark </h4>
<div class="outline-text-4" id="text-2.2.12">

<ul>
<li id="sec-2.2.12.1">burgin09 <br/>
<ul>
<li id="sec-2.2.12.1.1">definition of information in <br/>
Burgin, 316, according to Carnap and Bar-Hillel. Very interesting.
E.g. The more probable a statement is, the less information it
conveys, 320.
</li>
</ul>
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.13" class="outline-4">
<h4 id="sec-2.2.13"><span class="section-number-4">2.2.13</span> Chalmers, David </h4>
<div class="outline-text-4" id="text-2.2.13">

<ul>
<li id="sec-2.2.13.1">scenarios constitute epistemic space. If a subject <br/>
did not know anything, all scenarios would be epistemically possible
for the subject. When a subject knows something, some scenarios are
excluded. Every piece of substantive knowledge corresponds to a
division in epistemic space: some scenarios are excluded out as
epistemically impossible for the subject, while others are left open.
(David Chalmers, The Nature of Epistemic Space, 2)
</li>
<li id="sec-2.2.13.2">In epistemic logic and the theory <br/>
of belief revision, it is common to model epistemic possibility using
epistemic relations to an underlying space of pos- sible worlds. The
same goes for the theory of subjective probability: a subject’s
credences are usually taken to be distributed over a space of
epistemically possible worlds. (David Chalmers, The Nature of
Epistemic Space, 2)
</li>
<li id="sec-2.2.13.3">Instead, we should try to understand epistemic possibility <br/>
on its own terms. We are not dealing here with counterfactual space:
the space of ways things might have been. Here, we are dealing with
epistemic space: the space of ways things might be. This epistemic
space calls for its own epistemic tools of analysis. (David Chalmers,
The Nature of Epistemic Space, 3)
</li>
<li id="sec-2.2.13.4">But the notion of possibility invoked here differs from the notion <br/>
of possibility that is usually associated with possible worlds: it is
a sort of epistemic possibility, whereas possible worlds are usually
understood to be associated with a sort of `metaphysical' possibility.
(David Chalmers, The Nature of Epistemic Space, 10)
</li>
<li id="sec-2.2.13.5">Prima facie, this situation suggests that there is no good candidate <br/>
to be the cardinality of the set of all worlds, and that there may be
no such set. Kaplan’s paradox [see Modality, morality, and belief:
essays in honor of Ruth Barcan Marcus, 44f, title A problem in
possible-world semantics] arises at least as strongly when worlds and
propositions are replaced by scenarios and intensions. If anything,
the situation is worse. (David Chalmers, The Nature of Epistemic
Space, 35)
</li>
<li id="sec-2.2.13.6">In Counterfactuals, Lewis suggests that the cardinality of <br/>
the space of worlds might be beth2 , for reasons tied to the character
of spacetime. But it is hard to see why our spacetime should restrict
the space of worlds. (David Chalmers, The Nature of Epistemic Space,
37)
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.14" class="outline-4">
<h4 id="sec-2.2.14"><span class="section-number-4">2.2.14</span> Halpern, Joseph </h4>
<div class="outline-text-4" id="text-2.2.14">

<ul>
<li id="sec-2.2.14.1">Another famous justification of probability is <br/>
due to Cox (1946), who showed that any function that assigns degrees
to events and satisfies certain minimal properties (such as the degree
of belief in U is a decreasing function in the degree of belief in U)
must be isomorphic to a probability measure. Unfortunately, Cox's
argument is not quite correct as stated; his hypotheses need to be
strengthened (in ways that make them less compelling) to make it
correct [Halpern 1999a; Halpern 1999b; Paris 1994]. (Reasoning About
Uncertainty, 65)
</li>
<li id="sec-2.2.14.2">Given this intuition, it is perhaps not surprising <br/>
that there are proponents of maximum entropy and relative entropy who
recommend that if an agent's information can be characterized by a set
C of constraints, then the agent should act "as if" the probability is
determined by the measure that maximizes entropy relative to C (i.e.,
the measure that has the highest entropy of all the measures in C).
Similarly, if the agent starts with a particular measure . it and gets
new information characterized by C, he should update to the measure
,a' that satisfies C such that the relative entropy between and ,u is
a minimum. Maximum entropy and relative entropy have proved quite
successful in a number of applications, from physics to
natural-language modeling. Unfortunately, they also exhibit some
counterintuitive behavior on certain applications. Although they are
valuable tools, they should be used with care.(Reasoning About
Uncertainty, 110)
</li>
<li id="sec-2.2.14.3">[For the correspondence of ME and RW <br/>
(random worlds) and their overlap in the unary case, whereas RW also
covers the nonunary case, see pp416&ndash;420. For the origin of the RW
approach see p. 429.]
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.15" class="outline-4">
<h4 id="sec-2.2.15"><span class="section-number-4">2.2.15</span> Mach, Ernst </h4>
<div class="outline-text-4" id="text-2.2.15">

<ul>
<li id="sec-2.2.15.1">Die ökonomische Natur der physikalischen Forschung <br/>
<ul>
<li id="sec-2.2.15.1.1">Sowohl die Mitteilung als das Bedürfnis des <br/>
Einzelnen, seine Erfahrungssumme mit dem kleinsten Gedankenaufwand zu
beherrschen, zwingt zu ökonomischer Ordnung. Hiermit ist aber auch die
ganze rätselhafte Macht der Wissenschaft erschöpft. Im einzelnen mag
sie uns nichts zu bieten, was nicht jeder in genügend langer Zeit auch
ohne alle Methode finden könnte.
(<a href="http://www.gleichsatz.de/b-u-t/trad/mach2.html">http://www.gleichsatz.de/b-u-t/trad/mach2.html</a>)
</li>
</ul>
</li>
</ul>
</div>

</div>

<div id="outline-container-2.2.16" class="outline-4">
<h4 id="sec-2.2.16"><span class="section-number-4">2.2.16</span> Quine, WVO </h4>
<div class="outline-text-4" id="text-2.2.16">

<ul>
<li id="sec-2.2.16.1">Two Dogmas <br/>
<ul>
<li id="sec-2.2.16.1.1">the plan was that qualities should be assigned to point-instants in such <br/>
a way as to achieve the laziest world compatible with our experience.
The principle of least action was to be our guide in constructing a
world from experience. (37)
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>

</div>

<div id="outline-container-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> before fall 2010 </h2>
<div class="outline-text-2" id="text-3">


</div>

<div id="outline-container-3.1" class="outline-3">
<h3 id="sec-3.1"><span class="section-number-3">3.1</span> aufbau </h3>
<div class="outline-text-3" id="text-3.1">

<ol>
<li>
Information and Probability
</li>
<li>
Information and Divergence
</li>
<li>
Information and Complexity
</li>
<li>
Information and Philosophy
</li>
</ol>
</div>

</div>

<div id="outline-container-3.2" class="outline-3">
<h3 id="sec-3.2"><span class="section-number-3">3.2</span> quotes </h3>
<div class="outline-text-3" id="text-3.2">


</div>

<div id="outline-container-3.2.1" class="outline-4">
<h4 id="sec-3.2.1"><span class="section-number-4">3.2.1</span> ingardenurbanik62 </h4>
<div class="outline-text-4" id="text-3.2.1">

<ul>
<li id="sec-3.2.1.1">information seems intuitively a much simpler and <br/>
more elementary notion than that of probability. It gives more a
cruder and global description of some situations physical or other
than probability does. Therefore, information represents a more
primary step of knowledge than that of cognition of probabilities
(just as probability description is cruder and more global than
deterministic description). Furthermore, a prinicipal separation of
notions of probability and information seems convenient and useful
from the point of view of statistical physics. In physics there
prevail situations where information is known (e.g.\ entropy of some
macroscopic systems) and may be measured with a high degree of
accuracy, whereas probability distribution is unknown and practically
cannot be measured at all {\ldots} Finally, it may be remarked that a
new axiomatic definition of information, free of the inessential
connection with probability, clears the way for future generalizations
of this notion. (ingardenurbanik62:136)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.2" class="outline-4">
<h4 id="sec-3.2.2"><span class="section-number-4">3.2.2</span> bernardo79 </h4>
<div class="outline-text-4" id="text-3.2.2">

<ul>
<li id="sec-3.2.2.1">This pragmatic approach led to <br/>
Jose M. Bernardo's suggestion of Reference Posterior Distributions.
{\rppd}s agree with the Principle of Maximum Entropy in applicable
cases and thus also with the Principle of Indifference. Instead of
measuring and maximizing missing information, however, {\rppd}s
measure and maximize expected information. Let $p(&theta;)$ be our
prior density. Then the expected information IE is:
\begin{displaymath} \mbox{IE}=&int; p(x)&int; p(&theta;&#124;
x)log\frac{p(&theta;&#124; x)}{p(&theta;)}d&theta;\, dx \end{displaymath}
where $p(x)=&int; p(x&#124;&theta;)p(&theta;)d&theta;$ and $p(&theta;&#124;
x)=p(x&#124;&theta;)p(&theta;)/p(x)$ (Bernardo, 1979, p115). Again,
$p<sub>k</sub>=\frac{1}{n}$ for the straightforward discrete case, but this
time we also learn that for the continuous case the distribution which
maximizes expected information is the normal distribution. (my priors
paper)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.3" class="outline-4">
<h4 id="sec-3.2.3"><span class="section-number-4">3.2.3</span> clarkebarron90 </h4>
<div class="outline-text-4" id="text-3.2.3">

<ul>
<li id="sec-3.2.3.1">The relative entropy is a mathematical expression <br/>
that admits several different interpretations in information theory
and statistics. These include the redundancy in source coding
problems, the risk in statistical estimation, and the error exponents
in hypothesis testing, among others. (clarkebarron90:453)
</li>
<li id="sec-3.2.3.2">It is seen that $D(P<sup>n</sup><sub>&theta;</sub>\|M<sub>n</sub>)$ is <br/>
a) the cumulative risk of Bayes' estimators of the density function,
b) the redundancy of a source code based on $M<sub>n</sub>$, c) the exponent
of error probability for Bayes' tests of a simple versus composite
hypothesis, and d) a bound on the financial loss in a stock-market
portfolio selection problem. (clarkebarron90:455)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.4" class="outline-4">
<h4 id="sec-3.2.4"><span class="section-number-4">3.2.4</span> goguen97 </h4>
<div class="outline-text-4" id="text-3.2.4">

<ul>
<li id="sec-3.2.4.1">It is said that we live in an <br/>
Age of Information, but it is an open scandal that there is no theory,
nore even definition, of information that is both broad and precise
enough to make such an assertion meaningful. (goguen97:27)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.5" class="outline-4">
<h4 id="sec-3.2.5"><span class="section-number-4">3.2.5</span> guiasu77 </h4>
<div class="outline-text-4" id="text-3.2.5">

<ul>
<li id="sec-3.2.5.1">Therefore, the continuous entropy $H<sub>&rho;</sub>$ may be interpreted <br/>
as being (up to an additive constant) the variation of information
when we pass from the initial uniform probability distribution on the
interval $[a,b]$ to the new probability measure defined by the
probability distribution function $&rho;(x)$ (any such a probability
measure is absolutely continuous with respect to the uniform
probability distribution on the interval $[a,b]$). Thus, we can
utilize, in the continuous case, Boltzmann's continuous entropy as
well as Shannon Entropy in the discrete case, both being interpreted
as the variation of information when we pass from the initial uniform
distribution to the corresponding probability measures. (guiasu77:28)
</li>
<li id="sec-3.2.5.2">Theorem 3.1 shows that though the usual logical order, according <br/>
to which information is defined by means of probability, can be
reversed, and one can introduce information first, without using
probabilities, probabilities inevitably come in at a later stage. The
fact that a theory which starts with the aim of defining information
without probability leads to the proof of the existence of probability
supports the view that the notion of information cannot be separated
from that of probability. To each event $A$ there correspond two
numbers: its probability $p(A)$ and its information content $I(A)$
which are connected by the formulas $I(A)=log<sub>e</sub>\frac{1}{p(A)},
p(A)=e<sup>-I(A)</sup>$ (guiasu77:36f)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.6" class="outline-4">
<h4 id="sec-3.2.6"><span class="section-number-4">3.2.6</span> hjorland07 </h4>
<div class="outline-text-4" id="text-3.2.6">

<ul>
<li id="sec-3.2.6.1">[objective versus subjective understanding of <br/>
information] (hjorland07:1449)
</li>
<li id="sec-3.2.6.2">The problem is also about whether problems of <br/>
information science are best served with theories like Shannon and
Weaver's information theory or with theories more related to
semiotics. In the history of information science, the tendency has
been a development from information theory toward more semiotic
theories. (See also Werzig, 2003.) (hjorland07:1455)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.7" class="outline-4">
<h4 id="sec-3.2.7"><span class="section-number-4">3.2.7</span> jaynes57 </h4>
<div class="outline-text-4" id="text-3.2.7">

<ul>
<li id="sec-3.2.7.1">the maximum-entropy distribution may be asserted for the <br/>
positive reason that it is uniquely determined as the one which is
maximally noncommittal with regard to missing information, instead of
the negative one that there was no reason to think otherwise
(Jaynes, 1957, p623)
</li>
<li id="sec-3.2.7.2">there is nothing in the general <br/>
laws of motion that can provide us with any additional information
about the state of a system beyond what we have obtained from
measurement (Jaynes, 1957, 624)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.8" class="outline-4">
<h4 id="sec-3.2.8"><span class="section-number-4">3.2.8</span> khinchin57 </h4>
<div class="outline-text-4" id="text-3.2.8">

</div>

</div>

<div id="outline-container-3.2.9" class="outline-4">
<h4 id="sec-3.2.9"><span class="section-number-4">3.2.9</span> kolmogorov68 </h4>
<div class="outline-text-4" id="text-3.2.9">

<ul>
<li id="sec-3.2.9.1">the need for attaching definite meaning <br/>
to the expressions $H(x|y)$ and $I(x|y)$, in the case of individual
values $x$ and $y$ that are not viewed as a result of random tests
with a definite law of distribution, was realized long ago by many who
dealt with information theory. (kolmogorov68:662)
</li>
<li id="sec-3.2.9.2">The meaning of the new definition is very simple. Entropy <br/>
$H(x|y)$ is the minimal length of the recorded sequence of zeros and
ones of a \qnull{program} $P$ that permits construction of the value
of $x$, the value of $y$ being known {\ldots} Although Martin-L{\"o}f
and I realized the importance of the new concept, the development was
hindered because the simplest formulas that can be produced as a
result of simple algebraic transposition of (1) [Shannon's Entropy]
could not be derived from the new definitions (kolmogorov68:662)
</li>
<li id="sec-3.2.9.3">The preceding rather superficial discourse should <br/>
prove two general theses: 1) Basic information theory concepts must
and can be founded without recourse to the probability theory, and
such a manner that \qnull{entropy} and \qnull{mutual information}
concepts are applicable to individual values. 2) Thus introduced,
information theory concepts can form the basis of the term random,
which naturally suggests that random is the absence of periodicity.
(kolmogorov68:663f)
</li>
<li id="sec-3.2.9.4">by using probability theory, we resort to <br/>
considerably rougher generalization. A realistic interpretation of
probability results is always statistical, and error estimates are
considerable rougher that in the information theory exposition
developed by us. (kolmogorov68:664)
</li>
<li id="sec-3.2.9.5">Credit for noting this relatively simple condition <br/>
evidently belongs to Solomonov and me. (kolmogorov68:664) [compare
Matthew Effect]
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.10" class="outline-4">
<h4 id="sec-3.2.10"><span class="section-number-4">3.2.10</span> kolmogorov68a </h4>
<div class="outline-text-4" id="text-3.2.10">

<ul>
<li id="sec-3.2.10.1">Discussions of information theory do not go into this <br/>
combinatorial approach at any length, but I consider it important to
emphasize its logical independence of probabilistic assumptions.
(kolmogorov68a:158)
</li>
<li id="sec-3.2.10.2">If we make the variable $x$ and $y$ \qnull{random variables} <br/>
with given joint probability distributions, we can obtain a
considerably richer system of concepts and relationships
(kolmogorov68a:161)
</li>
<li id="sec-3.2.10.3">{\ldots} War and Peace {\ldots} <br/>
(kolmogorov68a:162)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.11" class="outline-4">
<h4 id="sec-3.2.11"><span class="section-number-4">3.2.11</span> loeve55 </h4>
<div class="outline-text-4" id="text-3.2.11">

<ul>
<li id="sec-3.2.11.1">Probability Theory <br/>
Synopsis:

<p>
(i) Constructive definition of conditional expectation:
</p>
<p>
\begin{displaymath}
E<sub>B</sub>X=&int;<sub>B</sub>XdP
\end{displaymath}
</p>
<p>
or, equivalently,
</p>
<p>
\begin{displaymath}
P(B)E<sub>B</sub>X=&int;<sub>B</sub>XdP
\end{displaymath}
</p>
<p>
then define
</p>
<p>
\begin{displaymath}
P<sub>B</sub>A=E<sub>B</sub>I<sub>A</sub>
\end{displaymath}
</p>
<p>
[page 338, more detail 339f]
</p>
<p>
(ii) the constructive definition fails if partition is not countable
-&gt; use Radon-Nikodym
</p>
<p>
conditional expectation is a function for which
</p>
<p>
\begin{displaymath}
&int;<sub>N</sub>(E<sup>\mathcal{B}</sup>X)dP=&int;<sub>B</sub>XdP
\end{displaymath}
</p>
<p>
and
</p>
<p>
\begin{displaymath}
P<sup>\mathcal{B}</sup>=E<sup>\mathcal{B}</sup>I<sub>A</sub>
\end{displaymath}
</p>
<p>
or
</p>
<p>
\begin{displaymath}
&int;<sub>B</sub>(P<sup>\mathcal{B}</sup>A)dP<sub>\mathcal{B}</sub>=PAB
\end{displaymath}
</p>
<p>
[page 341]
</p>
<p>
(iii) then show that the generalized definition accords with the
intuitive, constructive definition where applicable
</p></li>
</ul>
</div>

</div>

<div id="outline-container-3.2.12" class="outline-4">
<h4 id="sec-3.2.12"><span class="section-number-4">3.2.12</span> solomonov64 </h4>
<div class="outline-text-4" id="text-3.2.12">

<ul>
<li id="sec-3.2.12.1">That these kinds of models might be valid is <br/>
suggested by \qnull{Occam's Razor,} one interpretation of which is that
the more \qnull{simple} or \qnull{economical} of several hypotheses is
the more likely. Turing machines are then used to explicate the
concepts of \qnull{simplicity} or \qnull{economy}&mdash;the most
\qnull{simple} hypothesis being that with the shortest
\qnull{description.} (solomonov64:3)
</li>
<li id="sec-3.2.12.2">It is possible to devise a complete theory of <br/>
inductive inference using Bayes' Theorem, if we are able to assign an
a priori probability to every conceivable sequence of symbols. In
accord with this approach, it is felt that sequences should be given
high a priori probabilities if they have shortest descriptions and/or
many different descriptions {\ldots} any regularity in a corpus may be
utilized to write a shorter description of that corpus {\ldots} the
high a priori probability assigned to a sequence with a short
description corresponds to one possible interpretation of
\qnull{Occam's Razor.} The assignment of high a priori probabilities
to sequences with many descriptions corresponds to a feeling that if
an occurrence has many possible causes, then it is more likely.
(solomonov64:7)
</li>
<li id="sec-3.2.12.3">Suppose that all of the sensory observations <br/>
of a human being since his birth were coded in some sort of uniform
digital notation and written down as a long sequence of symbols. Then,
a model that accounts in an optimum manner for the creation of this
string, including the interaction of the man with his environment, can
be formed by supposing that the string was created as the output of a
universal machine of random input. (solomonov64:13)
</li>
<li id="sec-3.2.12.4">The laws of science that have been discovered <br/>
can be viewed as summaries of large amounts of empirical data about
the universe. (solomonov64:15)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.13" class="outline-4">
<h4 id="sec-3.2.13"><span class="section-number-4">3.2.13</span> turing37 </h4>
<div class="outline-text-4" id="text-3.2.13">

<ul>
<li id="sec-3.2.13.1">Turing (1937) has shown that it is impossible <br/>
to devise a Turing machine that will always be able to tell, in a
finite time, whether an arbitrary string will be \qnull{meaningful}
for another particular universal Turing machine. (solomonov64:9f)
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.14" class="outline-4">
<h4 id="sec-3.2.14"><span class="section-number-4">3.2.14</span> wallacedowe99 </h4>
<div class="outline-text-4" id="text-3.2.14">

<ul>
<li id="sec-3.2.14.1">The aim in this stream is to find the hypothesis <br/>
$H$ which leads to the shortest such stream $I$, which may be regarded
as the shortest message encoding the data given in $S$ {\ldots} The
minimization of #I [length of the program which reproduces the data
$S$] is, as shown by the equation above, equivalent to maximization of
$h(H) x f(S|H)=Prob(H,S)$, i.e. the joint probability of hypothesis
and data. It is thus formally equivalent to choosing the hypothesis of
highest Bayesian posterior probability given $S$. (271f) [nice summary
on 270 of Kolmogorov Complexity and Turing machines]
</li>
</ul>
</div>

</div>

<div id="outline-container-3.2.15" class="outline-4">
<h4 id="sec-3.2.15"><span class="section-number-4">3.2.15</span> zhulu04 </h4>
<div class="outline-text-4" id="text-3.2.15">

<ul>
<li id="sec-3.2.15.1">We should also note that, counter-intuitively, non-informative <br/>
priors and flat priors (such as the uniform distribution) do not
coincide (cf.\ Mu and Zhu, 2004)
</li>
<li id="sec-3.2.15.2">The lesson from this discussion is extremely <br/>
interesting; it tells us that flat priors (such as the uniform prior)
are not always the same thing as non-informative priors. A seemingly
informative prior can actually be quite weak in the sense that it does
not influence the posterior opinion very much. It is clear in our
example that the MLE is the result of using a weak prior, whereas the
most intuitive non-informative prior (the uniform prior) is not as
weak or non-informative as one would have thought. (6)
</li>
</ul>
</div>
</div>

</div>

<div id="outline-container-3.3" class="outline-3">
<h3 id="sec-3.3"><span class="section-number-3">3.3</span> links </h3>
<div class="outline-text-3" id="text-3.3">


</div>

<div id="outline-container-3.3.1" class="outline-4">
<h4 id="sec-3.3.1"><span class="section-number-4">3.3.1</span> information theory </h4>
<div class="outline-text-4" id="text-3.3.1">

<p><a href="http://en.wikipedia.org/wiki/Algorithmic_information_theory">http://en.wikipedia.org/wiki/Algorithmic_information_theory</a>
<a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity">http://en.wikipedia.org/wiki/Kolmogorov_complexity</a>
<a href="http://en.wikipedia.org/wiki/Kullback–Leibler_divergence">http://en.wikipedia.org/wiki/Kullback–Leibler_divergence</a>
<a href="http://en.wikipedia.org/wiki/Minimum_message_length">http://en.wikipedia.org/wiki/Minimum_message_length</a>
<a href="http://en.wikipedia.org/wiki/Bayesian_information_criterion">http://en.wikipedia.org/wiki/Bayesian_information_criterion</a>
</p></div>
</div>

</div>

<div id="outline-container-3.4" class="outline-3">
<h3 id="sec-3.4"><span class="section-number-3">3.4</span> ideas </h3>
<div class="outline-text-3" id="text-3.4">


</div>

<div id="outline-container-3.4.1" class="outline-4">
<h4 id="sec-3.4.1"><span class="section-number-4">3.4.1</span> information epistemology is an </h4>
<div class="outline-text-4" id="text-3.4.1">

<p>epistemology of ignorance rather than an epistemology of knowledge,
which suits me just right.
</p></div>

</div>

<div id="outline-container-3.4.2" class="outline-4">
<h4 id="sec-3.4.2"><span class="section-number-4">3.4.2</span> Kolmogorov's frustration with probability theory comes </h4>
<div class="outline-text-4" id="text-3.4.2">

<p>from a different place that Ingarden's or Kampe's. He wants an
information density  measure that applies to individual sequences of
symbols rather than to the probability distributions behind the
sequences of symbols.
</p></div>

</div>

<div id="outline-container-3.4.3" class="outline-4">
<h4 id="sec-3.4.3"><span class="section-number-4">3.4.3</span> math results </h4>
<div class="outline-text-4" id="text-3.4.3">

<ol>
<li>
Shannon Entropy is unique khinchin57:9
</li>
<li>
It doesn't matter what Turing machine we use
</li>
<li>
The uniform distribution has the highest Shannon Entropy guiasu77:3
</li>
<li>
H(x|y) is a generalization of Shannon Entropy for the continuous
case guiasu77:19ff
</li>
<li>
Ingarden and Kampe de Feriet guiasu77:29ff and guiasu77:37ff,
kampe67, ingardenurbanik62
</li>
<li>
the normal distribution contains the largest amount of uncertainty
guiasu77:299 with good quote, proof is due to kampe63, similar
result with respect to Poisson distribution ingardenkossakowski71,
see guiasu77:301
</li>
<li>
use Radon-Nikodym derivative to define conditional probability
because intuition fails in some cases see loeve55:338ff
</li>
<li>
Chaitin's Incompleteness Theorem
</li>
<li>
Shannon's Entropy is defined by KLD
</li>
</ol>
</div>

</div>

<div id="outline-container-3.4.4" class="outline-4">
<h4 id="sec-3.4.4"><span class="section-number-4">3.4.4</span> philsophical musings </h4>
<div class="outline-text-4" id="text-3.4.4">

<p>The world is full of specificity and unknowns, as it is full of
possibilities and eigenheit. (Harry Potter and the Prisoner of
Azkaban, Harry's patronus.)
</p>
<p>
If all is indifferent, there is no information. All there is is
entropy, the end of time. If all we have ever believed turns out to be
false, there is an infinity of information. This lack of entropy
altogether must be the closest approximation of Dante's Hell, of
Leibniz's Demon. We are, hopefully, somewhere in the middle between
total entropy and total information, somewhere between givens and
possibilities. It appears to be a feature of life that things are one
way and not another (call it truth, call it information) and that they
are not fixed yet (call it choices, call it probability).
</p>
<p>
This is the age of information, yet we know little and care little
about the meaning of information. Beginning in the forties and
petering out in the seventies, there was great interest in information
theory, fueled no doubt by the British and American mathematicians who
cracked the Japanese and the German codes. Then the interest
waned, or moved over to the engineers, when Turing's Halting Problem
halted algorithmization of information theory as G"odel's
Incompleteness Theorem halted TBA. Nothing in so dramatic a fashion
ever happened to probability theory, and so it still holds
epistemological attention, and so there is little we know yet about
the limits of its language.
</p>
<p>
We return to the reasons why information theory may have
epistemological primacy over probability theory: there is a
mathematical definition of its limits, as there is for logic in
G"odel's Incompleteness Theorem. There is an intuitive relation to
complexity, which in some way is the only thing which enables us to
assess the significance (the `bigness') of a thing. It is the only
physical property we can scale, and thus the law of entropy becomes to
us one of the most fundamental laws of nature. One day we may
understand the physicality of our world entirely by means of
information. Quantum mechanics undermines our faith in the continuous
fluidity of matter, but it seems to support the ideas we have of
informational states. Chesterton's prayer of gratitude in The Poet and
the Lunatic may yet need to be understood in new ways: ``Thank God for
hard stones; thank God for hard facts; thank God for thorns and rocks
and deserts and long years. At least I know now that I am not the best
or strongest thing in the world. At least I know now that I have not
dreamed of everything.''
</p></div>

</div>

<div id="outline-container-3.4.5" class="outline-4">
<h4 id="sec-3.4.5"><span class="section-number-4">3.4.5</span> there is also a convergence between physics and epistemology </h4>
<div class="outline-text-4" id="text-3.4.5">

<p>if information or entropy are recognized as fundamental notions.
</p></div>

</div>

<div id="outline-container-3.4.6" class="outline-4">
<h4 id="sec-3.4.6"><span class="section-number-4">3.4.6</span> is there a Dutch-book equivalent for </h4>
<div class="outline-text-4" id="text-3.4.6">

<p>information?
</p></div>

</div>

<div id="outline-container-3.4.7" class="outline-4">
<h4 id="sec-3.4.7"><span class="section-number-4">3.4.7</span> experimental design </h4>
<div class="outline-text-4" id="text-3.4.7">

<p>Design your experiment so that the evidence (the data) will be
information-rich and the hypothesis will be information-poor (see Jose Bernardo).
</p></div>

</div>

<div id="outline-container-3.4.8" class="outline-4">
<h4 id="sec-3.4.8"><span class="section-number-4">3.4.8</span> perl zipping program </h4>
<div class="outline-text-4" id="text-3.4.8">

<p>generate 0 1 bernoulli sequence, once with p=.5, once with p=.9, and
then zip it
</p></div>

</div>

<div id="outline-container-3.4.9" class="outline-4">
<h4 id="sec-3.4.9"><span class="section-number-4">3.4.9</span> Model-Fitting </h4>
<div class="outline-text-4" id="text-3.4.9">

<p>I have some data and a set of models for the data. Strategies:
</p>
<p>
(1) Likelihood Ratio Test
<a href="http://en.wikipedia.org/wiki/Likelihood-ratio_test">http://en.wikipedia.org/wiki/Likelihood-ratio_test</a>
</p>
<p>
(2) Bayes Factor
<a href="http://en.wikipedia.org/wiki/Bayes_factor">http://en.wikipedia.org/wiki/Bayes_factor</a> &ndash; guards against overfitting
</p>
<p>
(3) Minimum Message Length
<a href="http://en.wikipedia.org/wiki/Minimum_message_length">http://en.wikipedia.org/wiki/Minimum_message_length</a>
</p>
<p>
(4) Kullback's Minimum Discrimination Information
</p></div>

</div>

<div id="outline-container-3.4.10" class="outline-4">
<h4 id="sec-3.4.10"><span class="section-number-4">3.4.10</span> Minimum message length (MML) is a formal information theory </h4>
<div class="outline-text-4" id="text-3.4.10">

<p>restatement of Occam's Razor: even when models are not equal in
goodness of fit accuracy to the observed data, the one generating the
shortest overall message is more likely to be correct (where the
message consists of a statement of the model, followed by a statement
of data encoded concisely using that model). MML was invented by Chris
Wallace, first appearing in the seminal (Wallace and Boulton, 1968).
(see <a href="http://en.wikipedia.org/wiki/Minimum_message_length">http://en.wikipedia.org/wiki/Minimum_message_length</a>)
</p></div>

</div>

<div id="outline-container-3.4.11" class="outline-4">
<h4 id="sec-3.4.11"><span class="section-number-4">3.4.11</span> The idea of Kullback–Leibler divergence as discrimination information </h4>
<div class="outline-text-4" id="text-3.4.11">

<p>led Kullback to propose the Principle of Minimum Discrimination
Information (MDI): given new facts, a new distribution f should be
chosen which is as hard to discriminate from the original distribution
f0 as possible; so that the new data produces as small an information
gain DKL( f || f0 ) as possible. (see
<a href="http://en.wikipedia.org/wiki/Kullback–Leibler_divergence">http://en.wikipedia.org/wiki/Kullback–Leibler_divergence</a>)
</p></div>

</div>

<div id="outline-container-3.4.12" class="outline-4">
<h4 id="sec-3.4.12"><span class="section-number-4">3.4.12</span> Solomonoff, who focused on prediction using his invention of </h4>
<div class="outline-text-4" id="text-3.4.12">

<p>the universal a priori probability distribution
</p></div>

</div>

<div id="outline-container-3.4.13" class="outline-4">
<h4 id="sec-3.4.13"><span class="section-number-4">3.4.13</span> Incomputability of Kolmogorov complexity </h4>
<div class="outline-text-4" id="text-3.4.13">

<p>The first result is that there is no way to effectively compute K.
Theorem. K is not a computable function. (see
<a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity">http://en.wikipedia.org/wiki/Kolmogorov_complexity</a>)
</p></div>

</div>

<div id="outline-container-3.4.14" class="outline-4">
<h4 id="sec-3.4.14"><span class="section-number-4">3.4.14</span> Chaitin's incompleteness theorem </h4>
<div class="outline-text-4" id="text-3.4.14">

<p>We know that, in the set of all possible strings, most strings are
complex in the sense that they cannot be described in any
significantly "compressed" way. However, it turns out that the fact
that a specific string is complex cannot be formally proved, if the
string's complexity is above a certain threshold. (see
<a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity">http://en.wikipedia.org/wiki/Kolmogorov_complexity</a>)
</p></div>

</div>

<div id="outline-container-3.4.15" class="outline-4">
<h4 id="sec-3.4.15"><span class="section-number-4">3.4.15</span> in algorithmic information theory, the invariance theorem, originally proved by </h4>
<div class="outline-text-4" id="text-3.4.15">

<p>Ray Solomonoff, states that a universal Turing machine provides an
optimal means of description, up to an additive constant.
</p></div>

</div>

<div id="outline-container-3.4.16" class="outline-4">
<h4 id="sec-3.4.16"><span class="section-number-4">3.4.16</span> Gettier cases </h4>
<div class="outline-text-4" id="text-3.4.16">

<p>Miller believes that someone in his office owns a Ford. He doesn't own
a Ford, but he has Jones' reliable testimony that Jones owns a Ford.
It turns out that Jones doesn't own a Ford (he was lying, in this
case), but Smith does (who has been lying and claiming that he owns a
Chevrolet). Now consider someone telling Miller:
</p>
<p>
(X) Someone in your office owns a Ford.
</p>
<p>
Miller will think that (X) contains no information. He thinks he
already knows (X). Yet it turns out that (X) contains information
referring to the way in which Miller's belief is not properly
connected to the truth. (Imagine someone saying, ``Someone in your
office owns a Ford,'' with the right kind of intonation, intimating
that Miller's belief that Jones owns a Ford is false.) All the
problems of the conceptual analysis of knowledge remain the same.
</p>
<p>
Take, for example, a simple form of Nozick's analysis. Here, knowing
(X) means that (i) Miller believes (X), (ii) (X) is true, (iii) if (X)
were not true, Miller wouldn't believe (X), and (iv) if (X) were true
in a slightly different way, Miller would believe (X). (iii) fails,
because Miller would continue to believe (X) even if Smith didn't own
a Ford. What information does (X) add?
</p></div>

</div>

<div id="outline-container-3.4.17" class="outline-4">
<h4 id="sec-3.4.17"><span class="section-number-4">3.4.17</span> Mutual information can be expressed as the average Kullback–Leibler divergence </h4>
<div class="outline-text-4" id="text-3.4.17">

<p>(information gain) of the posterior probability distribution of X
given the value of Y to the prior distribution on X (wikipedia on
information theory)
</p></div>

</div>

<div id="outline-container-3.4.18" class="outline-4">
<h4 id="sec-3.4.18"><span class="section-number-4">3.4.18</span> information density </h4>
<div class="outline-text-4" id="text-3.4.18">

<ul>
<li id="sec-3.4.18.1">information density has as little <br/>
practicality to it as Bayesian epistemology. Scientists are not known
to hunker down with their calculators, plugging in priors and
likelihoods to figure out posteriors. What Bayesian epistemology does
is give us a pattern of thought and belief revision. Given various
alternative hypotheses, it is still our intuition, informed by
information density epistemology, that needs to make the call.
</li>
<li id="sec-3.4.18.2">if information is the primary notion <br/>
behind knowledge, understanding, evidence, or explanation, then there
is a Wittgensteinian point here: there is not <i>more</i> to be explained
about the world other than that things are one way and not another.
This is also a Humean point.
</li>
<li id="sec-3.4.18.3">if I am right, this would be a bit of a <br/>
resurrection for positivism. I may not be right. A philosopher's ideas
have no need to turn into his opinions. The best theories are those
that keep the information density at a maximum. What is your best
theory after the first sunrise, what after your second sunrise, what
after sunrise no. 1000. Information density operates on the same
principles as file compression.
</li>
<li id="sec-3.4.18.4">it is not inconsistent to believe in <br/>
a contradiction, but it is likely to violate the maximum information
density principle. A world in which a contradiction would be true
might be unnecessarily complicated. Sometimes, however, you may have
to believe in a contradiction to make sense of the world at all.
</li>
</ul>
</div>

</div>

<div id="outline-container-3.4.19" class="outline-4">
<h4 id="sec-3.4.19"><span class="section-number-4">3.4.19</span> What matters is belief revision, not knowledge </h4>
<div class="outline-text-4" id="text-3.4.19">

<p>acquisition. (The Bayesians are right, Williamson is wrong.) If, which
is rare, probability language applies, rationality is coextensive with
Bayesianism. If not, there must be a conversation about which belief
systems are less inconsistent. If, as is likely the case, there is no
appropriate measure of inconsistency (inconsistent may be an adjective
that does not allow comparatives), we may refer to information
density. Generally, disagreement arises over what the evidence and
what the hypothesis are, rather than how well-fitted the hypothesis is
to the evidence. In other (Quinean) words, the evidence is never
fixed. If you doubt my conclusion, you are as likely to question my
evidence as you are to question my fitting procedure. There is no
primacy of doubting the validity of the argument versus doubting the
validity of the premises.
</p></div>

</div>

<div id="outline-container-3.4.20" class="outline-4">
<h4 id="sec-3.4.20"><span class="section-number-4">3.4.20</span> Quantitative Bayesian belief analysis is </h4>
<div class="outline-text-4" id="text-3.4.20">

<p>like political analysis in terms of dollar amounts and number of
voters. It can only go so far and definitely not the whole way.
</p></div>

</div>

<div id="outline-container-3.4.21" class="outline-4">
<h4 id="sec-3.4.21"><span class="section-number-4">3.4.21</span> diachronische vernetztheit, eigenheit of the world, evidence.org </h4>
<div class="outline-text-4" id="text-3.4.21">

</div>

</div>

<div id="outline-container-3.4.22" class="outline-4">
<h4 id="sec-3.4.22"><span class="section-number-4">3.4.22</span> rephrase Leibniz: Why is there something and not rather nothing? Why is </h4>
<div class="outline-text-4" id="text-3.4.22">

<p>there information and not rather total entropy?
</p></div>

</div>

<div id="outline-container-3.4.23" class="outline-4">
<h4 id="sec-3.4.23"><span class="section-number-4">3.4.23</span> defining the size of objects by their complexity </h4>
<div class="outline-text-4" id="text-3.4.23">

<p>see Marilynne Robinson and the brain
</p></div>

</div>

<div id="outline-container-3.4.24" class="outline-4">
<h4 id="sec-3.4.24"><span class="section-number-4">3.4.24</span> Information is directly related to </h4>
<div class="outline-text-4" id="text-3.4.24">

<p>complexity, which in some way is the only thing which enables us to
assess the significance (the \qnull{bigness}) of a thing. It is the
only physical property we can scale, and thus the law of entropy
becomes to us one of the most fundamental laws of nature (entropy is
also the only quantity in the physical sciences that seems to imply a
particular direction for time). Information epistemology implies a
sense of convergence between physics and philosophy, for example in
the correspondence between Boltzmann's entropy and Shannon's entropy.
One day we may understand the physicality of our world entirely by
means of information. Quantum mechanics undermines our faith in the
continuous fluidity of matter, but it seems to support the ideas we
have of informational states. But information density and
</p></div>

</div>

<div id="outline-container-3.4.25" class="outline-4">
<h4 id="sec-3.4.25"><span class="section-number-4">3.4.25</span> I dedicate this paper to X whose </h4>
<div class="outline-text-4" id="text-3.4.25">

<p>relationship with me is proof that transmission across the noisy
channels of marriage and family is possible and can, at times, be intimate.
</p></div>
</div>
</div>
</div>
<div id="postamble">
<p class="author"> Author: U-VCC\stlukits
<a href="mailto:stlukits@KELAPVI01XXXXXX.vcc.ca">&lt;stlukits@KELAPVI01XXXXXX.vcc.ca&gt;</a>
</p>
<p class="date"> Date: 2012-02-29 13:26:34 PST</p>
<p class="creator">HTML generated by org-mode 6.33x in emacs 23</p>
</div>
</div>
</body>
</html>
