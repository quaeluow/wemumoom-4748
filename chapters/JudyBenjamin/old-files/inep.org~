* current
** roadmap
*** read Giffin and Caticha's work
*** read MaxEnt conference proceedings
*** think about information and Carnap
*** read information textbook (Raymond Yeung)
*** read 1953__Bar_Hillel_Carnap__Semantic_Information.pdf
*** find out whats been written on Information and Philosophy in the last five years
** ideas
*** ranking functions
Hi Stefan,

Lots to say here.

'Tis true -- the relationship between ranking functions and information. One could say, I suppose, that if it takes n bits of information to make you believe P then the rank of P is n. In a lottery with 1024 tickets it would take 10 bits to identify the winner, so \rho(P_{i})=10, if P_{i} designates that the i-th ticket wins. You would have to change the disjunction rule to

(*) \rho{A\cup B}=-log_{2}(2^{-I(A)}+2^{-I(B)}) for disjoint A and B

-- a formula that has little to recommend it in terms of elegance, but it takes care of the lottery paradox: if A_{i} is a disjoint cover of \Omega then

\rho(\Omega)=-log_{2}(\sum_{i}2^{-I(A_{i})})=0

A rigorous proof of this looks like an interesting challenge. I am only assuming this because it works for probabilities of the (1/k)^{m} type, thus by ``mathematical analogy''

OK -- part of the problem here is interpreting what claims about rank mean. According to the official rank theorists (Spohn, Huber): rank 0 is not "believes", but "does not disbelieve". So, rank 10 means disbelief that is 10 steps away from "does not disbelieve". But the entrenchment interpretation does not always seem to fit with this view about rank 0.

Your rule will violate the basic axioms of ranking theory: since \rho(A \cup ~A) = 0 = min(\rho(A), \rho(~A)), we must have at least one of \rho(A)=0 or \rho(~A)=0.

[beginning of rabbit trail] besides the examples you provided I was trying to think of cases of analogies in mathematics and couldn't come up with anything interesting, but then I read in my book on topology that I am reading for the Carnap seminar:

``This [a claim about manifolds] is a sensible claim because if v were a vector in \mathbold{R}^{m} then to express v as a linear combination of the standard basis vector, to find the approximate coefficients we would take the scalar product of v with the standard basis vectors. To verify this claim we must show that ...'' (David Gauld, Differential Topology, page 98)

In topology this analogy from n-dimensional Euclidean spaces to manifolds is quite common (and mathematically productive, as nobody can picture general manifolds very well, but we do OK with Euclidean spaces). Topology is to a large degree the discipline that provides theorems delineating when the analogies are valid and when they are not. [end of rabbit trail]

An m-manifold is locally like R^m, for sure. I guess there is an analogical argument here in support of a conjecture about manifolds involving scalar products -- that's pretty cool, since it is being put forward exactly the way I say things run: first the analogy (and with no big fuss about the degree of strength of the analogical argument), and then the need to follow up with a proof. In my chapter on analogies in mathematics, I have a section on "asymptotic analogies" -- those involving limits.

As soon as ranking functions are defined by information as outlined above, they could immediately be reduced to probabilities (to the degree to which probabilities and information hang together) ... not what the Baconian modal approach has in mind, I suppose, unless one could find a modal approach to information as well that makes it less of a one-to-one reflection of the corresponding probabilities. Now, I would be VERY interested in how that might work. Perhaps, instead of defining information by the corresponding probabilities, one could define information by ranking functions, as in I(A)=\rho(A), where we know how A ranks (in terms of plausibility), but not what quantifiable probability it has. Unfortunately, with the disjunction rule (*) \rho(A) would reduce to the Bayesian probability calculus (violating our Baconian intuitions), and without (*) (for example, your suggested disjunction rule) information wouldn't do anything for us that we didn't already know about ranking functions -- for example that they don't deal very well with the lottery paradox, or, I suppose, with anything that quantifies nicely probabilistically. Modal plausibilities and Bayesian probabilities appear to live in different kingdoms, not unlike my IT-1 (information theory intimately connected with probability theory) and IT-2 (information theory as it relates to data compression).

Stefan

Good -- I am wrestling with this too. I thought the idea of "modal information" or "Baconian information" might be interesting to you -- an approach that doesn't mesh with probability, but is independently worthwhile. Spohn thinks that rank is exactly this (though I have not seen him make the connection with information, the 'entrenchment semantics' seems to me to do just that).

Ranks don't mesh with probabilities, unless you use the infinitesimal semantics. The theme of the talk was that there really are these two different notions. Yet I refuse to let things stand at that -- there has to be some link. At present, the best I can do is an informal link, interpreting ranks as orders-of-magnitude of probability...

Paul
*** kickstart
We want to (a) know things and (b) come to know things. According to
Bayesian epistemology, knowing things corresponds to being able to
partition epistemic space and evaluating it quantitatively.
This evaluation happens on the basis of evidence, or more basic, on
the basis of information. Use the example of physics:
http://www.philosophynow.org/issue82/Hawking_contra_Philosophy. Debate
about multiverses. 
*** information, and only information, can 
be copied. <2011-02-25 Fri>
** quotes
*** Aristotle
**** Nicomachean Ethics
Here, as in all other cases, we must set down the appearances
(phainomena) and, first working through the puzzles (diaporesantas),
in this way go on to show, if possible, the truth of all the beliefs
we hold about these experiences; and, if this is not possible, the
truth of the greatest number and the most authoritative. For if the
difficulties are resolved and the beliefs are left in place, we will
have done enough showing. (NE VII, 1145b1ff)
*** Avenarius, Richard
***** die Gesamtheit des in der Erfahrung Gegebenen 
mit dem geringsten Kraftaufwand zu denken (Richard Avenarius
inspirierte die Figur des Professor Avenarius im Roman Die
Unsterblichkeit von Milan Kundera.)
*** Bar-Hillel, Yehoshua, and Carnap, Rudolf
see article Semantic Information in keep-2011
*** Burgin, Mark
**** burgin09
***** definition of information in 
Burgin, 316, according to Carnap and Bar-Hillel. Very interesting.
E.g. The more probable a statement is, the less information it
conveys, 320.
*** Chalmers, David
**** scenarios constitute epistemic space. If a subject 
did not know anything, all scenarios would be epistemically possible
for the subject. When a subject knows something, some scenarios are
excluded. Every piece of substantive knowledge corresponds to a
division in epistemic space: some scenarios are excluded out as
epistemically impossible for the subject, while others are left open.
(David Chalmers, The Nature of Epistemic Space, 2)
**** In epistemic logic and the theory 
of belief revision, it is common to model epistemic possibility using
epistemic relations to an underlying space of pos- sible worlds. The
same goes for the theory of subjective probability: a subject’s
credences are usually taken to be distributed over a space of
epistemically possible worlds. (David Chalmers, The Nature of
Epistemic Space, 2)
**** Instead, we should try to understand epistemic possibility 
on its own terms. We are not dealing here with counterfactual space:
the space of ways things might have been. Here, we are dealing with
epistemic space: the space of ways things might be. This epistemic
space calls for its own epistemic tools of analysis. (David Chalmers,
The Nature of Epistemic Space, 3)
**** But the notion of possibility invoked here differs from the notion 
of possibility that is usually associated with possible worlds: it is
a sort of epistemic possibility, whereas possible worlds are usually
understood to be associated with a sort of `metaphysical' possibility.
(David Chalmers, The Nature of Epistemic Space, 10)
**** Prima facie, this situation suggests that there is no good candidate 
to be the cardinality of the set of all worlds, and that there may be
no such set. Kaplan’s paradox [see Modality, morality, and belief:
essays in honor of Ruth Barcan Marcus, 44f, title A problem in
possible-world semantics] arises at least as strongly when worlds and
propositions are replaced by scenarios and intensions. If anything,
the situation is worse. (David Chalmers, The Nature of Epistemic
Space, 35)
**** In Counterfactuals, Lewis suggests that the cardinality of 
the space of worlds might be beth2 , for reasons tied to the character
of spacetime. But it is hard to see why our spacetime should restrict
the space of worlds. (David Chalmers, The Nature of Epistemic Space,
37)
*** Halpern, Joseph
**** Another famous justification of probability is 
due to Cox (1946), who showed that any function that assigns degrees
to events and satisfies certain minimal properties (such as the degree
of belief in U is a decreasing function in the degree of belief in U)
must be isomorphic to a probability measure. Unfortunately, Cox's
argument is not quite correct as stated; his hypotheses need to be
strengthened (in ways that make them less compelling) to make it
correct [Halpern 1999a; Halpern 1999b; Paris 1994]. (Reasoning About
Uncertainty, 65)
**** Given this intuition, it is perhaps not surprising 
that there are proponents of maximum entropy and relative entropy who
recommend that if an agent's information can be characterized by a set
C of constraints, then the agent should act "as if" the probability is
determined by the measure that maximizes entropy relative to C (i.e.,
the measure that has the highest entropy of all the measures in C).
Similarly, if the agent starts with a particular measure . it and gets
new information characterized by C, he should update to the measure
,a' that satisfies C such that the relative entropy between and ,u is
a minimum. Maximum entropy and relative entropy have proved quite
successful in a number of applications, from physics to
natural-language modeling. Unfortunately, they also exhibit some
counterintuitive behavior on certain applications. Although they are
valuable tools, they should be used with care.(Reasoning About
Uncertainty, 110)
**** [For the correspondence of ME and RW 
(random worlds) and their overlap in the unary case, whereas RW also
covers the nonunary case, see pp416--420. For the origin of the RW
approach see p. 429.]
*** Mach, Ernst
**** Die ökonomische Natur der physikalischen Forschung
***** Sowohl die Mitteilung als das Bedürfnis des 
Einzelnen, seine Erfahrungssumme mit dem kleinsten Gedankenaufwand zu
beherrschen, zwingt zu ökonomischer Ordnung. Hiermit ist aber auch die
ganze rätselhafte Macht der Wissenschaft erschöpft. Im einzelnen mag
sie uns nichts zu bieten, was nicht jeder in genügend langer Zeit auch
ohne alle Methode finden könnte.
(http://www.gleichsatz.de/b-u-t/trad/mach2.html)
*** Quine, WVO
**** Two Dogmas
***** the plan was that qualities should be assigned to point-instants in such 
a way as to achieve the laziest world compatible with our experience.
The principle of least action was to be our guide in constructing a
world from experience. (37)
* before fall 2010
** aufbau
1) Information and Probability
2) Information and Divergence
3) Information and Complexity
4) Information and Philosophy
** quotes
*** ingardenurbanik62
**** information seems intuitively a much simpler and 
more elementary notion than that of probability. It gives more a
cruder and global description of some situations physical or other
than probability does. Therefore, information represents a more
primary step of knowledge than that of cognition of probabilities
(just as probability description is cruder and more global than
deterministic description). Furthermore, a prinicipal separation of
notions of probability and information seems convenient and useful
from the point of view of statistical physics. In physics there
prevail situations where information is known (e.g.\ entropy of some
macroscopic systems) and may be measured with a high degree of
accuracy, whereas probability distribution is unknown and practically
cannot be measured at all {\ldots} Finally, it may be remarked that a
new axiomatic definition of information, free of the inessential
connection with probability, clears the way for future generalizations
of this notion. (ingardenurbanik62:136)
*** bernardo79
**** This pragmatic approach led to
Jose M. Bernardo's suggestion of Reference Posterior Distributions.
{\rppd}s agree with the Principle of Maximum Entropy in applicable
cases and thus also with the Principle of Indifference. Instead of
measuring and maximizing missing information, however, {\rppd}s
measure and maximize expected information. Let $p(\theta)$ be our
prior density. Then the expected information IE is:
\begin{displaymath} \mbox{IE}=\int p(x)\int p(\theta\vert
x)\log\frac{p(\theta\vert x)}{p(\theta)}d\theta\, dx \end{displaymath}
where $p(x)=\int p(x\vert\theta)p(\theta)d\theta$ and $p(\theta\vert
x)=p(x\vert\theta)p(\theta)/p(x)$ (Bernardo, 1979, p115). Again,
$p_{k}=\frac{1}{n}$ for the straightforward discrete case, but this
time we also learn that for the continuous case the distribution which
maximizes expected information is the normal distribution. (my priors
paper)
*** clarkebarron90
**** The relative entropy is a mathematical expression 
that admits several different interpretations in information theory
and statistics. These include the redundancy in source coding
problems, the risk in statistical estimation, and the error exponents
in hypothesis testing, among others. (clarkebarron90:453)
**** It is seen that $D(P^{n}_{\theta}\|M_{n})$ is 
a) the cumulative risk of Bayes' estimators of the density function,
b) the redundancy of a source code based on $M_{n}$, c) the exponent
of error probability for Bayes' tests of a simple versus composite
hypothesis, and d) a bound on the financial loss in a stock-market
portfolio selection problem. (clarkebarron90:455)
*** goguen97
**** It is said that we live in an 
Age of Information, but it is an open scandal that there is no theory,
nore even definition, of information that is both broad and precise
enough to make such an assertion meaningful. (goguen97:27)
*** guiasu77
**** Therefore, the continuous entropy $H_{\rho}$ may be interpreted 
as being (up to an additive constant) the variation of information
when we pass from the initial uniform probability distribution on the
interval $[a,b]$ to the new probability measure defined by the
probability distribution function $\rho(x)$ (any such a probability
measure is absolutely continuous with respect to the uniform
probability distribution on the interval $[a,b]$). Thus, we can
utilize, in the continuous case, Boltzmann's continuous entropy as
well as Shannon Entropy in the discrete case, both being interpreted
as the variation of information when we pass from the initial uniform
distribution to the corresponding probability measures. (guiasu77:28)
**** Theorem 3.1 shows that though the usual logical order, according 
to which information is defined by means of probability, can be
reversed, and one can introduce information first, without using
probabilities, probabilities inevitably come in at a later stage. The
fact that a theory which starts with the aim of defining information
without probability leads to the proof of the existence of probability
supports the view that the notion of information cannot be separated
from that of probability. To each event $A$ there correspond two
numbers: its probability $p(A)$ and its information content $I(A)$
which are connected by the formulas $I(A)=\log_{e}\frac{1}{p(A)},
p(A)=e^{-I(A)}$ (guiasu77:36f)
*** hjorland07
**** [objective versus subjective understanding of 
information] (hjorland07:1449)
**** The problem is also about whether problems of 
information science are best served with theories like Shannon and
Weaver's information theory or with theories more related to
semiotics. In the history of information science, the tendency has
been a development from information theory toward more semiotic
theories. (See also Werzig, 2003.) (hjorland07:1455)
*** jaynes57
**** the maximum-entropy distribution may be asserted for the
positive reason that it is uniquely determined as the one which is
maximally noncommittal with regard to missing information, instead of
the negative one that there was no reason to think otherwise
(Jaynes, 1957, p623)
**** there is nothing in the general
laws of motion that can provide us with any additional information
about the state of a system beyond what we have obtained from
measurement (Jaynes, 1957, 624)
*** khinchin57
*** kolmogorov68
**** the need for attaching definite meaning 
to the expressions $H(x|y)$ and $I(x|y)$, in the case of individual
values $x$ and $y$ that are not viewed as a result of random tests
with a definite law of distribution, was realized long ago by many who
dealt with information theory. (kolmogorov68:662)
**** The meaning of the new definition is very simple. Entropy 
$H(x|y)$ is the minimal length of the recorded sequence of zeros and
ones of a \qnull{program} $P$ that permits construction of the value
of $x$, the value of $y$ being known {\ldots} Although Martin-L{\"o}f
and I realized the importance of the new concept, the development was
hindered because the simplest formulas that can be produced as a
result of simple algebraic transposition of (1) [Shannon's Entropy]
could not be derived from the new definitions (kolmogorov68:662)
**** The preceding rather superficial discourse should 
prove two general theses: 1) Basic information theory concepts must
and can be founded without recourse to the probability theory, and
such a manner that \qnull{entropy} and \qnull{mutual information}
concepts are applicable to individual values. 2) Thus introduced,
information theory concepts can form the basis of the term random,
which naturally suggests that random is the absence of periodicity.
(kolmogorov68:663f)
**** by using probability theory, we resort to 
considerably rougher generalization. A realistic interpretation of
probability results is always statistical, and error estimates are
considerable rougher that in the information theory exposition
developed by us. (kolmogorov68:664)
**** Credit for noting this relatively simple condition 
evidently belongs to Solomonov and me. (kolmogorov68:664) [compare
Matthew Effect]
*** kolmogorov68a
**** Discussions of information theory do not go into this 
combinatorial approach at any length, but I consider it important to
emphasize its logical independence of probabilistic assumptions.
(kolmogorov68a:158)
**** If we make the variable $x$ and $y$ \qnull{random variables} 
with given joint probability distributions, we can obtain a
considerably richer system of concepts and relationships
(kolmogorov68a:161)
**** {\ldots} War and Peace {\ldots} 
(kolmogorov68a:162)
*** loeve55
**** Probability Theory
Synopsis:

(i) Constructive definition of conditional expectation:

\begin{displaymath}
  E_{B}X=\int_{B}XdP
\end{displaymath}

or, equivalently,

\begin{displaymath}
  P(B)E_{B}X=\int_{B}XdP
\end{displaymath}

then define

\begin{displaymath}
  P_{B}A=E_{B}I_{A}
\end{displaymath}

[page 338, more detail 339f]

(ii) the constructive definition fails if partition is not countable
-> use Radon-Nikodym

conditional expectation is a function for which

\begin{displaymath}
  \int_{N}(E^{\mathcal{B}}X)dP=\int_{B}XdP
\end{displaymath}

and

\begin{displaymath}
  P^{\mathcal{B}}=E^{\mathcal{B}}I_{A}
\end{displaymath}

or

\begin{displaymath}
  \int_{B}(P^{\mathcal{B}}A)dP_{\mathcal{B}}=PAB
\end{displaymath}

[page 341]

(iii) then show that the generalized definition accords with the
intuitive, constructive definition where applicable
*** solomonov64
**** That these kinds of models might be valid is 
suggested by \qnull{Occam's Razor,} one interpretation of which is that
the more \qnull{simple} or \qnull{economical} of several hypotheses is
the more likely. Turing machines are then used to explicate the
concepts of \qnull{simplicity} or \qnull{economy}---the most
\qnull{simple} hypothesis being that with the shortest
\qnull{description.} (solomonov64:3)
**** It is possible to devise a complete theory of 
inductive inference using Bayes' Theorem, if we are able to assign an
a priori probability to every conceivable sequence of symbols. In
accord with this approach, it is felt that sequences should be given
high a priori probabilities if they have shortest descriptions and/or
many different descriptions {\ldots} any regularity in a corpus may be
utilized to write a shorter description of that corpus {\ldots} the
high a priori probability assigned to a sequence with a short
description corresponds to one possible interpretation of
\qnull{Occam's Razor.} The assignment of high a priori probabilities
to sequences with many descriptions corresponds to a feeling that if
an occurrence has many possible causes, then it is more likely.
(solomonov64:7)
**** Suppose that all of the sensory observations 
of a human being since his birth were coded in some sort of uniform
digital notation and written down as a long sequence of symbols. Then,
a model that accounts in an optimum manner for the creation of this
string, including the interaction of the man with his environment, can
be formed by supposing that the string was created as the output of a
universal machine of random input. (solomonov64:13)
**** The laws of science that have been discovered 
can be viewed as summaries of large amounts of empirical data about
the universe. (solomonov64:15)
*** turing37
**** Turing (1937) has shown that it is impossible 
to devise a Turing machine that will always be able to tell, in a
finite time, whether an arbitrary string will be \qnull{meaningful}
for another particular universal Turing machine. (solomonov64:9f)
*** wallacedowe99
**** The aim in this stream is to find the hypothesis
$H$ which leads to the shortest such stream $I$, which may be regarded
as the shortest message encoding the data given in $S$ {\ldots} The
minimization of #I [length of the program which reproduces the data
$S$] is, as shown by the equation above, equivalent to maximization of
$h(H) x f(S|H)=Prob(H,S)$, i.e. the joint probability of hypothesis
and data. It is thus formally equivalent to choosing the hypothesis of
highest Bayesian posterior probability given $S$. (271f) [nice summary
on 270 of Kolmogorov Complexity and Turing machines]
*** zhulu04
**** We should also note that, counter-intuitively, non-informative 
priors and flat priors (such as the uniform distribution) do not
coincide (cf.\ Mu and Zhu, 2004)
**** The lesson from this discussion is extremely 
interesting; it tells us that flat priors (such as the uniform prior)
are not always the same thing as non-informative priors. A seemingly
informative prior can actually be quite weak in the sense that it does
not influence the posterior opinion very much. It is clear in our
example that the MLE is the result of using a weak prior, whereas the
most intuitive non-informative prior (the uniform prior) is not as
weak or non-informative as one would have thought. (6)
** links
*** information theory
http://en.wikipedia.org/wiki/Algorithmic_information_theory
http://en.wikipedia.org/wiki/Kolmogorov_complexity
http://en.wikipedia.org/wiki/Kullback–Leibler_divergence
http://en.wikipedia.org/wiki/Minimum_message_length
http://en.wikipedia.org/wiki/Bayesian_information_criterion
** ideas
*** information epistemology is an 
epistemology of ignorance rather than an epistemology of knowledge,
which suits me just right.
*** Kolmogorov's frustration with probability theory comes 
from a different place that Ingarden's or Kampe's. He wants an
information density  measure that applies to individual sequences of
symbols rather than to the probability distributions behind the
sequences of symbols.
*** math results
1) Shannon Entropy is unique khinchin57:9
2) It doesn't matter what Turing machine we use
3) The uniform distribution has the highest Shannon Entropy guiasu77:3
4) H(x|y) is a generalization of Shannon Entropy for the continuous
   case guiasu77:19ff
5) Ingarden and Kampe de Feriet guiasu77:29ff and guiasu77:37ff,
   kampe67, ingardenurbanik62
6) the normal distribution contains the largest amount of uncertainty
   guiasu77:299 with good quote, proof is due to kampe63, similar
   result with respect to Poisson distribution ingardenkossakowski71,
   see guiasu77:301
7) use Radon-Nikodym derivative to define conditional probability
   because intuition fails in some cases see loeve55:338ff
8) Chaitin's Incompleteness Theorem
9) Shannon's Entropy is defined by KLD
*** philsophical musings
The world is full of specificity and unknowns, as it is full of
possibilities and eigenheit. (Harry Potter and the Prisoner of
Azkaban, Harry's patronus.)

If all is indifferent, there is no information. All there is is
entropy, the end of time. If all we have ever believed turns out to be
false, there is an infinity of information. This lack of entropy
altogether must be the closest approximation of Dante's Hell, of
Leibniz's Demon. We are, hopefully, somewhere in the middle between
total entropy and total information, somewhere between givens and
possibilities. It appears to be a feature of life that things are one
way and not another (call it truth, call it information) and that they
are not fixed yet (call it choices, call it probability).

This is the age of information, yet we know little and care little
about the meaning of information. Beginning in the forties and
petering out in the seventies, there was great interest in information
theory, fueled no doubt by the British and American mathematicians who
cracked the Japanese and the German codes. Then the interest
waned, or moved over to the engineers, when Turing's Halting Problem
halted algorithmization of information theory as G"odel's
Incompleteness Theorem halted TBA. Nothing in so dramatic a fashion
ever happened to probability theory, and so it still holds
epistemological attention, and so there is little we know yet about
the limits of its language.

We return to the reasons why information theory may have
epistemological primacy over probability theory: there is a
mathematical definition of its limits, as there is for logic in
G"odel's Incompleteness Theorem. There is an intuitive relation to
complexity, which in some way is the only thing which enables us to
assess the significance (the `bigness') of a thing. It is the only
physical property we can scale, and thus the law of entropy becomes to
us one of the most fundamental laws of nature. One day we may
understand the physicality of our world entirely by means of
information. Quantum mechanics undermines our faith in the continuous
fluidity of matter, but it seems to support the ideas we have of
informational states. Chesterton's prayer of gratitude in The Poet and
the Lunatic may yet need to be understood in new ways: ``Thank God for
hard stones; thank God for hard facts; thank God for thorns and rocks
and deserts and long years. At least I know now that I am not the best
or strongest thing in the world. At least I know now that I have not
dreamed of everything.''
*** there is also a convergence between physics and epistemology 
if information or entropy are recognized as fundamental notions.
*** is there a Dutch-book equivalent for
information?
*** experimental design
Design your experiment so that the evidence (the data) will be
information-rich and the hypothesis will be information-poor (see Jose Bernardo).
*** perl zipping program
generate 0 1 bernoulli sequence, once with p=.5, once with p=.9, and
then zip it
*** Model-Fitting
I have some data and a set of models for the data. Strategies:

(1) Likelihood Ratio Test
http://en.wikipedia.org/wiki/Likelihood-ratio_test

(2) Bayes Factor
http://en.wikipedia.org/wiki/Bayes_factor -- guards against overfitting

(3) Minimum Message Length
http://en.wikipedia.org/wiki/Minimum_message_length

(4) Kullback's Minimum Discrimination Information
*** Minimum message length (MML) is a formal information theory 
restatement of Occam's Razor: even when models are not equal in
goodness of fit accuracy to the observed data, the one generating the
shortest overall message is more likely to be correct (where the
message consists of a statement of the model, followed by a statement
of data encoded concisely using that model). MML was invented by Chris
Wallace, first appearing in the seminal (Wallace and Boulton, 1968).
(see http://en.wikipedia.org/wiki/Minimum_message_length)
*** The idea of Kullback–Leibler divergence as discrimination information 
led Kullback to propose the Principle of Minimum Discrimination
Information (MDI): given new facts, a new distribution f should be
chosen which is as hard to discriminate from the original distribution
f0 as possible; so that the new data produces as small an information
gain DKL( f || f0 ) as possible. (see
http://en.wikipedia.org/wiki/Kullback–Leibler_divergence)
*** Solomonoff, who focused on prediction using his invention of 
the universal a priori probability distribution
*** Incomputability of Kolmogorov complexity
The first result is that there is no way to effectively compute K.
Theorem. K is not a computable function. (see
http://en.wikipedia.org/wiki/Kolmogorov_complexity)
*** Chaitin's incompleteness theorem
We know that, in the set of all possible strings, most strings are
complex in the sense that they cannot be described in any
significantly "compressed" way. However, it turns out that the fact
that a specific string is complex cannot be formally proved, if the
string's complexity is above a certain threshold. (see
http://en.wikipedia.org/wiki/Kolmogorov_complexity)
*** in algorithmic information theory, the invariance theorem, originally proved by 
Ray Solomonoff, states that a universal Turing machine provides an
optimal means of description, up to an additive constant.
*** Gettier cases
Miller believes that someone in his office owns a Ford. He doesn't own
a Ford, but he has Jones' reliable testimony that Jones owns a Ford.
It turns out that Jones doesn't own a Ford (he was lying, in this
case), but Smith does (who has been lying and claiming that he owns a
Chevrolet). Now consider someone telling Miller:

(X) Someone in your office owns a Ford.

Miller will think that (X) contains no information. He thinks he
already knows (X). Yet it turns out that (X) contains information
referring to the way in which Miller's belief is not properly
connected to the truth. (Imagine someone saying, ``Someone in your
office owns a Ford,'' with the right kind of intonation, intimating
that Miller's belief that Jones owns a Ford is false.) All the
problems of the conceptual analysis of knowledge remain the same.

Take, for example, a simple form of Nozick's analysis. Here, knowing
(X) means that (i) Miller believes (X), (ii) (X) is true, (iii) if (X)
were not true, Miller wouldn't believe (X), and (iv) if (X) were true
in a slightly different way, Miller would believe (X). (iii) fails,
because Miller would continue to believe (X) even if Smith didn't own
a Ford. What information does (X) add?
*** Mutual information can be expressed as the average Kullback–Leibler divergence 
(information gain) of the posterior probability distribution of X
given the value of Y to the prior distribution on X (wikipedia on
information theory)
*** information density
***** information density has as little 
practicality to it as Bayesian epistemology. Scientists are not known
to hunker down with their calculators, plugging in priors and
likelihoods to figure out posteriors. What Bayesian epistemology does
is give us a pattern of thought and belief revision. Given various
alternative hypotheses, it is still our intuition, informed by
information density epistemology, that needs to make the call.
***** if information is the primary notion 
behind knowledge, understanding, evidence, or explanation, then there
is a Wittgensteinian point here: there is not /more/ to be explained
about the world other than that things are one way and not another.
This is also a Humean point.
***** if I am right, this would be a bit of a 
resurrection for positivism. I may not be right. A philosopher's ideas
have no need to turn into his opinions. The best theories are those
that keep the information density at a maximum. What is your best
theory after the first sunrise, what after your second sunrise, what
after sunrise no. 1000. Information density operates on the same
principles as file compression.
***** it is not inconsistent to believe in 
a contradiction, but it is likely to violate the maximum information
density principle. A world in which a contradiction would be true
might be unnecessarily complicated. Sometimes, however, you may have
to believe in a contradiction to make sense of the world at all.
*** What matters is belief revision, not knowledge 
acquisition. (The Bayesians are right, Williamson is wrong.) If, which
is rare, probability language applies, rationality is coextensive with
Bayesianism. If not, there must be a conversation about which belief
systems are less inconsistent. If, as is likely the case, there is no
appropriate measure of inconsistency (inconsistent may be an adjective
that does not allow comparatives), we may refer to information
density. Generally, disagreement arises over what the evidence and
what the hypothesis are, rather than how well-fitted the hypothesis is
to the evidence. In other (Quinean) words, the evidence is never
fixed. If you doubt my conclusion, you are as likely to question my
evidence as you are to question my fitting procedure. There is no
primacy of doubting the validity of the argument versus doubting the
validity of the premises.
*** Quantitative Bayesian belief analysis is 
like political analysis in terms of dollar amounts and number of
voters. It can only go so far and definitely not the whole way.
*** diachronische vernetztheit, eigenheit of the world, evidence.org
*** rephrase Leibniz: Why is there something and not rather nothing? Why is 
there information and not rather total entropy?
*** defining the size of objects by their complexity
see Marilynne Robinson and the brain
*** Information is directly related to 
complexity, which in some way is the only thing which enables us to
assess the significance (the \qnull{bigness}) of a thing. It is the
only physical property we can scale, and thus the law of entropy
becomes to us one of the most fundamental laws of nature (entropy is
also the only quantity in the physical sciences that seems to imply a
particular direction for time). Information epistemology implies a
sense of convergence between physics and philosophy, for example in
the correspondence between Boltzmann's entropy and Shannon's entropy.
One day we may understand the physicality of our world entirely by
means of information. Quantum mechanics undermines our faith in the
continuous fluidity of matter, but it seems to support the ideas we
have of informational states. But information density and
*** I dedicate this paper to X whose 
relationship with me is proof that transmission across the noisy
channels of marriage and family is possible and can, at times, be intimate.
