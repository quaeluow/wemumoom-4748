The Principle of Maximum Entropy
and a Problem in Probability Kinematics
1. Introduction
There are cases in which, given evidence, we cannot use Bayes’ formula to
deliver a set of posterior probabilities given a set of prior probabilities. The
Bayesian method presupposes that evidence comes in the form of an event. As
Richard Jeﬀrey observes, however, the evidence may not relate the certainty
of an event but a reassessment of its uncertainty or its probabilistic relation
to other events (see Jeﬀrey 1965, 153ﬀ), expressible in a shift in expectation
(see Hobson 1971). Bas van Fraassen has come up with a good example from
the 1980 comedy ﬁlm Private Benjamin (see van Fraassen 1981), in which
Goldie Hawn portrays a Jewish-American woman (Judy Benjamin) who joins
the U.S. Army.
In the movie, Judy Benjamin is on an assignment and lands in a place
where she is not sure of her location. She is on team Blue. Because of the
map, her probability of being in Blue territory equals the probability of being
in Red territory, and being in the Red Second Company area equals the
probability of being in the Red Headquarters area. Her commanders inform
Judy by radio that in case she is in Red territory, her chance of being in
their Headquarters area is three times the chance of being in their Second
Company area. A straightforward use of the Bayesian formula is not in the
cards, because there is no immediately obvious event space in which we can
condition on an event E.
Blue (Second Company) Blue (Headquarters)
Red (Second Company) Red (Headquarters)
A 1 A 2
A 3
Figure 1: Judy Benjamin’s map. Blue territory (A 3 ) is friendly
and does not need to be divided into a Headquarters and a
Second Company area.
Largely in the ﬁeld of physical statistics (but also in others, for an im-
pressive (and outdated) list see Shore and Johnson 1980, 26), problems like
the Judy Benjamin problem occur frequently and are usually solved using
the principle of maximum entropy, maxent from now on. The constraint
imposed by the evidence transforms the prior probability distribution in a
way that secures minimal information gain. We want a posterior probability
distribution that reﬂects the evidence but does not provide more information
than necessary. If the prior probability distribution is uniform, this principle
is called the principle of maximum entropy; if it is not uniform, it is also
called the infomin principle, the principle of minimal discrimination, or the
principle of minimum cross-entropy. The mathematics leading to the solution
of these types of problems is elegant and has compelling properties, outlined
in a seminal article by John E. Shore and Rodney W. Johnson (1980).
The goal of this paper is to undermine the notion that maxent ’s sug-
gested solution for the Judy Benjamin problem is counter-intuitive. We will
show that another intuitive approach, the powerset approach, lends signif-
icant support to the solution provided by maxent for the Judy Benjamin
problem. Our argument is vaguely related to Jaynes’ use of the Wallis deriva-
tion to justify maxent in Jaynes and Bretthorst 1998, 351ﬀ. The intuition
that maxent ’s solution for the Judy Benjamin problem violates (we will
call it T1) is based on fallacious independence and uniformity assumptions.
There is another powerful intuition (we will call it T2) in direct contradiction
to T1 which maxent obeys.
2. Two Intuitions
There are two pieces of information relevant to Judy Benjamin when she
decides on her posterior probability assignment. We will call them (MAP)
and (HDQ). As in ﬁgure 1, A 1 is Red’s Second Company area, A 2 is Red’s
Headquarters area, A 3 is Blue territory. Judy presumably wants to be in Blue
territory, but if she is in Red territory, she would prefer their Second Company
area (where enemy soldiers are not as well-trained as in the Headquarters
area).
(MAP)  Judy has no idea where she is. She is on team Blue. Because of the
map, her probability of being in Blue territory equals the probability
of being in Red territory, and being in the Red Second Company area
equals the probability of being in the Red Headquarters area.
(HDQ)  Her commanders inform Judy that in case she is in Red territory, her
chance of being in their Headquarters area is three times the chance of
being in their Second Company area.
In formal terms (sloppily writing A i for the event of Judy being in A i ),
2 · P (A 1 ) = 2 · P (A 2 ) = P (A 3 ) (MAP)
q = P (A 2 |A 1 ∪ A 2 ) =
3
4
(HDQ)
(HDQ) is partial information because in contrast to the kind of evidence we
are used to in Bayes’ formula (such as ‘an even number was rolled’), and
to the kind of evidence needed for Jeﬀrey’s rule (where a partition of the
whole event space and its probability reassignment is required, not only A 1 ∪
A 2 , but see here the objections in Douven and Romeijn 2009), the scenario
suggests that Bayesian conditionalization and Jeﬀrey’s rule are inapplicable.
We are interested in the most defensible posterior probability assignment(s)
(it is contentious if there is only one of them and if it or they can be called
reasonable) and will express them in the form of a normalized odds vector
(q 1 , q 2 , q 3 ), following van Fraassen (1981). q i is the posterior probability Q(A i )
that Judy Benjamin is in A i (let P be the prior probability distribution and
p i the individual prior probabilities). The q i sum to 1 (this diﬀers from van
Fraassen’s canonical odds vector, which is proportional to the normalized
odds vector but has 1 as its ﬁrst element). We deﬁne
t =
q
1 − q
t is the factor by which (HDQ) indicates that Judy’s chance of being in A 2
is greater than being in A 1 . In Judy’s particular case, t = 3 and q = 0.75.
Van Fraassen found out with various audiences that they have the following
intuition:
T1  (HDQ) does not refer to Blue territory and should not aﬀect P (A 3 ):
q 3 = p 3 (= 0.50).
There is another, conﬂicting intuition (due to Peter Williams via personal
communication with van Fraassen, see van Fraassen 1981, 379):
T2  If the value of q approaches 1 (in other words, t approaches inﬁnity)
then q 3 should approach 2/3. (HDQ) would turn into ‘if you are in
Red territory you are almost certainly in the Red Headquarters area.’
Considering (MAP), q 3 should approach 2/3. Continuity considerations
pose a contradiction to T1.
To parse these conﬂicting intuitions, we will introduce several methods to
provide G, the function that maps q to the appropriate normalized posterior
odds vector (q 1 , q 2 , q 3 ). The ﬁrst method is extremely simple and accords with
intuition T1: G ind (q) = (0.5(1 − q), 0.5q, 0.5). In Judy’s particular case with
t = 3 the normalized odds vector is (ind stands for independent):
G ind (0.75) = (0.125, 0.375, 0.500)
Both Grove and Halpern (1997) as well as Douven and Romeijn (2009) make
a case for this distribution, Grove and Halpern by using Bayesian condition-
alization on the event of the message being transmitted to Judy, Douven and
Romeijn by using Jeﬀrey’s rule (because they believe that T1 is in this case
so strong that Q(A 3 ) = P (A 3 ) is as much of a constraint as (MAP) and
(HDQ), yielding a Jeﬀrey partition). T1, however (and not unbeknownst to
these authors), conﬂicts with the symmetry requirements outlined in van
Fraassen et. al. (1986).
Van Fraassen introduces various updating methods which do not con-
ﬂict with those symmetry requirements, the most notable of which is max-
ent . Shore and Johnson have already shown that, given certain assumptions
(which have been heavily criticized, however, e.g. Uﬃnk 1996), maxent pro-
duces a unique posterior probability assignment. The minimum information
discrimination theorem of Kullback and Leibler (see, for example, Csisz´ar
1967,  section  3)  demonstrates  how  Shannon’s  entropy  and  the  Kullback-
Leibler Divergence formula can provide the least informative posterior proba-
bility assignment (with reference to the prior probability assignment) obeying
the constraint posed by the evidence. We will show how this is done in the
next section. The idea is to deﬁne a space of probability distributions, make
sure that the constraint identiﬁes a closed, convex subset in this space, and
then determine which of the distributions in the closed, convex subset is least
distant from the prior probability distribution in terms of information (using
the minimum information discrimination theorem). It is necessary for the
uniqueness of this least distant distribution that the subset be closed and
convex (in other words, that the constraints be aﬃne, see Csisz´ar 1967).
For Judy Benjamin, maxent suggests the following normalized odds vec-
tor:
G max (0.75) ≈ (0.12, 0.35, 0.53) (1)
The posterior probability of being on Blue territory (A 3 ) has increased from
50% to approximately 53%. Grove and Halpern ﬁnd this result “highly counter-
intuitive” (Grove and Halpern 1997, 2). Van Fraassen summarizes the worry:
It is hard not to speculate that the dangerous implications of being in the
enemy’s Headquarters area are causing Judy Benjamin to indulge in wishful
thinking, her indulgence becoming stronger as her conditional estimate of
the danger increases. (Van Fraassen 1981, 379)
There are two ways in which we can arrive at result (1). We may either use
Jaynes’ constraint rule and ﬁnd the posterior probability distribution that is
both least informative with respect to Shannon’s entropy and in accordance
with the constraint (using Dempster’s Rule of Combination, which together
with the constraint rule is equivalent to the principle of minimum cross-
entropy, see Cover and Thomas Cover and Thomas 2006, 409, exercise 12.2.),
or use the Kullback-Leibler Divergence and diﬀerentiate it to obtain where
it is minimal.
3. The Constraint Rule
There are two ways in which we can arrive at result (1).
We may either use Jaynes’ constraint rule and ﬁnd the posterior probabil-
ity distribution that is both least informative with respect to Shannon’s en-
tropy and in accordance with the constraint (using Dempster’s Rule of Com-
bination, which together with the constraint rule is equivalent to the principle
of minimum cross-entropy, see Cover and Thomas Cover and Thomas 2006,
409, exercise 12.2.), or use the Kullback-Leibler Divergence and diﬀerentiate
it to obtain where it is minimal.
Before we dive into the constraint rule (which has the advantage of work-
ing even when the derivative of the Kullback-Leibler Divergence is diﬃcult
to ﬁnd), we go the easier route of the second method. The Kullback-Leibler
Divergence is
D(Q, P ) =
m
X
i=1
q i log
q i
p i
We ﬁll in the explicit details from Judy Benjamin’s situation and diﬀer-
entiate the expression to obtain the minimum (by setting the derivative to
0).
∂
∂q 1
(q 1 log 2 (4q 1 ) + tq 1 log 2 (4tq 1 ) + (1 − (t + 1)q 1 ) log 2 2(1 − (t + 1)q 1 )) = 0
The resulting expression for G max is
G max (q) =
 C
1 + Ct + C
, t
C
1 + Ct + C
, 1 − (t + 1)
C
1 + Ct + C

where
C = 2
−
t log
2
t+t+1
1+t
The remainder of this section is less relevant to the aim of my paper
and can be skipped. It provides a concise but comprehensive summary of
Jaynes’ constraint rule not easily obtainable in the literature. Jaynes applied
it to the Brandeis Dice Problem (see Jaynes 1989, 243), but does not give a
mathematical justiﬁcation.
Let f be a probability distribution on a ﬁnite space x 1 , . . . , x m that fulﬁlls
the constraint
m
X
i=1
r(x i )f(x i ) = α (2)
An  aﬃne  constraint  can  always  be  expressed  by  assigning  a  value  to
the expectation of a probability distribution (see Hobson 1971). In Judy
Benjamin’s case, for example, let r(x 1 ) = 0, r(x 2 ) = 1, r(x 3 ) = q and α = q.
Because f is a probability distribution it fulﬁlls
m
X
i=1
f(x i ) = 1 (3)
We want to maximize Shannon’s entropy, given the constraints (2) and
(3),
−
m
X
i=1
f(x i ) ln(x i ) (4)
We use Lagrange multipliers to deﬁne the functional
J(f) = −
m
X
i=1
f(x i ) ln f(x i ) + λ 0
m
X
i=1
f(x i ) + λ 1
m
X
i=1
r(x i )f(x i )
and diﬀerentiate it with respect to f(x i )
∂J
∂f(x i )
= − ln(f(x i )) − 1 + λ 0 + λ 1 r(x i ) (5)
Set (5) to 0 to ﬁnd the necessary condition to maximize (4)
g(x i ) = e λ0 −1+λ1r(xi )
This is the Gibbs distribution. We still need to do two things: (a) show
that the entropy of g is maximal, and (b) show how to ﬁnd λ 0 and λ 1 . (a) is
shown in Theorem 12.1.1 in Cover and Thomas (2006) and there is no reason
to copy it here.
For (b), let
λ 1 = −β
Z(β) =
m
X
i=1
e
−βr(xi )
λ 0 = 1 − ln(Z(β))
To ﬁnd λ 0 and λ 1 we introduce the constraint
−
∂
∂β
ln(Z(β)) = α
To see how this constraint gives us λ 0 and λ 1 , Jaynes’ solution of the
Brandeis Dice Problem (see Jaynes 1989, 243) is a helpful example. We are,
however, interested in a general proof that this choice of λ 0 and λ 1 gives
us the probability distribution maximizing the entropy. That g so deﬁned
maximizes the entropy is shown in (a). We need to make sure, however, that
with this choice of λ 0 and λ 1 the constraints (2) and (3) are also fulﬁlled.
First, we show
m
X
i=1
g(x i ) =
m
X
i=1
e λ0 −1+λ1r(xi ) = e λ0 −1
m
X
i=1
e λ1r(xi ) =
e
− ln(Z(β)) Z(β) = 1
Then, we show, by diﬀerentiating ln(Z(β)) using the substitution x = e −β
α = −
∂
∂β
ln(Z(β)) = −
1
P
m
i=1
x r(xi )
  m
X
i=1
r(x i )x r(xi )−1
!
(−x) =
P
m
i=1
r(x i )x r(xi )
P
m
i=1
x r(xi )
And, ﬁnally,
m
X
i=1
r(x i )g(x i ) =
m
X
i=1
r(x i )e λ0 −1+λ1r(x1 ) = e λ0 −1
m
X
i=1
r(x i )e λ1r(x1 ) =
e λ0 −1
m
X
i=1
r(x i )x r(xi ) = αe λ0 −1
m
X
i=1
x r(xi ) = αe λ0 −1
m
X
i=1
e
−βr(xi ) =
αZ(β)e λ0 −1 = αZ(β))e
− ln(Z(β)) = α
Filling in the variables from Judy Benjamin’s scenario gives us result (1).
The lambdas are:
λ 0 = 1 − ln
  m
X
i=1
e λ1r(xi )
!
λ 1 = ln q − ln(1 − q)
We combine the normalized odds vector (0.16, 0.48, 0.36) following from
these lambdas using Dempster’s Rule of Combination with (MAP) and get
result (1).
Figures 2 and 3 show in diagram form the distribution of (q 1 , q 2 , q 3 ) de-
pending on the value of q (between 0 and 1), respectively following intuition
T1 and maxent . Notice that in accordance with intuition T2, maxent pro-
vides a result where q 3 → 2/3 for q approaching 0 or 1.
4. Epistemic Entrenchment
Even though T1 is an understandably strong intuition, it does not take into
account that the information given to Judy by her commanders may be
dependent on whether she is in Blue or in Red territory. To underline this
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0
q 1
q 2
q 3
Figure  2:  Judy  Benjamin’s  posterior  proba-
bility  assignment  according  to  intuition  T1.
0  <  q  <  1  forms  the  horizontal  axis,  the
vertical axis shows the posterior probability
distribution (or the normalized odds vector)
(q 1 , q 2 , q 3 ). The vertical line at q = 0.75 shows
the speciﬁc posterior probability distribution
G ind (0.75) for the Judy Benjamin problem.
objection to intuition T1 we want to consider three scenarios, any of which
may form the basis of the partial information provided by her commanders.
I  Judy was dropped oﬀ by a pilot who ﬂipped two coins. If the ﬁrst coin
landed H, then Judy was dropped oﬀ in Blue territory, otherwise in
Red territory. If the second coin landed H, she was dropped oﬀ in the
Headquarters area, otherwise in the Second Company area. Judy’s com-
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0
q 1
q 2
q 3
Figure 3: Judy Benjamin’s posterior probabil-
ity  assignment  using maxent .  0  <  q  <  1
forms  the  horizontal  axis,  the  vertical  axis
shows  the  posterior  probability  distribution
(or  the  normalized  odds  vector)  (q 1 , q 2 , q 3 ).
The vertical line at q = 0.75 shows the speciﬁc
posterior  probability  distribution  G max (0.75)
for the Judy Benjamin problem.
manders ﬁnd out that the second coin was biased q : 1−q toward H with
q = 0.75. The normalized odds vector is G I (0.75) = (0.125, 0.375, 0.500)
and agrees with T1, because the choice of Blue or Red is completely
independent from the choice of the Headquarters area or the Second
Company area.
II  The pilot randomly lands in any of the four quadrants and rolls a die.
If she rolls an even number, she drops oﬀ Judy. If not, she takes her to
another (or the same, the choice happens with replacement) randomly
selected quadrant to repeat the procedure. Judy’s commanders ﬁnd
out, however, that for A 1 , the pilot requires a six to drop oﬀ Judy, not
just an even number. The normalized odds vector in this scenario is
G II (0.75) = (0.1, 0.3, 0.6) and does not accord with T1.
III  Judy’s commanders have divided the map into 24 congruent rectangles,
A 3 into twelve, and A 1 and A 2 into six rectangles each (see ﬁgures 4 and
5). They have information that the only subsets of the 24 rectangles
in which Judy Benjamin may be located are such that they contain
three times as many A 2 rectangles than A 1 rectangles. The normalized
odds vector in this scenario is G III (0.75) ≈ (.108, .324, .568) (evaluating
almost 17 million subsets).
I–III demonstrate the contrast between scenarios when independence is
true and when it is not. Douven and Romeijn’s capital mistake in their pa-
per is that they assume that the Judy Benjamin problem is analogous to
their example of Sarah and the sundowners at the Westcliﬀ (see Douven
and Romeijn 2009, 7). Sarah, however, knows that whether it rains or not
is independent of her activity the next night, whereas in Judy Benjamin we
have no evidence of such independence, as scenario II demonstrates. Douven
and Romeijn’s reliance on intuition T1 leads them to apply Jeﬀrey’s rule to
the Judy Benjamin problem with the additional constraint Q(A 3 ) = P (A 3 ).
They claim that in most cases “the learning of a conditional is or would be
irrelevant to one’s degree of belief for the conditional’s antecedent . . .  the
learning of the relevant conditional should intuitively leave the probability of
the antecedent unaltered” (Douven and Romeijn 2009, 9). This, according to
Douven and Romeijn, is the usual epistemic entrenchment and applies in full
force to the Judy Benjamin problem. They give an example where the epis-
temic entrenchment could go the other way and leave the consequent rather
than the antecedent unaltered (Kate and Henry, see Douven and Romeijn
2009, 13).
5. The Powerset Approach
In this section, we will focus on scenario III and consider what happens when
the grain of the partition becomes ﬁner. We call this the powerset approach.
Two remarks are in order: (1) The powerset approach has little independent
appeal. The reason behind using maxent is that we want our evidence to
have just the right inﬂuence on our posterior probabilities, i.e. neither over-
inform nor under-inform. There is no corresponding reason why we should
update our probabilities using the powerset approach.
(2) What the powerset approach does is lend support to another approach.
In this task, it is persuasive because it tells us what would happen if we were
to divide the event space into inﬁnitesimally small, uniformly weighed, and
independent ‘atomic’ bits of information. It would be especially interesting
if the powerset approach did not support the independence and uniformity
assumptions of intuition T1, because both of these features are strongly rep-
resented in the powerset approach.
Let’s assume a partition {B i } i=1,...,4n of A 1 ∪ A 2 ∪ A 3 into sets that are
of equal measure µ and whose intersection with A i is either the empty set
or the whole set itself (this is the division into rectangles of scenario III).
(MAP) dictates that the number of sets covering A 3 equals the number of
sets covering A 1 ∪A 2 . For convenience, we assume the number of sets covering
A 1 to be n. Let C, a subset of the powerset of {B i } i=1,...,4n , be the collection
of sets which agree with the constraint imposed by (HDQ), i.e.
C ∈ C iﬀ C = {C j } and tµ

[
C j ∩ A 1

= µ

[
C j ∩ A 2

In ﬁgures 4 and 5 there are diagrams of two elements of the powerset of
{B i } i=1,...,4n . One of them (ﬁgure 4) is not a member of C, the other one
(ﬁgure 5) is.
Let X be the random variable that corresponds to the ratio of the number
of partition elements (rectangles) that are in A 3 and the total number of
partition elements (rectangles) for a randomly chosen C ∈ C. We would now
anticipate that the expectation of X  (which we will call EX) gives us an
indication of the posterior probability that Judy is in A 3 (so EX ≈ q 3 ). The
powerset approach is often superior to the uniformity approach (Grove and
Halpern use uniformity, with all the necessary qualiﬁcations): if you have
played Monopoly, you will know that the frequencies for rolling a 2, a 7, or a
10 with two dice tend to conform more closely to the binomial distribution
A 3 A 1
A 2
Figure 4: This choice of rectangles is not a
member of C  because the number of rectan-
gles in A 2 is not a t-multiple of the number of
rectangles in A 1 , here with s = 2, t = 3 as in
scenario III.
(based on a powerset approach) rather than to the uniform distribution with
P (rolling i) = 1/11 for i = 2, . . ., 12.
The binomial distribution dictates the value of EX, using simple combi-
natorics. In this case we require, again for convenience, that n be divisible by
t and the ‘grain’ of the partition A be s = n/t. We introduce a few variables
which later on will help for abbreviation:
n = ts 2m = n 2j = n − 1 T = t 2 + 1
EX, of course, depends both on the grain of A and the value of t. It makes
sense to make it independent of the grain by letting the grain become in-
A 3 A 1
A 2
Figure 5: This choice of rectangles is a member
of C because the number of rectangles in A 2
is a t-multiple of the number of rectangles in
A 1 , here with s = 2, t = 3 as in scenario III.
creasingly ﬁner and by determining EX as s → ∞. This cannot be done for
the binomial distribution, as it is notoriously uncomputable for large num-
bers (even with a powerful computer things get dicey around s = 10). But,
equally notorious, the normal distribution provides a good approximation of
the binomial distribution and will help us arrive at a formula for G pws (cor-
responding to G ind and G max ), determining the value q 3 dependent on q as
suggested by the powerset approach.
First, we express the random variable X by the two independent random
variables X 12 and X 3 . X 12 is the number of partition elements in the randomly
chosen C which are either in A 1 or in A 2 (the random variable of the number
of partition elements in A 1 and the random variable of the number of partition
elements in A 2 are decisively not independent, because they need to obey
(HDQ)); X 3 is the number of partition elements in the randomly chosen C
which are in A 3 . A relatively simple calculation shows that EX 3 = n, which
is just what we would expect (either the powerset approach or the uniformity
approach would give us this result):
EX 3 = 2
−2n
2n
X
i=0
i
 2n
i

= n (use
 n
k

=
n
k
 n − 1
k − 1

)
The expectation of X, X being the random variable expressing the ratio
of the number of sets covering A 3 and the number of sets covering A 1 ∪A 2 ∪A 3 ,
is
EX =
EX 3
EX 12 + EX 3
=
n
EX 12 + n
If we were able to use uniformity and independence, EX 12 = n and EX =
1/2, just as Grove and Halpern suggest (although their uniformity approach
is admittedly less crude than the one used here). Will the powerset approach
concur with the uniformity approach, will it support the principle of maxi-
mum entropy, or will it make another suggestion on how to update the prior
probabilities? To answer this question, we must ﬁnd out what EX 12 is, for
a given value t and s → ∞, using the binomial distribution and its approxi-
mation by the normal distribution.
Using combinatorics,
EX 12 = (t + 1)
P
s
i=1
i  ts
i
 ts
ti

P
s
i=0
 ts
i
 ts
ti

Let us call the numerator of this fraction NUM and the denominator
DEN. According to the de Moivre-Laplace Theorem,
DEN =
s
X
i=0
 ts
i
 ts
ti

≈ 2 2n
s
X
i=0
Z
i+
1
2
i−
1
2
N (
n
2
,
n
4
)(i)N (
n
2
,
n
4
)(ti)di
where
N (µ, σ 2 )(x) =
1
√
2πσ 2
exp

−
(x − µ) 2
2σ 2

Substitution yields
DEN ≈ 2 2n 1
πm
s
X
i=0
Z
i+
1
2
i−
1
2
exp
 
−
(x − m)
2
m
−
t 2   x − m
t

2
m
!
dx
Consider brieﬂy the argument of the exponential function:
−
(x − m)
2
m
−
t 2   x − m
t

2
m
= −
t 2
m
(a
00
x 2 + b
00
x + c
00
) = −
t 2
m
  a
00
(x − h
00
) 2 + k
00
with (the double prime sign corresponds to the simple prime sign for the
numerator later on)
a
00
=
1
t 2
T b
00
= (−2m)
1
t 2
(t + 1) c
00
= 2m 2
1
t 2
h
00
= −b
00
/2a
00
k
00
= a
00
h
002
+ b
00
h
00
+ c
00
Consequently,
DEN ≈ 2 2n exp

−
t 2
m
k
00

r
1
πa 00 mt 2
Z
s+
1
2
−∞
N

h
00
,
m
2a 00 t 2

dx
And, using the error function for the cumulative density function of the
normal distribution,
DEN ≈ 2 2n−1
r
1
πa 00 mt 2
exp

−
k 00 t 2
m

(1 − erf(w
00
)) (6)
with
w
00
=
t
√
a 00   s + 1
2
− h 00
√
m
We proceed likewise with the numerator, although the additional factor
introduces a small complication:
NUM   =
s
X
i=1
i
 ts
i
 ts
ti

=
s
X
i=1
s
 ts
i
 ts − 1
ti − 1

≈   s2 2n−1
s
X
i=1
N

m,
m
2

(i)N

j,
j
2

(ti − 1)
Again, we substitute and get
NUM ≈ s2 2n−1

π
p
mj

−1
s−1
X
0
Z
i+
1
2
i−
1
2
exp   a
0
(x − h
0
) 2 + k
0
where the argument for the exponential function is
−
1
mj
 
j(x − m) 2 + mt 2

x −
j + 1
t

2!
and therefore
a
0
= j+mt 2 b
0
= 2j(1−m)+2mt (t − j) c
0
= j(1−m) 2 +m (t − j − 1)
2
h
0
= −b
0
/2a
0
k
0
= a
0
h
02
+ b
0
h
0
+ c
0
Using the error function,
NUM ≈ 2 2n−2
s
√
πa 0
exp

−
k 0
mj

(1 + erf(w
0
)) (7)
with
w
0
=
√
a 0   s − 1
2
− h 0
√
mj
Combining (6) and (7),
EX 12 =   (t + 1)
NUM
DEN
≈
1
2
(t + 1)
r
T ts
T ts − 1
se αt,s
for large s, because the arguments for the error function w 0 and w 00 escape
to positive inﬁnity in both cases (NUM and DEN) so that their ratio goes to
1. The argument for the exponential function is
α t,s = −
k 0
mj
+
k 00 t 2
m
and, for s → ∞, goes to
α t =
1
2
T
−2 (2t 3 − 3t 2 + 4t − 5)
Notice that, for t → ∞, α t goes to 0 and
EX =
n
EX 12 + n
→
2
3
in accordance with intuition T2.
We now have a formula for the powerset approach corresponding to the
formula for the maxent approach, giving us q 3 dependent on t. Notice that
this formula is for t = 2, 3, 4, . . .. For t = 1 use the Chu-Vandermonde identity
to ﬁnd that
EX 12 = (t + 1)
P
s
i=1
i  ts
i
 ts
ti

P
s
i=0
 ts
i
 ts
ti

= (t + 1)
s
2
and consequently EX = 1/2, as one would expect. For t = 1/2, 1/3, 1/4, . . .
we can simply reverse the roles of A 1 and A 2 . These results give us G pws and
a graph of the normalized odds vector (see ﬁgure 6), a bit bumpy around the
middle because the t-values are discrete and farther apart in the middle, as
t = q/(1 − q). Comparing the graphs of the normalized odds vector under
Grove and Halpern’s uniformity approach (G ind ), Jaynes’ maxent approach
(G max ), and the powerset approach suggested in this paper (G pws ), it is clear
that the powerset approach supports maxent .
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0
q 1
q 2
q 3
Figure 6: Judy Benjamin’s posterior probabil-
ity assignment according to the powerset ap-
proach. 0 < q < 1 forms the horizontal axis,
the vertical axis shows the posterior probabil-
ity distribution (or the normalized odds vec-
tor) (q 1 , q 2 , q 3 ). The vertical line at q = 0.75
shows the speciﬁc posterior probability distri-
bution G pws for the Judy Benjamin problem.
Going through the calculations, it seems at many places that the pow-
erset approach should give its support to Grove and Halpern’s uniformity
approach in keeping with intuition T1. It was unexpected to ﬁnd out that
in the mathematical analysis α t,s converges to a non-trivial factor and did
not tend to negative or positive inﬁnity, enabling a graph of the normalized
odds vector that was not of the simple nature of the graph suggested by
Grove and Halpern. Most surprisingly, the powerset approach, prima facie
unrelated to an approach using information, supports the idea that a set of
events about which nothing is known (such as A 3 ) gains in probability in the
posterior probability distribution compared to the set of events about which
something is known (such as A 1 and A 2 ), even if it is only partial informa-
tion. Unless independence is speciﬁed, as in Sarah and sundowners at the
Westcliﬀ, the area of ignorance gains compared to the area of knowledge.
6. References
Cover, T. and Thomas, J., 2006. Elements of Information Theory, volume 6.
Wiley, Hoboken, NJ.
Csisz´ar, I., 1967.   Information-Type Measures of Diﬀerence of Probability
Distributions and Indirect Observations.  Studia Scientiarum Mathemati-
carum Hungarica, 2:299–318.
Douven, I. and Romeijn, J., 2009. A New Resolution of the Judy Benjamin
Problem. CPNSS Working Paper, 5(7):1–22.
Grove, A. and Halpern, J., 1997. Probability Update: Conditioning Vs. Cross-
Entropy.  In Proceedings of the Thirteenth Conference on Uncertainty in
Artiﬁcial Intelligence. Citeseer, Providence, Rhode Island.
Hobson, A., 1971.  Concepts in Statistical Mechanics.  Gordon and Beach,
New York, NY.
Jaynes, E., 1989.  Papers on Probability, Statistics and Statistical Physics.
Springer, Dordrecht.
Jaynes, E. and Bretthorst, G., 1998. Probability Theory: the Logic of Science.
Cambridge University Press, Cambridge, UK.
Jeﬀrey, R., 1965. The Logic of Decision. McGraw-Hill, New York, NY.
Shore, J. and Johnson, R., 1980.  Axiomatic Derivation of the Principle of
Maximum Entropy and the Principle of Minimum Cross-Entropy.  IEEE
Transactions on Information Theory, 26(1):26–37.
Uﬃnk, J., 1996.  The Constraint Rule of the Maximum Entropy Principle.
Studies In History and Philosophy of Science Part B: Studies In History
and Philosophy of Modern Physics, 27(1):47–79.
Van Fraassen, B., 1981.  A Problem for Relative Information Minimizers in
Probability Kinematics. The British Journal for the Philosophy of Science,
32(4):375–379.
Van Fraassen, B.; Hughes, R.; and Harman, G., 1986. A Problem for Relative
Information Minimizers, Continued.  The British Journal for the Philoso-
phy of Science, 37(4):453–463.
