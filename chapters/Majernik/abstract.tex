Two open questions of inductive reasoning are solved: (1) does the
principle of maximum entropy \textsc{pme} give a solution to the
obverse Majern{\'\i}k problem; and (2) is Wagner correct when he
claims that Jeffrey's updating principle \textsc{jup} contradicts the
\textsc{pme}?  Majern{\'\i}k shows that the \textsc{pme} provides
unique and plausible marginal probabilities, given conditional
probabilities.  The obverse problem posed here is whether the
\textsc{pme} also provides such conditional probabilities, given
certain marginal probabilities. The theorem developed to solve the
obverse Majern{\'\i}k problem demonstrates that in the special case
introduced by Wagner the \textsc{pme} does not contradict
\textsc{jup}, but elegantly generalizes it and offers a more
integrated approach to probability updating.
