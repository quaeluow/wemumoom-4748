Two open questions are solved: (1) Does the principle of maximum entropy give a solution to the obverse Majernik problem? (2) Is Carl Wagner correct when he claims that Jeffrey's updating principle contradicts the principle of maximum entropy? Vladimir Majernik shows that the principle of maximum entropy provides unique and plausible marginal probabilities, given conditional probabilities. The obverse problem posed here is whether the principle of maximum entropy also provides such conditional probabilities, given certain marginal probabilities. The theorem developed to solve the obverse Majernik problem demonstrates that in the special case introduced by Wagner the principle of maximum entropy does not contradict Jeffrey's updating principle. Wagner's appeal to reject the principle of maximum entropy because it violates Jeffrey's updating principle loses its sting. Not only does the principle of maximum entropy generalize Jeffrey conditioning (a commonly known fact), it also elegantly generalizes the broader applications of Jeffrey's updating principle as introduced by Wagner. On the domain where Jeffrey's updating principle is operative, the principle of maximum entropy offers an integrated approach to probability updating.
