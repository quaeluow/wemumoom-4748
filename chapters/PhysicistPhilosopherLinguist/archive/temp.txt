When we come to know a conditional, we cannot straightforwardly apply Jeffrey conditioning to gain an updated probability distribution. Carl Wagner has proposed a natural generalization of Jeffrey conditioning to accommodate this case. The generalization rests on an ad hoc but plausible intuition. Wagner shows how the principle of maximum entropy disagrees with this intuition, thus casting further doubt on the principle of maximum entropy as a generally valid updating mechanism that generalizes Jeffrey conditioning. This article demonstrates that Wagner's application of the principle of maximum entropy is incorrect and that a correct application agrees with his intuition. It presents a formal proof that the principle of maximum entropy seamlessly and elegantly generalizes not only standard conditioning and Jeffrey conditioning (as is well-documented in the literature) but also Wagner's generalization.
